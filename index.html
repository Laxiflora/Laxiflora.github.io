<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"laxiflora.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="laxiflora的小天地">
<meta property="og:url" content="https://laxiflora.github.io/index.html">
<meta property="og:site_name" content="laxiflora的小天地">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="劉宇承">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://laxiflora.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-TW","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>laxiflora的小天地</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">laxiflora的小天地</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">前進軟體工程師的練功之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">劉宇承</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/10/10/C-pipe%E8%88%87buffer-overflow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/10/C-pipe%E8%88%87buffer-overflow/" class="post-title-link" itemprop="url">C++ pipe與buffer overflow</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-10-10 23:28:56" itemprop="dateCreated datePublished" datetime="2022-10-10T23:28:56+08:00">2022-10-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-10-11 00:15:31" itemprop="dateModified" datetime="2022-10-11T00:15:31+08:00">2022-10-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本篇主要講述C++中<code>pipe()</code>函數的相關行為</p>
<p>因為pipe的buffer大小並非無限大，如果輸入流資料量過大，很有可能會碰到buffer塞滿而輸入還沒結束的問題<br>寫了以下的code來測試pipe buffer如果塞爆了會發生甚麼事情</p>
<h1 id="實驗"><a href="#實驗" class="headerlink" title="實驗"></a>實驗</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/wait.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span>* argv[])</span></span>&#123;</span><br><span class="line">    <span class="comment">// 創造pipe</span></span><br><span class="line">    <span class="type">int</span> my_pipe[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">pipe</span>(my_pipe) == <span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Error creating pipe\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//-------------------------</span></span><br><span class="line">    <span class="type">pid_t</span> child_id;</span><br><span class="line">    child_id = fork();</span><br><span class="line">    <span class="keyword">if</span>(child_id == <span class="number">-1</span>)&#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(stderr, <span class="string">&quot;Fork error\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 創造一個子process，將buffer塞爆</span></span><br><span class="line">    <span class="keyword">if</span>(child_id == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">close</span>(my_pipe[<span class="number">0</span>]);</span><br><span class="line">        <span class="built_in">dup2</span>(my_pipe[<span class="number">1</span>], <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        string some = <span class="string">&quot;something&quot;</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1000000000000000</span>;i++)&#123;</span><br><span class="line">            cout&lt;&lt;some;</span><br><span class="line">        &#125;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;Chind,finished&quot;</span>;</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//---------------------------------</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;   </span><br><span class="line">        <span class="type">int</span> aaa = fork();</span><br><span class="line">        <span class="comment">// 再創造一個子process，讓他先sleep 4秒以後再嘗試在已經被塞爆的buffer寫入</span></span><br><span class="line">        <span class="keyword">if</span>(aaa == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="built_in">sleep</span>(<span class="number">4</span>);</span><br><span class="line">            <span class="built_in">close</span>(my_pipe[<span class="number">0</span>]);</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">1999</span>;i++)&#123;</span><br><span class="line"></span><br><span class="line">                cout&lt;&lt;<span class="string">&quot;Child2 round &quot;</span>&lt;&lt;i+<span class="number">1</span>&lt;&lt;<span class="string">&quot;\n&quot;</span>;</span><br><span class="line">                <span class="built_in">write</span>(my_pipe[<span class="number">1</span>],<span class="string">&quot;NP&quot;</span>,<span class="built_in">sizeof</span>(<span class="string">&quot;NP&quot;</span>));  <span class="comment">// is stuck because of the fullness of pipe</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//----------------------------</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 原本的父process，先sleep 10秒讓我們觀察child process被塞爆的現象再read一些東西來疏通pipe，但這樣的量不足以讀完所有的input</span></span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line"></span><br><span class="line">            <span class="built_in">close</span>(my_pipe[<span class="number">1</span>]); <span class="comment">// parent doesn&#x27;t write</span></span><br><span class="line"></span><br><span class="line">            <span class="type">char</span> reading_buf[<span class="number">1000</span>]=&#123;<span class="string">&#x27;\0&#x27;</span>&#125;;</span><br><span class="line">            <span class="built_in">sleep</span>(<span class="number">10</span>);</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;<span class="number">10000</span>;i++)&#123;</span><br><span class="line">                <span class="built_in">read</span>(my_pipe[<span class="number">0</span>], reading_buf, <span class="number">100</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//等待第一次fork出來的子process</span></span><br><span class="line">    <span class="built_in">wait</span>(&amp;child_id);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//這行永遠不會印出來，因為子process永遠不會輸出完成而結束</span></span><br><span class="line">    cout&lt;&lt;my_pipe[<span class="number">0</span>]&lt;&lt;my_pipe[<span class="number">1</span>]; <span class="comment">//3,4</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>實際編譯執行後，出現以下結果<br><img src="/../images/20221010_2.png" alt="upload successful"><br>Child2卡在第1897次輸出就寫不下去了，當然第一個process也是卡住的狀態(見Ps)</p>
<h1 id="Pipe特性"><a href="#Pipe特性" class="headerlink" title="Pipe特性"></a>Pipe特性</h1><p>從這個小實驗可以知道一些事情</p>
<ul>
<li><p>pipe的buffer有限，是會被塞爆的</p>
</li>
<li><p>原生的pipe如果被寫滿，會讓想繼續寫入的<strong>所有process</strong>被卡住不能繼續執行，直到pipe被讀取</p>
<ul>
<li>不可以wait process完整寫入發signal以後才fork另一個process再讀取，這樣很可能導致整個程式卡死<br>    - 如果卡住的process太多，可能會讓父process再也fork不出東西來讓本該讀取的process去接，造成整個程式卡死</li>
</ul>
</li>
<li><p>要注意針對大資料的處理，pipe應該要有個”抒發管道”，不能期待他真的裝下全世界</p>
</li>
</ul>
<h2 id="補充"><a href="#補充" class="headerlink" title="補充"></a>補充</h2><p>我另外做了一個反向實驗:<br>    讓輸入資料的process延遲輸入，而讀取的process開始讀空的pipe，得到以下心得</p>
<ul>
<li>讀取端會等read(fd,char* buffer,int size)裡面的size被填滿才會執行接下來的動作<ul>
<li>想到以前上課老師說的，只要<strong>還有process 對pipe的輸入端還未關閉</strong>，讀取端就會一直認為有東西要進來，而呆呆地等 -&gt; 關不用的stream很重要!</li>
</ul>
</li>
</ul>
<p>P.S<br>測試這個東西的時候還有用背景執行，創造了不少卡著的process<br><img src="/../images/20221010_1.png"><br>其中相連的pid可以看出來是同一個程式來的，原本的父process，連帶所有child process都無法被正常結束…</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/10/09/%E7%94%A8std-string%E5%81%9Astrtok/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/10/09/%E7%94%A8std-string%E5%81%9Astrtok/" class="post-title-link" itemprop="url">用std::string做strtok</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>
      

      <time title="創建時間：2022-10-09 17:16:11 / 修改時間：17:36:08" itemprop="dateCreated datePublished" datetime="2022-10-09T17:16:11+08:00">2022-10-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>參考資料: <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/289347/using-strtok-with-a-stdstring">stackoverflow</a></p>
<h1 id="用std-string做strtok"><a href="#用std-string做strtok" class="headerlink" title="用std::string做strtok"></a>用std::string做strtok</h1><p>由於C++的string type並不支援strtok的功能，所以如果想要將C++的string做切段，有以下幾種方法:</p>
<h2 id="法1-用istringstream"><a href="#法1-用istringstream" class="headerlink" title="法1: 用istringstream"></a>法1: 用istringstream</h2><p>使用<a target="_blank" rel="noopener" href="https://cplusplus.com/reference/sstream/istringstream/istringstream/">stringstream類別</a>，使用方法就像C++風格的iostream一樣，只是這個stream不是stdin&#x2F;stdout，也不是fstream，而是將string的內容倒入一個stream (因此不具有fd–待查證)。</p>
<p>將要切割的字串倒入stream以後，再用getline中的Delimiter參數做為切割標準即可<br>參考程式碼片段如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">vector&lt;string&gt; <span class="title">split</span><span class="params">(<span class="type">const</span> string&amp; s, <span class="type">char</span> delimiter)</span></span>&#123;</span><br><span class="line">   vector&lt;string&gt; tokens;</span><br><span class="line">   string token;</span><br><span class="line">   <span class="function">istringstream <span class="title">tokenStream</span><span class="params">(s)</span></span>;</span><br><span class="line">   <span class="keyword">while</span> (<span class="built_in">getline</span>(tokenStream, token, delimiter))&#123;</span><br><span class="line">      tokens.<span class="built_in">push_back</span>(token);</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">return</span> tokens;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// tokens vector裝的是切割完的string</span></span><br></pre></td></tr></table></figure>


<h2 id="法2-先把string轉成char-以後再切割"><a href="#法2-先把string轉成char-以後再切割" class="headerlink" title="法2: 先把string轉成char*以後再切割"></a>法2: 先把string轉成char*以後再切割</h2><p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/289347/using-strtok-with-a-stdstring">參考資料</a><br>如果要將string轉換成char*，可以透過<code>string.c_str()</code>函數</p>
<p>這個方法其實不太推薦，他是把C++風格棄掉，強制使用strtok來處理字串<br>參考程式碼片段如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//given string str as a string needed to slice</span></span><br><span class="line"><span class="type">char</span> *dup = <span class="built_in">strdup</span>(str.<span class="built_in">c_str</span>());</span><br><span class="line">token = <span class="built_in">strtok</span>(dup, <span class="string">&quot; &quot;</span>);</span><br><span class="line"><span class="built_in">free</span>(dup);</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/17/ML-2021-12-1-%E5%A2%9E%E5%BC%B7%E5%BC%8F%E5%AD%B8%E7%BF%92%E8%B7%9F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E4%B8%80%E6%A8%A3%E9%83%BD%E6%98%AF%E4%B8%89%E5%80%8B%E6%AD%A5%E9%A9%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/17/ML-2021-12-1-%E5%A2%9E%E5%BC%B7%E5%BC%8F%E5%AD%B8%E7%BF%92%E8%B7%9F%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E4%B8%80%E6%A8%A3%E9%83%BD%E6%98%AF%E4%B8%89%E5%80%8B%E6%AD%A5%E9%A9%9F/" class="post-title-link" itemprop="url">ML_2021_12-1 增強式學習跟機器學習一樣都是三個步驟</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>
      

      <time title="創建時間：2022-08-17 13:15:48 / 修改時間：19:31:50" itemprop="dateCreated datePublished" datetime="2022-08-17T13:15:48+08:00">2022-08-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/15/ML-2021-11-1-%E6%A6%82%E8%BF%B0%E9%A0%98%E5%9F%9F%E8%87%AA%E9%81%A9%E6%87%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/15/ML-2021-11-1-%E6%A6%82%E8%BF%B0%E9%A0%98%E5%9F%9F%E8%87%AA%E9%81%A9%E6%87%89/" class="post-title-link" itemprop="url">ML_2021_11-1 概述領域自適應</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-15 01:58:17" itemprop="dateCreated datePublished" datetime="2022-08-15T01:58:17+08:00">2022-08-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-17 19:31:50" itemprop="dateModified" datetime="2022-08-17T19:31:50+08:00">2022-08-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Train跟testing data之間可能會有不同的分佈 -&gt; <strong>domain shift</strong></p>
<p>ex. 用黑白圖片訓練數字辨識，但測試資料使用彩色圖片，則命中率會大幅降低</p>
<h1 id="Domain-shift的種類"><a href="#Domain-shift的種類" class="headerlink" title="Domain shift的種類"></a>Domain shift的種類</h1><ul>
<li>不只是輸入資料的特性不合</li>
<li>可能輸出的資料，其機率分佈不一樣</li>
<li>或是也許在測試資料裡面，雖然圖樣跟訓練資料很像，但是它所代表的意涵卻不一樣<br><img src="/../images/20220817_1.png"></li>
</ul>
<h1 id="Domain-adaptation"><a href="#Domain-adaptation" class="headerlink" title="Domain adaptation"></a>Domain adaptation</h1><ul>
<li>可以看作是transfer learning的一種</li>
<li>我們會需要對target domain有一些了解</li>
</ul>
<h2 id="Case-1-有target-domain的labeled資料但資料量很少"><a href="#Case-1-有target-domain的labeled資料但資料量很少" class="headerlink" title="Case 1:有target domain的labeled資料但資料量很少"></a>Case 1:有target domain的labeled資料但資料量很少</h2><ul>
<li>用類似BERT的fine-tune方法來微調一下model</li>
<li>但target domain資料量很少，所以很容易overfitting<ul>
<li>限制fine-tune前後的參數變化量<br>    - 降低lr<br>    - 限制epoch數</li>
</ul>
</li>
</ul>
<h2 id="Case-2-有一大堆target-domain的unlabeled資料"><a href="#Case-2-有一大堆target-domain的unlabeled資料" class="headerlink" title="Case 2:有一大堆target domain的unlabeled資料"></a>Case 2:有一大堆target domain的unlabeled資料</h2><ul>
<li>本課的討論重點</li>
<li>在實務上比較有常發生</li>
<li>Idea:用一個feature extractor把source跟target domain的不同點刪除，擷取出共同的部分<ul>
<li>Ex.數字辨識，學習去忽略圖片顏色</li>
</ul>
</li>
</ul>
<h3 id="Domain-Adversarial-training"><a href="#Domain-Adversarial-training" class="headerlink" title="Domain Adversarial training"></a>Domain Adversarial training</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><ul>
<li><p>我們會訓練出一個new image classifier model，其中前半部分是feature extractor，後半部則是label predictor<br><img src="/../images/20220817_2.png"></p>
</li>
<li><p>我們會希望feature extractor的輸出（上圖右下角的分佈圖），source跟target domain的分佈看不出差異</p>
</li>
<li><p>由feature extractor跟domain classifier互相對抗，將feature extractor的輸出送到domain classifier，domain classifier要想辦法辨認出這個輸出是來自source還是target domain</p>
</li>
<li><p>feature extractor -&gt; Generator &amp; domain classifier -&gt; Discriminator</p>
</li>
<li><p>但這樣對於feature extractor優勢太大，因為只要他都輸出0，就可以讓domain classifier被輕鬆騙過去 -&gt; 讓label Predictor也加入戰局</p>
</li>
</ul>
<h4 id="計算方法"><a href="#計算方法" class="headerlink" title="計算方法"></a>計算方法</h4><p>令</p>
<ol>
<li>Feature extractor的參數為$\theta_f$</li>
<li>Label Predictor的參數為$\theta_p$</li>
<li>Domain Classifier的參數為$\theta_d$</li>
<li>輸出圖片預測結果與真實結果的loss(cross entropy)為$L$</li>
<li>Domain Classifier二元分類器的輸出loss為$L_d$</li>
</ol>
<p>因為我們同時希望Label Predictor分類越正確越好，又同時希望domain classifier能被騙過。則可以得出一個最佳化feature extractor的公式（非正確，勿照抄）<br>$$<br>\theta_f^* &#x3D; min_{\theta_f}\ L-L_d<br>$$</p>
<p>問題來了，如果我們直接套用這個公式，會導致$L_d$越大越好（也就是讓domain classifier的loss飆高），這可能讓feature extractor變成努力讓domain classifier把target看成source，source看成target，而這也是某種程度上的分隔開兩個domain</p>
<p>如何改善公式，留給大家思考orz</p>
<p>domain adversarial training的效果拔群<br><img src="/../images/20220817_3.png"></p>
<h3 id="Limitation"><a href="#Limitation" class="headerlink" title="Limitation"></a>Limitation</h3><p><img src="/../images/20220817_5.png"><br>由上面的公式，我們可以練出上圖兩種類型的model滿足上面的公式，但是可以明顯看出，右邊的分佈會比左邊還好</p>
<p>我們雖然不知道橘色(target domain)的label為何，但我們知道藍色(source)資料的分界線，因此我們要在這樣的前提下，想辦法也讓橘色的資料被該分界線劃清</p>
<ul>
<li>有很多相關方法<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.08735">參考文獻：DIRT-T</a></li>
<li>一種簡單的方向是確保unlabeled data丟入label predictor後輸出的分佈越集中越好<br><img src="/../images/20220817_6.png"></li>
</ul>
</li>
</ul>
<h2 id="Case-3：雖然Target-domain-unlabeled-data很多，但Source跟Target-domain的class集合不同"><a href="#Case-3：雖然Target-domain-unlabeled-data很多，但Source跟Target-domain的class集合不同" class="headerlink" title="Case 3：雖然Target domain unlabeled data很多，但Source跟Target domain的class集合不同"></a>Case 3：雖然Target domain unlabeled data很多，但Source跟Target domain的class集合不同</h2><p>到目前為止，我們都假設target跟source domain的類別集合是一樣的</p>
<p>如果類別集合不同，則硬要align data可能會反導致兩個無關的class被綁在一起 $\rightarrow$ <strong>Universal domain adaptation</strong></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/html/You_Universal_Domain_Adaptation_CVPR_2019_paper.html">參考文獻</a></li>
</ul>
<h2 id="Case-4：Target-domain-unlabeled-data也很少"><a href="#Case-4：Target-domain-unlabeled-data也很少" class="headerlink" title="Case 4：Target domain unlabeled data也很少"></a>Case 4：Target domain unlabeled data也很少</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.13231">Testing time training(TTT)</a></li>
</ul>
<h2 id="Case-5：我啥都不知道QQ"><a href="#Case-5：我啥都不知道QQ" class="headerlink" title="Case 5：我啥都不知道QQ"></a>Case 5：我啥都不知道QQ</h2><ul>
<li>Domain Generalization<ul>
<li>訓練資料豐富，包含各種domain（ex. 貓狗分類，除了真貓真狗以外還有素描、卡通畫風）<br>    	- <a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8578664">參考文獻</a><br>    - 訓練資料不豐富，但測試資料很豐富(有點像想辦法做data augmentation)<br>    	- <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2003.13216">參考文獻</a></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/11/ML-2021-10-2-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%83%BD%E5%90%A6%E8%BA%B2%E9%81%8E%E4%BA%BA%E9%A1%9E%E6%B7%B1%E4%B8%8D%E8%A6%8B%E5%BA%95%E7%9A%84%E6%83%A1%E6%84%8F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/11/ML-2021-10-2-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%83%BD%E5%90%A6%E8%BA%B2%E9%81%8E%E4%BA%BA%E9%A1%9E%E6%B7%B1%E4%B8%8D%E8%A6%8B%E5%BA%95%E7%9A%84%E6%83%A1%E6%84%8F/" class="post-title-link" itemprop="url">ML_2021_10-2 類神經網路能否躲過人類深不見底的惡意?</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-11 16:26:19" itemprop="dateCreated datePublished" datetime="2022-08-11T16:26:19+08:00">2022-08-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-15 02:00:01" itemprop="dateModified" datetime="2022-08-15T02:00:01+08:00">2022-08-15</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在前面的攻擊，是假設我們知道模型的weights，這類攻擊稱為White box attack</p>
<p>白箱攻擊非常簡單，盡量不要暴露parameters</p>
<p>下面課程前半部以圖片辨識為例介紹</p>
<h1 id="Black-box-attack"><a href="#Black-box-attack" class="headerlink" title="Black box attack"></a>Black box attack</h1><h2 id="1-Proxy-network"><a href="#1-Proxy-network" class="headerlink" title="1. Proxy network"></a>1. Proxy network</h2><h3 id="a-原理"><a href="#a-原理" class="headerlink" title="a. 原理"></a>a. 原理</h3><p>我們雖然不知道想攻擊的模型的參數，但我們可以透過用同樣一批訓練資料，練出一個自己的網路。當我們能透過白箱攻擊讓Proxy network出現漏洞，則我們也有可能可以用同樣的方式讓想攻擊的network淪陷</p>
<h3 id="b-若無訓練資料"><a href="#b-若無訓練資料" class="headerlink" title="b. 若無訓練資料"></a>b. 若無訓練資料</h3><p>如果沒有訓練資料，也可以透過自己準備一批資料，餵給想攻擊的模型，讓他吐出一堆輸出，把輸入與輸出綁成成對資料，再拿去訓練自己的proxy network</p>
<p><img src="/../images/20220814_1.png" alt="上圖是用不同網路去攻擊各網路的accuracy，對角線因為是為白箱攻擊，所以不計入(能破proxy必能破attacked)"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.02770">上圖來源(相關論文)</a></li>
</ul>
<h3 id="c-Advanced-technique-Ensemble-attack"><a href="#c-Advanced-technique-Ensemble-attack" class="headerlink" title="c. Advanced technique: Ensemble attack"></a>c. Advanced technique: Ensemble attack</h3><ul>
<li>透過使用Ensemble model有效提高攻擊的強度</li>
</ul>
<p><img src="/../images/20220814_2.png"><br>上圖縱列是指拿掉甚麼network，橫列則是被攻擊的network，如「-ResNet-152」那列就是結合除了ResNet-152以外的4個network所訓練出來的proxy network對各網路的攻擊結果；其中非對角線部分因為已在proxy network被訓練過，均視為白箱攻擊，不計入(0%)</p>
<h1 id="為何黑箱攻擊如此容易成功"><a href="#為何黑箱攻擊如此容易成功" class="headerlink" title="為何黑箱攻擊如此容易成功?"></a>為何黑箱攻擊如此容易成功?</h1><ul>
<li><strong>至今仍然還沒有確定性的答案</strong></li>
<li>多數人相信是因為模型之間存在著相似性，如下圖<br><img src="/../images/20220814.png"></li>
</ul>
<p>圖片為一個高維向量，圖片的值是為原點，圖片的橫軸為可以讓攻擊成功的維度變化量，縱軸則為其他維度的偏移量。</p>
<p>可以發現，能在VGG-16攻擊成功的維度偏移方向，與其餘4種network均很相近。也就是說，能找到在VGG-16攻擊成功的圖片偏移方向與大小，在其他network上均大同小異。</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1611.02770.pdf">論文來源</a></p>
</li>
<li><p>目前有一群人認為：或許Adversarial attack會成功，不是因為模型的問題，而是資料本身的特徵真的就是長那樣 $\rightarrow$ 或許資料量更大就能避免</p>
</li>
</ul>
<h1 id="One-pixel-attack"><a href="#One-pixel-attack" class="headerlink" title="One pixel attack"></a>One pixel attack</h1><p>只動圖片裡的1 pixel就達成攻擊目的</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.08864">來源論文</a></li>
<li>目前效果有限</li>
</ul>
<h1 id="Universal-Adversarial-Attack"><a href="#Universal-Adversarial-Attack" class="headerlink" title="Universal Adversarial Attack"></a>Universal Adversarial Attack</h1><ul>
<li>針對一個network的全方位攻擊方式</li>
</ul>
<p>針對不同的圖片輸入，客製化出一個攻擊方式</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1610.08401">來源論文</a></li>
</ul>
<h1 id="Adversarial-reprogramming"><a href="#Adversarial-reprogramming" class="headerlink" title="Adversarial reprogramming"></a>Adversarial reprogramming</h1><p>有點像殭屍寄生，讓原本的model輸出非他原本訓練想要的結果<br><img src="/../images/20220815_7.png" alt="upload successful"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.11146">來源論文</a></li>
</ul>
<h1 id="Backdoor-in-model"><a href="#Backdoor-in-model" class="headerlink" title="Backdoor in model"></a>Backdoor in model</h1><ul>
<li>在訓練階段就展開攻擊</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.00792">來源論文</a></li>
<li>在訓練資料就放入attacked image，讓模型練完以後看似正常，卻只對單一類型圖片會出現問題，如同後門</li>
</ul>
<p>$rightarrow$ 若這樣的技術成熟，公開資料集將會變得不安全</p>
<hr>
<h1 id="其他領域的攻擊應用"><a href="#其他領域的攻擊應用" class="headerlink" title="其他領域的攻擊應用"></a>其他領域的攻擊應用</h1><h2 id="1-Speech-processing"><a href="#1-Speech-processing" class="headerlink" title="1. Speech processing"></a>1. Speech processing</h2><ul>
<li>Detect synthesized speech：抓出合成的聲音訊號</li>
</ul>
<p>攻擊者刻意在合成音裡面加入雜訊，讓機器以為那是原聲</p>
<h2 id="2-NLP"><a href="#2-NLP" class="headerlink" title="2. NLP"></a>2. NLP</h2><p>文字輸入，進行機器QA</p>
<p>刻意在文字中加入雜訊，讓機器搞錯重點</p>
<ul>
<li>範例：(<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.07125">https://arxiv.org/abs/1908.07125</a>)</li>
</ul>
<h2 id="3-人臉辨識：真實世界攻擊"><a href="#3-人臉辨識：真實世界攻擊" class="headerlink" title="3. 人臉辨識：真實世界攻擊"></a>3. 人臉辨識：真實世界攻擊</h2><ul>
<li>既然能在虛擬世界中對圖片加工造成機器判別錯誤，當然也有可能在現實世界中對人臉加裝配件對機器造成攻擊</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://www.cs.cmu.edu/~sbhagava/papers/face-rec-ccs16.pdf">來源論文</a><br><img src="/../images/20220815_5.png"></p>
<ul>
<li>現實世界需要考慮諸多因素<ul>
<li>攝影角度 $\rightarrow$ universal attack(?<br>    - 解析度問題<br>    - 眼鏡印製的色差問題</li>
</ul>
</li>
</ul>
<p>除此以外，也有針對交通號誌的攻擊，讓自駕車變得困難<br><img src="/../images/20220815_6.png"></p>
<hr>
<h1 id="Defence"><a href="#Defence" class="headerlink" title="Defence"></a>Defence</h1><ul>
<li>防禦分為兩種<ul>
<li>主動防禦</li>
<li>被動防禦</li>
</ul>
</li>
</ul>
<h2 id="1-被動防禦"><a href="#1-被動防禦" class="headerlink" title="1. 被動防禦"></a>1. 被動防禦</h2><ul>
<li><p>network不動，在圖片丟入之前放一個Filter，來隔絕雜訊</p>
</li>
<li><p>一種簡單的做法是刻意把圖片模糊化，讓原本可以讓攻擊成功的維度偏移量改變</p>
<ul>
<li>但同時也會降低原始正常圖片的辨識度</li>
</ul>
</li>
</ul>
<h3 id="a-更多作法"><a href="#a-更多作法" class="headerlink" title="a. 更多作法"></a>a. 更多作法</h3><ul>
<li><p>圖片壓縮(刻意失真)</p>
</li>
<li><p>讓Generator重新把input image重新畫一遍</p>
<ul>
<li>是有方法讓Generator產生一樣東西的，但因為generator沒看過雜訊，會產生不出來<br>    - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.06605">相關文獻</a></li>
</ul>
</li>
<li><p>被動防禦(模糊化)也可以視為在network前面加入一層，所以一旦被知道以後，防禦力將會大減 $\rightarrow$ 隨機化</p>
</li>
</ul>
<h3 id="b-Randomization"><a href="#b-Randomization" class="headerlink" title="b. Randomization"></a>b. Randomization</h3><ul>
<li>把圖片隨機resize,padded一些背景之後再丟入network</li>
</ul>
<p><img src="/../images/20220814_8.png" alt="upload successful"></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.01991">相關文獻</a></p>
</li>
<li><p>仍然有可能被攻破，抓出所有可能以後用universal attack</p>
</li>
</ul>
<h2 id="2-主動防禦"><a href="#2-主動防禦" class="headerlink" title="2. 主動防禦"></a>2. 主動防禦</h2><h3 id="a-Adversarial-training"><a href="#a-Adversarial-training" class="headerlink" title="a. Adversarial training"></a>a. Adversarial training</h3><ul>
<li><p>在訓練階段就讓模型被攻擊</p>
</li>
<li><p>把原始圖片做成attacked image後標上正確label以後再丟入model</p>
</li>
<li><p>某種程度上就是data augmentation (有洞就補洞)</p>
<ul>
<li>就算不會被攻擊，也會有人用這樣的方式來強化model(降低overfitting可能性)</li>
</ul>
</li>
<li><p>訓練過程需要大量訓練資源，且如果碰到沒補過洞的attack algorithm，依然會被攻破</p>
</li>
<li><p>有方法是不需額外計算的情況下做到adversarial training</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.12843">相關文獻</a></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/11/ML-2021-10-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/11/ML-2021-10-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">ML_2021_10-1 基本概念</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>
      

      <time title="創建時間：2022-08-11 15:24:48 / 修改時間：19:32:45" itemprop="dateCreated datePublished" datetime="2022-08-11T15:24:48+08:00">2022-08-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>光是正確率高還不夠，若想要讓model放在真實世界運用，還要能防止針對模型的惡意攻擊</p>
<ul>
<li>本課一樣是舉圖形分類問題為例</li>
</ul>
<h1 id="How-to-attack"><a href="#How-to-attack" class="headerlink" title="How to attack"></a>How to attack</h1><p>我們將原本正常的圖片(Benign image)vector都加上一些小小的值，做成Attacked image，則雖然肉眼看不出來，對機器來說卻很容易造成誤判<br><img src="/../images/20220811_5.png" alt="上圖是雜訊被過度加大的結果，正常是什麼都看不出來的"></p>
<h1 id="如何找出攻擊的參數"><a href="#如何找出攻擊的參數" class="headerlink" title="如何找出攻擊的參數"></a>如何找出攻擊的參數</h1><p>雜訊並非亂加就好，需要解出一個optimization問題<br>假設原始圖片benign image是$x^0$，則輸出$y^0 &#x3D; f(x^0)$是一個分布</p>
<p>現在我們想要找到attacked image $\ x^*$，使得他</p>
<ol>
<li>與原始$y^0$所屬的類別$\hat{y}$差距越大越好</li>
<li>與想被誤判的目標類別$y^{target}$越小越好</li>
<li>與原始圖片$x^0$的差距越小越好（才不會被抓到偷改）</li>
</ol>
<p>則我們會需要解出一個最佳化圖片$x^*$使<br>$$<br>x^* &#x3D; arg\ min_{d(x^0,x)\leq \epsilon}\ L(x) \\\<br>L(x) &#x3D; -e(y,\hat{y}) + e(y,y^{target})<br>$$<br>其中e表示cross entropy，L表示loss function，$\epsilon$表示與原圖差距的極限值</p>
<h2 id="原圖與攻擊圖的差距計算"><a href="#原圖與攻擊圖的差距計算" class="headerlink" title="原圖與攻擊圖的差距計算"></a>原圖與攻擊圖的差距計算</h2><ul>
<li><p>方便計算，這裡均假設他們是一個vector，則原圖與修改圖之間的差距就是他們的向量相減。</p>
<ul>
<li>問題是，如何定義這樣的差值的距離？</li>
</ul>
</li>
<li><p>可以用L2-norm或L-infinity等等算法算距離<br><img src="/../images/20220811_6.png" alt="差值計算方法與L2、L-infinity的公式"></p>
</li>
</ul>
<p>要用哪種norm好呢？<br>舉例，給定一個圖片，進行兩種修改：<br><img src="/../images/20220811_8.png?200x200" alt="右上角的圖片4個色塊都小量更改; 右下圖片只修改一個色塊但修改較多"></p>
<p>則如果套用L2-norm，則兩種改法的距離差一樣，但是如果套用L-infinity，右下的距離會大幅大於右上</p>
<p>為了要瞞過人眼，應該是要讓每張圖的pixel都不會看起來變異過多，故此時應該採用L-infinity更符合實際需求。</p>
<hr>
<h1 id="Attack-approach"><a href="#Attack-approach" class="headerlink" title="Attack approach"></a>Attack approach</h1><p>要求出$x^*$的步驟</p>
<ol>
<li>首先，init parameters，可以直接從$x^0$開始</li>
<li>For t&#x3D;1 to T，做gradient descend，同訓練模型，此時暫時不考慮上面提到的constraints<br>$$<br>x^t \leftarrow x^{t-w}-\eta g<br>$$</li>
</ol>
<p><img src="/../images/20220811_9.png?100x100" alt="g的算法"></p>
<ol start="3">
<li>套回剛剛的限制：確認$x^*$與$x^0$差距小於$\epsilon$<br>$$<br>if\ d(x^0,x^t)&gt; \epsilon: \\\<br>\ \ \ x^t \leftarrow fix(x^t)<br>$$</li>
</ol>
<p>現今有很多種的attack method，但精神都不脫離現在的範例，不同的地方主要是</p>
<ul>
<li>optimization的方法</li>
<li>Constraints的設計不同</li>
</ul>
<hr>
<h1 id="Fast-Gradient-Sign-Method-FGSM"><a href="#Fast-Gradient-Sign-Method-FGSM" class="headerlink" title="Fast Gradient Sign Method(FGSM)"></a>Fast Gradient Sign Method(FGSM)</h1><ul>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1412.6572">相關論文</a></p>
</li>
<li><p>只更新一次參數</p>
</li>
<li><p>g裡面的元素只可能是+1,-1</p>
<ul>
<li>一樣做偏微分，但如果結果為正，輸出1，反之輸出-1</li>
</ul>
</li>
<li><p>根據$\epsilon$的不同，$x^1 &#x3D; x^0 - \epsilon g$</p>
</li>
<li><p>這麼做可以確保修正後的圖片可以達到限制的$\epsilon$極值的一個角落</p>
</li>
<li><p>可以嘗試多跑幾個iteration，但這樣有可能就不小心出界了，還需要套用剛剛的constraint，把出界的x拉回來</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/10/ML-2021-9-2-%E6%A9%9F%E5%99%A8%E5%BF%83%E4%B8%AD%E7%9A%84%E8%B2%93%E9%95%B7%E4%BB%80%E9%BA%BC%E6%A8%A3%E5%AD%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/10/ML-2021-9-2-%E6%A9%9F%E5%99%A8%E5%BF%83%E4%B8%AD%E7%9A%84%E8%B2%93%E9%95%B7%E4%BB%80%E9%BA%BC%E6%A8%A3%E5%AD%90/" class="post-title-link" itemprop="url">ML_2021_9-2 機器心中的貓長什麼樣子?</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-10 02:57:37" itemprop="dateCreated datePublished" datetime="2022-08-10T02:57:37+08:00">2022-08-10</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-11 19:32:45" itemprop="dateModified" datetime="2022-08-11T19:32:45+08:00">2022-08-11</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Global-explanation"><a href="#Global-explanation" class="headerlink" title="Global explanation"></a>Global explanation</h1><ul>
<li>「What does a cat(specific class) look like」</li>
<li>本課程以convolution network做圖片分類為例，講述各種global explainable approach</li>
</ul>
<h2 id="觀察各Convolution-layer中，filter關注什麼pattern"><a href="#觀察各Convolution-layer中，filter關注什麼pattern" class="headerlink" title="觀察各Convolution layer中，filter關注什麼pattern"></a>觀察各Convolution layer中，filter關注什麼pattern</h2><ul>
<li><p>假設給定一張特定圖片，則我們每次捲積，都會出現一個feature map</p>
<ul>
<li>觀察這個feature map，如果有某個filter裡面的值偏大，可以判定這張圖有某些pattern是由該filter分析</li>
</ul>
</li>
<li><p>不過現在我們不會知道要輸入什麼圖片，要怎麼知道該filter是注意在什麼pattern呢？ $\rightarrow$ 製造一張圖片X*</p>
</li>
<li><p>我們把X做為要學習的參數，作為模型的輸入，目標是要maximize該input在經過convolution以後，對應的filter的feature map的各元素值，算式如下<br>$$<br>X^* &#x3D; arg\ max_{X}\sum_i{\sum_j{a_{ij}}}<br>$$<br>其中，使右式最大的自訂圖片X稱為X* (gradient ascent)</p>
</li>
</ul>
<p><img src="/../images/20220811_1.png"><br>以數字辨識為例，這是每個filter想觀察的重點，可以發現有些filter著重注意橫線，有些filter在意協直線等等，看起來非常合理</p>
<h2 id="透過classifier-output觀察"><a href="#透過classifier-output觀察" class="headerlink" title="透過classifier output觀察"></a>透過classifier output觀察</h2><ul>
<li><p>找出一種輸入Ｘ，讓第i類別類別$y_i$的分數越高越好</p>
<ul>
<li>這種做法無用，只會看到一堆雜訊<br><img src="/../images/20220811_2.png"></li>
</ul>
</li>
<li><p>一種做法是，再加入一個分類器R，用於判定$X^*$到底有多像一個數字</p>
</li>
</ul>
<p>$$<br>X^* &#x3D; arg\ max_{X}\ y_i+R(X) \\\<br>R(X)&#x3D;-\sum_{i,j}|X_{ij}|<br>$$</p>
<p>這種作法很多需要regularization terms(Constraint)、hyperparameter tuning，並不簡單<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.06579">範例論文</a></p>
<h3 id="Constraint-from-generator"><a href="#Constraint-from-generator" class="headerlink" title="Constraint from generator"></a>Constraint from generator</h3><ul>
<li>train 一個image generator，輸入z以後輸出一個圖片，再把這個圖片丟入image classifier，找出能讓$y_i$最大的值$z^*$<br><img src="/../images/20220811_3.png"><br>$$<br>z^* &#x3D; arg\ max_{z}\ y_i+R(X) \\\<br>R(X)&#x3D;-\sum_{i,j}|X_{ij}|<br>$$</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1612.00005">範例論文</a></p>
<p>找出z以後，則我們可以透過Generator來告訴大家，我們所產生的這些圖片會讓電腦容易辨認成這個class</p>
<blockquote>
<p>電腦真實想法或許不重要，但希望有辦法可以讓解讀出來的東西可以說服人類</p>
</blockquote>
<h2 id="透過仿作一個類似成效的簡易model來解釋"><a href="#透過仿作一個類似成效的簡易model來解釋" class="headerlink" title="透過仿作一個類似成效的簡易model來解釋"></a>透過仿作一個類似成效的簡易model來解釋</h2><p><img src="/../images/20220811_4.png"></p>
<p>問題是，簡易的模型如何能模仿neural network的決策？<br>$\rightarrow$ 只模仿一部分區域的行為</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://youtu.be/K1mWgthGS-A">LIME(Local Interpretable Model-agnostoc Explanations)</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/09/ML-2021-9-1-%E7%82%BA%E4%BB%80%E9%BA%BC%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E5%8F%AF%E4%BB%A5%E6%AD%A3%E7%A2%BA%E5%88%86%E8%BE%A8%E5%AF%B6%E5%8F%AF%E5%A4%A2%E5%92%8C%E6%95%B8%E7%A2%BC%E5%AF%B6%E8%B2%9D%E5%91%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/09/ML-2021-9-1-%E7%82%BA%E4%BB%80%E9%BA%BC%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E5%8F%AF%E4%BB%A5%E6%AD%A3%E7%A2%BA%E5%88%86%E8%BE%A8%E5%AF%B6%E5%8F%AF%E5%A4%A2%E5%92%8C%E6%95%B8%E7%A2%BC%E5%AF%B6%E8%B2%9D%E5%91%A2/" class="post-title-link" itemprop="url">ML_2021_9-1 為什麼類神經網路可以正確分辨寶可夢和數碼寶貝呢?</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-09 14:46:25" itemprop="dateCreated datePublished" datetime="2022-08-09T14:46:25+08:00">2022-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-10 02:52:35" itemprop="dateModified" datetime="2022-08-10T02:52:35+08:00">2022-08-10</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Correct answers !&#x3D; Intelligent</p>
<h1 id="Why-we-need-explainable-ML"><a href="#Why-we-need-explainable-ML" class="headerlink" title="Why we need explainable ML"></a>Why we need explainable ML</h1><ol>
<li>對現實決策的解釋性</li>
</ol>
<ul>
<li><p>如果銀行利用機器學習來做是否貸款的判斷，則法律規定機器學習必須給出拒絕&#x2F;同意貸款的理由</p>
</li>
<li><p>醫療、法律、自駕車、金融等等領域，不滿足於機器學習的黑箱</p>
</li>
</ul>
<ol start="2">
<li>可以更好的去調整Model</li>
</ol>
<h1 id="Interpretable-v-s-Powerful"><a href="#Interpretable-v-s-Powerful" class="headerlink" title="Interpretable v.s Powerful"></a>Interpretable v.s Powerful</h1><p>Linear model能力差，但是他容易解釋</p>
<p>Deep networks雖然強大，卻無法被解釋</p>
<p>與其侷限只用linear model，不如學著讓深度模型可以被解釋</p>
<ul>
<li>How about decision tree?<ul>
<li>Decision tree can be terrible<br>    - 通常會用的都是random forest，而非單一一棵decision tree</li>
</ul>
</li>
</ul>
<h1 id="Goal-of-Explainable-ML"><a href="#Goal-of-Explainable-ML" class="headerlink" title="Goal of Explainable ML"></a>Goal of Explainable ML</h1><ul>
<li>判准不好定義，以下是老師個人界定</li>
</ul>
<p>人腦也是黑盒子，但我們卻可以相信人的決斷<br>相關心理學實驗：<a target="_blank" rel="noopener" href="https://jamesclear.com/wp-content/uploads/2015/03/copy-machine-study-ellen-langer.pdf">印表機</a></p>
<p>很多時候人們只是想要一個可以說服他們的理由，所以所謂的Explainable ML其實就是模型的決斷可以給出一個說服老闆、客戶、你自己的一種理由</p>
<h1 id="Explainable-ML的兩大類"><a href="#Explainable-ML的兩大類" class="headerlink" title="Explainable ML的兩大類"></a>Explainable ML的兩大類</h1><p>問在甚麼情況下會這樣分類 (“你覺得貓看起來像如何”)</p>
<ul>
<li>Local explanation</li>
<li>Global explanation</li>
</ul>
<h2 id="Local-explanation"><a href="#Local-explanation" class="headerlink" title="Local explanation"></a>Local explanation</h2><p>根據一個圖片(data)來問問題 (“為何圖片是一隻貓”)</p>
<ul>
<li><strong>要找出一個data的哪個component對於機器的分類至關重要</strong><ul>
<li>一種做法是：遮蓋資料的不同部分，看是否會影響機器的預測結果<br><img src="/../images/20220809_7.png"></li>
</ul>
</li>
</ul>
<h3 id="另一種作法：Saliency-map"><a href="#另一種作法：Saliency-map" class="headerlink" title="另一種作法：Saliency map"></a>另一種作法：Saliency map</h3><p>針對各維的weight，加上$\Delta x$，看這樣損失函數值e的變化量為何 (|$\frac{\Delta e}{\Delta x}$|)</p>
<p>(其實就是|$\frac{\partial e}{\partial x_n}$|)</p>
<p>以圖片為例，可以得出下圖結果，此圖稱為<strong>saliency map</strong>(像素越白表示重要性越高)<br><img src="/../images/20220809_8.png"></p>
<p>但是Saliency也有限制，會碰到的問題與解決方式如下：</p>
<ol>
<li>Noisy Gradient：資料的判別依據混入了雜訊 -&gt; SmoothGrad</li>
<li>Gradient Saturation：可能一張圖片的特徵已經足以明顯，再對這個明顯的特徵做偏微分以後，e的變化性依然不大，則可能會誤判這個特徵點不重要 -&gt; 有替代的做法稱為「Integrated gradient(IG)」，相關文獻：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.02639">https://arxiv.org/abs/1611.02639</a><br>ex: 大象鼻子長度作為判別是否為大象<br><img src="/../images/20220809_10.png"></li>
</ol>
<h3 id="SmoothGrad"><a href="#SmoothGrad" class="headerlink" title="SmoothGrad"></a>SmoothGrad</h3><p>這個技術就是把原始的圖片輸入隨機加入一些雜訊並分別計算他們的Saliency map再取平均，真正重要的部位就會被凸顯出來<br><img src="/../images/20220809_9.png"></p>
<hr>
<h1 id="機器如何處理輸入"><a href="#機器如何處理輸入" class="headerlink" title="機器如何處理輸入"></a>機器如何處理輸入</h1><p>前面主要都在說機器如何找出一個輸入的重要部分</p>
<p>現在要探討的則是機器如何去處理這個輸入的</p>
<h2 id="Visualization：具現化用肉眼觀察"><a href="#Visualization：具現化用肉眼觀察" class="headerlink" title="Visualization：具現化用肉眼觀察"></a>Visualization：具現化用肉眼觀察</h2><pre><code>- 直接去看neuron、attention的輸出是甚麼。雖然輸出的維度很高，但是可以透過一些方法(PCA、t-SNE等等)壓縮成二維並顯示出來
</code></pre>
<p>以作業2為例解釋<br><img src="/../images/20220809_11.png"><br>透過觀察被壓縮後的結果，我們可以看出一些特性</p>
<p><img src="/../images/20220809_12.png"><br>比如範例中的model某層輸出，可以看出機器可以看的出不同人所說的同樣內容，並把他們align在一起</p>
<p>關於attention可否被解釋，有諸多論戰</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1902.10186">Attention is not Explanation</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.04626">Attention is not not Explanation</a></li>
</ul>
<h2 id="Probing：用探針插入network來觀察發生甚麼事"><a href="#Probing：用探針插入network來觀察發生甚麼事" class="headerlink" title="Probing：用探針插入network來觀察發生甚麼事"></a>Probing：用探針插入network來觀察發生甚麼事</h2><p>訓練一個classifier，將embedding丟進去，讓classifier試圖去訓練是否可以分類出想要的資訊<br><img src="/../images/pasted-46.png"></p>
<p>注意，probing仍會失誤，不可太快下定論(ex. 分類模型練壞等等)</p>
<ul>
<li>一種probing應用的範例：<br>用作業二(語者辨識)的範例，可以把特定layer的輸出embedding丟入TTS模型，讓TTS模型想辦法還原原始的輸入。</li>
</ul>
<p>若TTS無法完整的還原某塊部分(如.語者資訊)，則可以知道這個network有學到抹去語者的資訊，只保留語音內容。</p>
<h2 id="另一個probing例子"><a href="#另一個probing例子" class="headerlink" title="另一個probing例子"></a>另一個probing例子</h2><ul>
<li>是李老師的論文</li>
</ul>
<p><img src="/../images/20220809_13.png" alt="upload successful"><br>  - <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1911.01102">論文連結</a></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=6gtn7H-pWr8">相關發表</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/09/ML-2021-8-2-%E9%A0%98%E7%B5%90%E8%AE%8A%E8%81%B2%E5%99%A8%E8%88%87%E6%9B%B4%E5%A4%9A%E6%87%89%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/09/ML-2021-8-2-%E9%A0%98%E7%B5%90%E8%AE%8A%E8%81%B2%E5%99%A8%E8%88%87%E6%9B%B4%E5%A4%9A%E6%87%89%E7%94%A8/" class="post-title-link" itemprop="url">ML_2021_8-2 領結變聲器與更多應用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>
      

      <time title="創建時間：2022-08-09 03:22:28 / 修改時間：14:45:29" itemprop="dateCreated datePublished" datetime="2022-08-09T03:22:28+08:00">2022-08-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Feature-Disentanglement"><a href="#Feature-Disentanglement" class="headerlink" title="Feature Disentanglement"></a>Feature Disentanglement</h1><ul>
<li><p>有沒有可能可以知道embedding vector中，各維所儲存的資訊呢？</p>
</li>
<li><p>Feature disentanglement旨在找出各維的內容，且有辦法做到</p>
<ul>
<li>非本課內容，只列參考</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.05742">https://arxiv.org/abs/1904.05742</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.02812">https://arxiv.org/abs/1804.02812</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.05879">https://arxiv.org/abs/1905.05879</a></li>
</ul>
</li>
</ul>
<h2 id="Feature-Disentanglement-應用"><a href="#Feature-Disentanglement-應用" class="headerlink" title="Feature Disentanglement 應用"></a>Feature Disentanglement 應用</h2><p><em>假如我們能知道embedding各維所代表的意涵，我們能用它做寫甚麼？</em></p>
<h3 id="Voice-Conversion"><a href="#Voice-Conversion" class="headerlink" title="Voice Conversion"></a>Voice Conversion</h3><ul>
<li><p>ex.柯南的領結變聲器</p>
</li>
<li><p>如果要A人聲轉成B人聲，一般需要A,B都念一樣的句子</p>
</li>
<li><p>透過feature disentanglement技術，可以讓A,B不必一定要說一樣的話</p>
<ul>
<li>我們知道哪些維度代表說話者的特徵，則我們可以只擷取這段維度，丟入decoder<br><img src="/../images/20220809_1.png"></li>
</ul>
</li>
</ul>
<p>    </p>
<h1 id="Discrete-Latent-Representation"><a href="#Discrete-Latent-Representation" class="headerlink" title="Discrete Latent Representation"></a>Discrete Latent Representation</h1><ul>
<li><p>embedding的各維可以不一定是real numbers，它可以是binary，甚至是one-hot</p>
</li>
<li><p>把embedding做這樣的格式可以更容易做feature disentanglement</p>
</li>
</ul>
<h2 id="Example：VQVAE"><a href="#Example：VQVAE" class="headerlink" title="Example：VQVAE"></a>Example：VQVAE</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.00937">論文連結</a></li>
</ul>
<p>會準備一個code book，將embedding跟這裏面的vectors計算相似度，取出相似度最高的那個vector，丟入decoder，範例如下圖</p>
<p><img src="/../images/20220809_2.png"></p>
<p>這樣的過程其實有點像self-attention。encoder的輸出類比於self-attention裡面的query，而code book的vectors則像是key</p>
<ul>
<li>這樣表示decoder的輸入可能性只有codebook裡面的向量數量，讓輸出變成離散的</li>
</ul>
<h2 id="Text-as-Representation"><a href="#Text-as-Representation" class="headerlink" title="Text as Representation"></a>Text as Representation</h2><ul>
<li>Representation &#x3D; embedding</li>
<li>有沒有可能讓embedding不要是向量，而是人們看得懂的文字呢？</li>
</ul>
<p><img src="/../images/20220809_4.png"><br>範例：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.02851">https://arxiv.org/abs/1810.02851</a></p>
<ul>
<li><p>在這個範例下，輸入跟輸出都是seq，所以model會需要是一個seq2seq的類型</p>
<ul>
<li>這也是一種transformer</li>
</ul>
</li>
<li><p>這類做法也稱為seq2seq2seq auto-encoder (中間也是文字)</p>
</li>
</ul>
<h3 id="embedding的可讀性"><a href="#embedding的可讀性" class="headerlink" title="embedding的可讀性"></a>embedding的可讀性</h3><ul>
<li>若我們要取的任務是取得文章摘要，有沒有可能輸出的embedding其實就是summary呢？<ul>
<li><p>行不通。實務上encoder跟decoder之間會發明一個暗號，人類看不懂embedding的輸出，但是decoder卻能正常還原</p>
</li>
<li><p>一種解決方法就是套用GAN的概念，加入discriminator，讓embedding跟真人寫得summary做比較，而embedding則必須騙過discriminator</p>
</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220809_5.png"><br>沒錯 看起來又很像cycle GAN了<br>encoder、decoder就是generator，上面的則是discriminator</p>
<h2 id="Tree-as-representation"><a href="#Tree-as-representation" class="headerlink" title="Tree as representation"></a>Tree as representation</h2><p>本課不細講，相關參考如下</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1806.07832">https://arxiv.org/abs/1806.07832</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.03746">https://arxiv.org/abs/1904.03746</a></li>
</ul>
<h1 id="More-Applications"><a href="#More-Applications" class="headerlink" title="More Applications"></a>More Applications</h1><h2 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h2><ul>
<li><p>若把decoder單獨拆出來，也可以看作是一個generator</p>
</li>
<li><p>decoder經過一段修正，就是variational auto-encoder (VAE)</p>
</li>
</ul>
<h2 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h2><ul>
<li>auto-encoder也可以看作是一種壓縮，把一個圖片丟入encoder，並且儲存embedding<ul>
<li>decoder的還原動作則是”decompression”，不過這樣還原出來的圖片會有失真</li>
</ul>
</li>
</ul>
<h2 id="Anomaly-Detection-異常檢測"><a href="#Anomaly-Detection-異常檢測" class="headerlink" title="Anomaly Detection (異常檢測)"></a>Anomaly Detection (異常檢測)</h2><p><em>本次作業內容</em></p>
<p>給定一個資料集{$x^1,x^2,…,x^N$}，並且判斷輸入x與資料集是否相似<br><img src="/../images/20220809_6.png"></p>
<p>異常檢測的相關應用：</p>
<ul>
<li><p>信用卡交易詐欺檢測 (交易行為是否異常)</p>
</li>
<li><p>網路侵入偵測 (連線行為是否異常)</p>
</li>
<li><p>癌症偵測 (細胞是否變異)</p>
</li>
<li><p>那異常檢測是否就是一種二元分類問題呢？</p>
<ul>
<li>這種問題的難點就是在蒐集資料，異常資料不易蒐集</li>
<li>這類問題假設我們只有正常的訓練資料(其中一種class)，而沒有異常訓練資料，稱為”One class分類問題”</li>
</ul>
</li>
<li><p>解決One class classification問題，就會需要auto-encoder</p>
<ul>
<li>正常資料由於有學習過，所以可以有效還原<br>    - 但如果出現了異常資料，decoder會難以還原，若發現decoder的輸出與原始輸入相似度低(large reconstruction loss)，則可以判斷它就是anomaly的資料</li>
</ul>
</li>
</ul>
<p>auto-encoder只是anomaly detection的一種approach，更多的異常檢測任務解法可以參考其它年的課程</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/08/ML-2021-8-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/08/ML-2021-8-1-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/" class="post-title-link" itemprop="url">ML_2021_8-1 基本概念</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-08 23:58:36" itemprop="dateCreated datePublished" datetime="2022-08-08T23:58:36+08:00">2022-08-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-09 03:21:25" itemprop="dateModified" datetime="2022-08-09T03:21:25+08:00">2022-08-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><p>也不用label data就可以做pretrain -&gt; 算是一種self-supervised learning</p>
</li>
<li><p>出現在2006年，是很老的模型</p>
</li>
</ul>
<h1 id="Auto-encoder-模型"><a href="#Auto-encoder-模型" class="headerlink" title="Auto-encoder 模型"></a>Auto-encoder 模型</h1><p><img src="/../images/20220808_2.png"><br>Auto-encoder也有encoder、decoder的兩層network，輸入會是一張unlabeled的圖片，經過encoder以後變成向量，再透過decoder變回一張圖片</p>
<ul>
<li><p>訓練的目標是希望decoder輸出的圖與原圖越像越好(距離越近越好)</p>
<ul>
<li>又稱為reconstruction</li>
</ul>
</li>
<li><p>很像Cycle GAN中，2個generator之間的關係</p>
</li>
<li><p>關於中間的vector，有很多別稱</p>
<ul>
<li>Embedding, Representation, Code</li>
</ul>
</li>
<li><p>auto-encoder的encoder通常輸入是為度很高的向量，而中介的vector則是維度低很多的向量，故可用於壓縮</p>
<ul>
<li>具備壓縮的功能<br>    - encoder的輸出也叫做bottleneck<br>    - 這樣降維的技術稱為「dimention reduction」</li>
</ul>
</li>
</ul>
<h1 id="Why-auto-encoder"><a href="#Why-auto-encoder" class="headerlink" title="Why auto-encoder"></a>Why auto-encoder</h1><ul>
<li>為何有辦法讓低維度向量變成一個圖片呢?<ul>
<li>圖片的變化有限，把變化的可能性記下來，就可以把一個複雜的圖片用簡單的方式記錄下來</li>
</ul>
</li>
</ul>
<h2 id="變形：De-noising-auto-encode"><a href="#變形：De-noising-auto-encode" class="headerlink" title="變形：De-noising auto-encode"></a>變形：De-noising auto-encode</h2><ul>
<li><p>也不是多新的技術(2008)</p>
</li>
<li><p>把輸入的圖片先隨便加入一些雜訊，但是要decoder還原加入雜訊之前的結果</p>
<ul>
<li>auto-encoder必須自己學會把雜訊去除</li>
</ul>
</li>
<li><p>這個idea其實跟現今的BERT很像(填空)</p>
</li>
</ul>
<p><img src="/../images/20220808_3.png"></p>
<ul>
<li>BERT又可看作一個de-noising auto-encoder<ul>
<li>BERT的decoder不一定是linear。 廣義來看，可以把BERT切開，比如一個BERT前6層是encoder，後6層+linear layer是decoder</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">劉宇承</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
