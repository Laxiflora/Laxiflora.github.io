<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"laxiflora.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="芝麻街家族與模型有很多關聯  BERT有340M個parameters，非常巨大  下面課程主要講BERT與GPT系列  BERT 就是transformer encoder     BERT learning techniqueSemi-supervised?- BERT用在下游任務需要labeled data做一些fine-tune，是supervised learning - BERT p">
<meta property="og:type" content="article">
<meta property="og:title" content="ML_2021_X-1&amp;X-2 BERT簡介">
<meta property="og:url" content="https://laxiflora.github.io/2022/07/30/ML-2021-X-1-X-2-BERT%E7%B0%A1%E4%BB%8B/index.html">
<meta property="og:site_name" content="laxiflora的小天地">
<meta property="og:description" content="芝麻街家族與模型有很多關聯  BERT有340M個parameters，非常巨大  下面課程主要講BERT與GPT系列  BERT 就是transformer encoder     BERT learning techniqueSemi-supervised?- BERT用在下游任務需要labeled data做一些fine-tune，是supervised learning - BERT p">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://laxiflora.github.io/images/20220730_1.png">
<meta property="og:image" content="https://laxiflora.github.io/images/pasted-44.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_1.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_2.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_3.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_4.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_5.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_6.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220802_7.png">
<meta property="article:published_time" content="2022-07-30T08:23:44.000Z">
<meta property="article:modified_time" content="2022-08-09T08:58:50.421Z">
<meta property="article:author" content="劉宇承">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://laxiflora.github.io/images/20220730_1.png">


<link rel="canonical" href="https://laxiflora.github.io/2022/07/30/ML-2021-X-1-X-2-BERT%E7%B0%A1%E4%BB%8B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://laxiflora.github.io/2022/07/30/ML-2021-X-1-X-2-BERT%E7%B0%A1%E4%BB%8B/","path":"2022/07/30/ML-2021-X-1-X-2-BERT簡介/","title":"ML_2021_X-1&X-2 BERT簡介"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ML_2021_X-1&X-2 BERT簡介 | laxiflora的小天地</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">laxiflora的小天地</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">前進軟體工程師的練功之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#BERT-learning-technique"><span class="nav-number">1.</span> <span class="nav-text">BERT learning technique</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Semi-supervised"><span class="nav-number">1.1.</span> <span class="nav-text">Semi-supervised?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Self-supervised"><span class="nav-number">1.2.</span> <span class="nav-text">Self-supervised?</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Pretrain-Self-supervised-learning"><span class="nav-number">2.</span> <span class="nav-text">Pretrain(Self-supervised learning)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pretrain%E4%BB%BB%E5%8B%991%EF%BC%9Amasking-input"><span class="nav-number">2.0.1.</span> <span class="nav-text">Pretrain任務1：masking input</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pretrain%E4%BB%BB%E5%8B%992%EF%BC%9ANext-sentence-prediction"><span class="nav-number">2.0.2.</span> <span class="nav-text">Pretrain任務2：Next sentence prediction</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#How-to-use-BERT"><span class="nav-number">2.1.</span> <span class="nav-text">How to use BERT</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BERT-%E8%A1%A8%E7%8F%BEin-GLUE"><span class="nav-number">2.2.</span> <span class="nav-text">BERT 表現in GLUE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BERT%E5%AF%A6%E5%8B%99"><span class="nav-number">2.3.</span> <span class="nav-text">BERT實務</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-1"><span class="nav-number">2.3.1.</span> <span class="nav-text">Case 1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-2"><span class="nav-number">2.3.2.</span> <span class="nav-text">Case 2</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-3"><span class="nav-number">2.3.3.</span> <span class="nav-text">Case 3</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-4-%E4%BD%9C%E6%A5%AD7"><span class="nav-number">2.3.4.</span> <span class="nav-text">Case 4 (作業7)</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Training-BERT-is-challenging"><span class="nav-number">2.4.</span> <span class="nav-text">Training BERT is challenging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A6%82%E6%9E%9C%E4%BB%8A%E5%A4%A9%E8%A6%81%E8%A7%A3%E7%9A%84%E4%BB%BB%E5%8B%99%E6%98%AFseq2seq%E5%91%A2"><span class="nav-number">2.5.</span> <span class="nav-text">如果今天要解的任務是seq2seq呢</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">劉宇承</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/30/ML-2021-X-1-X-2-BERT%E7%B0%A1%E4%BB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ML_2021_X-1&X-2 BERT簡介 | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML_2021_X-1&X-2 BERT簡介
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-30 16:23:44" itemprop="dateCreated datePublished" datetime="2022-07-30T16:23:44+08:00">2022-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-09 16:58:50" itemprop="dateModified" datetime="2022-08-09T16:58:50+08:00">2022-08-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <ul>
<li><p>芝麻街家族與模型有很多關聯<br><img src="/../images/20220730_1.png"></p>
</li>
<li><p>BERT有340M個parameters，非常巨大</p>
</li>
<li><p>下面課程主要講BERT與GPT系列</p>
<blockquote>
<p>BERT 就是transformer encoder</p>
</blockquote>
</li>
</ul>
<hr>
<h1 id="BERT-learning-technique"><a href="#BERT-learning-technique" class="headerlink" title="BERT learning technique"></a>BERT learning technique</h1><h2 id="Semi-supervised"><a href="#Semi-supervised" class="headerlink" title="Semi-supervised?"></a>Semi-supervised?</h2><pre><code>- BERT用在下游任務需要labeled data做一些fine-tune，是supervised learning
- BERT pretrain過程卻不需要labeled data，是unsupervised learning
</code></pre>
<p>$\rightarrow$ 所以合起來稱為semi-supervised</p>
<h2 id="Self-supervised"><a href="#Self-supervised" class="headerlink" title="Self-supervised?"></a>Self-supervised?</h2><ul>
<li>雖然是supervised learning，但是卻不需要人工標記，這種方法將訓練資料本身作為label</li>
<li>我們會切割一部分的資料x’作為輸入，一部分的資料x’’則做為label<ul>
<li>在沒有資料的情況下，自己想辦法supervised (故在人工方面可以看做是一種unsupervised)</li>
</ul>
</li>
<li>BERT的pretrain任務，就是self-supervised learning</li>
</ul>
<h1 id="Pretrain-Self-supervised-learning"><a href="#Pretrain-Self-supervised-learning" class="headerlink" title="Pretrain(Self-supervised learning)"></a>Pretrain(Self-supervised learning)</h1><ul>
<li></li>
<li>不同於supervised，self-supervised的資料沒有標註，我們會切割一部分的資料x’作為輸入，一部分的資料x’’則做為label<ul>
<li>在沒有資料的情況下，自己想辦法supervised (是一種unsupervised)</li>
</ul>
</li>
</ul>
<h3 id="Pretrain任務1：masking-input"><a href="#Pretrain任務1：masking-input" class="headerlink" title="Pretrain任務1：masking input"></a>Pretrain任務1：masking input</h3><pre><code>- 會隨機把input sequence中隨機一個vector蓋掉，稱為masking input，然後讓BERT去訓練猜中原本蓋掉的詞(token)是甚麼
- mask / random
- 很像分類問題，類別量 = token總數
- BERT出來會有一個linear的matrix，做完softmax以後輸出  
</code></pre>
<p><img src="/../images/pasted-44.png"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">reference</a></li>
</ul>
<h3 id="Pretrain任務2：Next-sentence-prediction"><a href="#Pretrain任務2：Next-sentence-prediction" class="headerlink" title="Pretrain任務2：Next sentence prediction"></a>Pretrain任務2：Next sentence prediction</h3><pre><code>- 任取兩個sequence，在開頭跟句子之間加入分隔符號
</code></pre>
<p>    - BERT要訓練去辨認這兩個例子是否相接<br>    - 這招不是很有效，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.11692">Robustly optimized BERT approach</a><br>    	- 一種可能是這個任務過於簡單</p>
<ul>
<li>另外一招：sentence order prediction(SOP)<ul>
<li>2句子本來就接在一起但亂序，要分辨誰是前面誰是後面</li>
<li>在<a target="_blank" rel="noopener" href="https://arxiv.org/avs/1909.11942">ALBERT</a>中使用</li>
</ul>
</li>
</ul>
<h2 id="How-to-use-BERT"><a href="#How-to-use-BERT" class="headerlink" title="How to use BERT"></a>How to use BERT</h2><ul>
<li>BERT雖然只做上述兩個訓練，但【卻可以使用在不同的任務上面 (downstream tasks)】<ul>
<li>針對不同任務，BERT仍需要做一點微調(一些些的labeled data)，稱為<b><em>Fine-Tune</em></b></li>
</ul>
</li>
<li>我們會讓BERT去做各種任務(任務集)取各種任務的成績以後平均<ul>
<li>一個訓練的集合：<a target="_blank" rel="noopener" href="https://gluebenchmark.com/">general Language Understanding Evaluation(GLUE)</a></li>
</ul>
</li>
</ul>
<h2 id="BERT-表現in-GLUE"><a href="#BERT-表現in-GLUE" class="headerlink" title="BERT 表現in GLUE"></a>BERT 表現in GLUE</h2><p><img src="/../images/20220802_1.png"></p>
<ul>
<li>1.0的基準線是人類的成績(指標不一定是正確率)</li>
</ul>
<h2 id="BERT實務"><a href="#BERT實務" class="headerlink" title="BERT實務"></a>BERT實務</h2><h3 id="Case-1"><a href="#Case-1" class="headerlink" title="Case 1"></a>Case 1</h3><ul>
<li>輸入一個sequence，輸出一個class (ex. sentiment analysis)<br><img src="/../images/20220802_2.png"></li>
<li>使用pretrained data後，BERT的參數已經被初始化了(一個會做填空題的BERT)，而線性層則是仍然要隨機初始化</li>
</ul>
<h3 id="Case-2"><a href="#Case-2" class="headerlink" title="Case 2"></a>Case 2</h3><ul>
<li><p>輸入一個sequence，輸出一樣長度的sequence (詞性標註 POS tagging)<br><img src="/../images/20220802_3.png"></p>
</li>
<li><p>處理過程同case 1</p>
</li>
</ul>
<h3 id="Case-3"><a href="#Case-3" class="headerlink" title="Case 3"></a>Case 3</h3><ul>
<li>輸入兩個句子，輸出一個類別 (NLI)<ul>
<li>NLI : 從前提要能推出假設</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220802_4.png"></p>
<h3 id="Case-4-作業7"><a href="#Case-4-作業7" class="headerlink" title="Case 4 (作業7)"></a>Case 4 (作業7)</h3><ul>
<li>問答系統：給機器讀文章，問他問題要能回應</li>
<li>但是機器只能從文章中給出答案(抓取文章的特定序列)<ul>
<li>輸出兩個正整數</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220802_5.png"></p>
<ul>
<li><p>輸入的形狀跟case 3很像，只是後面改成文章，前面改成問題<br><img src="/../images/20220802_6.png"></p>
</li>
<li><p>黃色向量輸出分別對橘、藍vector做內積，然後過softmax</p>
</li>
<li><p>答案會是($d_i,d_j)$，其中i來自橘色，j來自藍色</p>
</li>
</ul>
<h2 id="Training-BERT-is-challenging"><a href="#Training-BERT-is-challenging" class="headerlink" title="Training BERT is challenging"></a>Training BERT is challenging</h2><ul>
<li><p>google訓練最早的BERT的時候用了3 billions words</p>
</li>
<li><p>訓練非常花時間，但是微調很快(colab GPU約1 hr)</p>
</li>
<li><p>既然BERT都已經被訓練過了，為何還會有人想要重新訓練他?</p>
<ul>
<li>實際上訓練BERT的過程中，BERT到底學到了甚麼仍有待研究<br>    - 為了<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.02480">學習BERT的胚胎學</a>，所以會需要重新訓練</li>
</ul>
</li>
</ul>
<h2 id="如果今天要解的任務是seq2seq呢"><a href="#如果今天要解的任務是seq2seq呢" class="headerlink" title="如果今天要解的任務是seq2seq呢"></a>如果今天要解的任務是seq2seq呢</h2><ul>
<li><p>BERT只有pretrain encoder，有沒有辦法pretrain decoder？ 可以。</p>
</li>
<li><p>Encoder看到corrupted的data，decoder則是要想辦法把他還原</p>
<ul>
<li>弄壞資料的方法：旋轉、空白、mask…<br><img src="/../images/20220802_7.png"></li>
</ul>
</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/07/29/ML-2021-6-4-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E5%9B%9B-%E2%80%93-Cycle-GAN/" rel="prev" title="ML_2021_6-4 生成式對抗網路(四) – Cycle GAN">
                  <i class="fa fa-chevron-left"></i> ML_2021_6-4 生成式對抗網路(四) – Cycle GAN
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/08/03/ML-2021-X-3-BERT%E7%9A%84%E5%A5%87%E8%81%9E%E8%BB%BC%E4%BA%8B/" rel="next" title="ML_2021_X-3 BERT的奇聞軼事">
                  ML_2021_X-3 BERT的奇聞軼事 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">劉宇承</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
