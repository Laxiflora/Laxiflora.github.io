<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"laxiflora.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="作業題目 可進行的目標Data augmentation (training) 搜尋torchvision.transform，docs  有用的文章：Pytorch提供之torchvision data augmentation技巧  transform.randomRotate   ,   resize等等  最後必須要toTensor，model只吃pytorch的tensor不吃PIL l">
<meta property="og:type" content="article">
<meta property="og:title" content="ML_LEE_2022_hw3">
<meta property="og:url" content="https://laxiflora.github.io/2022/07/11/ML-LEE-2022-hw3/index.html">
<meta property="og:site_name" content="laxiflora的小天地">
<meta property="og:description" content="作業題目 可進行的目標Data augmentation (training) 搜尋torchvision.transform，docs  有用的文章：Pytorch提供之torchvision data augmentation技巧  transform.randomRotate   ,   resize等等  最後必須要toTensor，model只吃pytorch的tensor不吃PIL l">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="https://laxiflora.github.io/images/20220711_1.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220711_2.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220711_3.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220712_4.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220712_1.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220712_2.png">
<meta property="og:image" content="https://laxiflora.github.io/images/20220712_3.png">
<meta property="article:published_time" content="2022-07-11T13:24:56.000Z">
<meta property="article:modified_time" content="2022-08-08T12:10:07.961Z">
<meta property="article:author" content="劉宇承">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://laxiflora.github.io/images/20220711_1.png">


<link rel="canonical" href="https://laxiflora.github.io/2022/07/11/ML-LEE-2022-hw3/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://laxiflora.github.io/2022/07/11/ML-LEE-2022-hw3/","path":"2022/07/11/ML-LEE-2022-hw3/","title":"ML_LEE_2022_hw3"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>ML_LEE_2022_hw3 | laxiflora的小天地</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">laxiflora的小天地</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">前進軟體工程師的練功之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%AF%E9%80%B2%E8%A1%8C%E7%9A%84%E7%9B%AE%E6%A8%99"><span class="nav-number">1.</span> <span class="nav-text">可進行的目標</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-augmentation-training"><span class="nav-number">1.1.</span> <span class="nav-text">Data augmentation (training)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Adv-Data-augmentation-mixed-up-training"><span class="nav-number">1.2.</span> <span class="nav-text">Adv. Data augmentation - mixed up (training)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Module-selection-%E6%90%9C%E5%B0%8Btorchvision-models"><span class="nav-number">1.3.</span> <span class="nav-text">Module selection (搜尋torchvision.models)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cross-validation"><span class="nav-number">1.4.</span> <span class="nav-text">Cross validation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#First-Approach"><span class="nav-number">2.</span> <span class="nav-text">First Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-argumentation"><span class="nav-number">2.1.</span> <span class="nav-text">Data argumentation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Module-selection"><span class="nav-number">2.2.</span> <span class="nav-text">Module selection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Result"><span class="nav-number">2.3.</span> <span class="nav-text">Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Second-Approach"><span class="nav-number">3.</span> <span class="nav-text">Second Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Module-Selection"><span class="nav-number">3.1.</span> <span class="nav-text">Module Selection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Result-1"><span class="nav-number">3.2.</span> <span class="nav-text">Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Third-Approach"><span class="nav-number">4.</span> <span class="nav-text">Third Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transform"><span class="nav-number">4.1.</span> <span class="nav-text">Transform</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Result-2"><span class="nav-number">4.2.</span> <span class="nav-text">Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Forth-Approach"><span class="nav-number">5.</span> <span class="nav-text">Forth Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transform-1"><span class="nav-number">5.1.</span> <span class="nav-text">Transform</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BatchSize"><span class="nav-number">5.2.</span> <span class="nav-text">BatchSize</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Result-3"><span class="nav-number">5.3.</span> <span class="nav-text">Result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Fifth-Approach"><span class="nav-number">6.</span> <span class="nav-text">Fifth Approach</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Result-Finale"><span class="nav-number">6.1.</span> <span class="nav-text">Result (Finale)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E7%B5%82%E6%88%90%E6%9E%9C"><span class="nav-number">6.2.</span> <span class="nav-text">最終成果</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BF%83%E5%BE%97"><span class="nav-number">7.</span> <span class="nav-text">心得</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">劉宇承</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/11/ML-LEE-2022-hw3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="ML_LEE_2022_hw3 | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          ML_LEE_2022_hw3
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-11 21:24:56" itemprop="dateCreated datePublished" datetime="2022-07-11T21:24:56+08:00">2022-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/ml2022spring-hw3b">作業題目</a></p>
<h1 id="可進行的目標"><a href="#可進行的目標" class="headerlink" title="可進行的目標"></a>可進行的目標</h1><h2 id="Data-augmentation-training"><a href="#Data-augmentation-training" class="headerlink" title="Data augmentation (training)"></a>Data augmentation (training)</h2><ul>
<li><p>搜尋torchvision.transform，<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">docs</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://chih-sheng-huang821.medium.com/03-pytorch-dataaug-a712a7a7f55e">有用的文章：Pytorch提供之torchvision data augmentation技巧</a></p>
</li>
<li><p>transform.randomRotate   ,   resize等等</p>
</li>
<li><p>最後必須要toTensor，model只吃pytorch的tensor不吃PIL library的</p>
</li>
</ul>
<h2 id="Adv-Data-augmentation-mixed-up-training"><a href="#Adv-Data-augmentation-mixed-up-training" class="headerlink" title="Adv. Data augmentation - mixed up (training)"></a>Adv. Data augmentation - mixed up (training)</h2><ul>
<li><p>mixup (把兩個影像混再一起，變成多重label)</p>
</li>
<li><p>cross entropy loss function需要重寫</p>
</li>
</ul>
<h2 id="Module-selection-搜尋torchvision-models"><a href="#Module-selection-搜尋torchvision-models" class="headerlink" title="Module selection (搜尋torchvision.models)"></a>Module selection (搜尋torchvision.models)</h2><ul>
<li><p>AlexNet</p>
</li>
<li><p>VGG系列</p>
</li>
<li><p>ResNet</p>
</li>
<li><p>SqueezeNet</p>
</li>
</ul>
<h2 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross validation"></a>Cross validation</h2><ul>
<li><p>每次訓練更換dataset</p>
</li>
<li><p>ensemble</p>
</li>
</ul>
<p><img src="/../images/20220711_1.png" alt="upload successful"></p>
<hr>
<p>以下是我對這作業除了Base sample code以外所做的變化，針對上述目標，有做的我才會列出來</p>
<h1 id="First-Approach"><a href="#First-Approach" class="headerlink" title="First Approach"></a>First Approach</h1><p>Note: 因為這次作業放在kaggle上寫&amp;跑，而kaggle設計在結束比賽之前不能公開notebook，所以不能內嵌frame&#x3D; &#x3D;，下面只能先直接貼上code代替</p>
<!--<iframe src="https://codepen.io/gretema/embed/eYOjPJx?height=265&theme-id=default&default-tab=html,result" width="100%" height="300" frameborder="0" loading="lazy" allowfullscreen></iframe> -->
<h2 id="Data-argumentation"><a href="#Data-argumentation" class="headerlink" title="Data argumentation"></a>Data argumentation</h2><ul>
<li>改動trains transform，新增兩個處理，一個是讓照片有0.6的可能水平翻轉，另一個則是把它做normalization<ul>
<li>針對個別batch算出mean,std做normalization的方法我沒找到，目前直接套網路上常用的3 channel RGB圖之平均值當參數 (mean &#x3D; [0.5,0.5,0.5] std &#x3D; [0.1, 0.1, 0.1])<br>    - 這樣做觸犯1個問題，我的normalization是單一標準對所有data做，還是對每個batch單獨這樣做？在這個case沒差，不過這是因為數字寫死，normalization做的實在有夠醜&#x3D; &#x3D;<br>    - 觸犯另一個問題是，我的layer之間有沒有再進行一次normalization呢？有待釐清<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mean = [0.5, 0.5, 0.5]</span><br><span class="line">std = [0.1, 0.1, 0.1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    # Resize the image into a fixed shape (height = width = 128)</span><br><span class="line">    transforms.Resize((128, 128)),</span><br><span class="line">    # You may add some transforms here.</span><br><span class="line">    transforms.RandomHorizontalFlip(p=0.6),</span><br><span class="line">    # ToTensor() should be the last one of the transforms.</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean,std),</span><br><span class="line">])</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="Module-selection"><a href="#Module-selection" class="headerlink" title="Module selection"></a>Module selection</h2><ul>
<li>這裡我直接選用VGG11取代原本的自訂模型Classifier</li>
</ul>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><ul>
<li>跑了至少100 epoch，結果training acc達到0.97，validate acc卻只有0.1x而且不再有更好結果，明顯的overfitting &#x3D; &#x3D;</li>
<li>可能要考慮加入cross validation</li>
<li>可能是data augmentation太弱？</li>
<li>可能是VGG11模型太強(彈性過高)</li>
<li>我耍笨不小心把訓練的過程輸出洗掉了，沒有圖片QQ</li>
</ul>
<hr>
<h1 id="Second-Approach"><a href="#Second-Approach" class="headerlink" title="Second Approach"></a>Second Approach</h1><h2 id="Module-Selection"><a href="#Module-Selection" class="headerlink" title="Module Selection"></a>Module Selection</h2><ul>
<li>單純的把VGG11模型改回Classification</li>
</ul>
<h2 id="Result-1"><a href="#Result-1" class="headerlink" title="Result"></a>Result</h2><ul>
<li>看起來好像沒什麼變化，看來不是VGG模型導致overfitting</li>
<li>可能是normalization的部分出問題了，接下來嘗試把normalization改掉，用VGG train看看<ul>
<li>如果這樣成功的話，只能說應該是normalization把數字改成詭異的形狀了，算是一種人為mismatch吧<br><img src="/../images/20220711_2.png"></li>
</ul>
</li>
</ul>
<hr>
<h1 id="Third-Approach"><a href="#Third-Approach" class="headerlink" title="Third Approach"></a>Third Approach</h1><h2 id="Transform"><a href="#Transform" class="headerlink" title="Transform"></a>Transform</h2><ul>
<li>移除normalization</li>
</ul>
<h2 id="Result-2"><a href="#Result-2" class="headerlink" title="Result"></a>Result</h2><ul>
<li><p>acc爆增回正常範圍了，看來真的是normalization的鍋qwq<br><img src="/../images/20220711_3.png"></p>
</li>
<li><p>上面這是最高紀錄，valid acc 有70%，位於epoch 32，我後來一直跑到epoch 52都沒看到更好的分數，就先卡掉了(看起來進medium概率近乎於零&#x3D; &#x3D;)<br><img src="/../images/20220712_4.png"></p>
</li>
<li><p>不過雖然70%比起之前的acc是大躍進，距離medium仍有一段距離，training acc也到達瓶頸，看起來是需要提高data augmentation的時候了</p>
</li>
</ul>
<h1 id="Forth-Approach"><a href="#Forth-Approach" class="headerlink" title="Forth Approach"></a>Forth Approach</h1><ul>
<li>偷偷參考了一下<a target="_blank" rel="noopener" href="https://github.com/Joshuaoneheart/ML2022_all_A_plus/blob/main/hw3.md">學長</a>的筆記，發現新招數「AutoAugmentation」，適用在Transform內</li>
<li>這招的原理來自於<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.09501.pdf">這篇論文</a>，可以從data裡面學到如何排Transform Augment</li>
<li>同時也從學長的筆記學到，因為code裡面有用BatchNorm2d (batch Normalization)，所以batchSize大一點會比較有利<ul>
<li>這好像就是元兇嗎orz，多做一次norm<br>    - 不過我只有在助教寫的Classification有看到norm，因為用的是VGG11，所以不確定是否仍然有用norm(沒看源碼XD)</li>
</ul>
</li>
</ul>
<h2 id="Transform-1"><a href="#Transform-1" class="headerlink" title="Transform"></a>Transform</h2><ul>
<li>新增<code>transforms.AutoAugment()</code></li>
<li>新增<code>transforms.RandomRotation(degrees = 32)  //rotate+-32度</code></li>
</ul>
<h2 id="BatchSize"><a href="#BatchSize" class="headerlink" title="BatchSize"></a>BatchSize</h2><ul>
<li>修改為96</li>
</ul>
<h2 id="Result-3"><a href="#Result-3" class="headerlink" title="Result"></a>Result</h2><ul>
<li>這次讓他跑了一整晚，充分認識到kaggel save&amp;run的重要性&#x3D; &#x3D;</li>
<li>直接掛網頁按run all如果網頁停止回應或是閒置過久就沒了</li>
<li>這次訓練時間大約10hr，仍然沒有得到最終結果-&gt;網頁爆了<br><img src="/../images/20220712_1.png"></li>
<li>練到了291 epoch，感覺valid的acc就上不去了… 只能止步medium嗎</li>
</ul>
<hr>
<h1 id="Fifth-Approach"><a href="#Fifth-Approach" class="headerlink" title="Fifth Approach"></a>Fifth Approach</h1><ul>
<li>最後又重跑了一次training &#x3D; &#x3D;，沒有作任何更動，GPU quota還有18 hr 希望夠用…</li>
</ul>
<h2 id="Result-Finale"><a href="#Result-Finale" class="headerlink" title="Result (Finale)"></a>Result (Finale)</h2><p><img src="/../images/20220712_2.png"><br>&#x3D; &#x3D;凸</p>
<ul>
<li>最終在epoch 389的時候終止了，最好的epoch在252，其實已經很接近當初的150 patience了</li>
<li>好在best model parameters有保存下來，接下來就是load model之後直接predict了</li>
</ul>
<h2 id="最終成果"><a href="#最終成果" class="headerlink" title="最終成果"></a>最終成果</h2><p><img src="/../images/20220712_3.png"><br><a target="_blank" rel="noopener" href="https://www.kaggle.com/code/laxiflora/ml2022hw3-sample-code-training-predictin">Notebook連結</a></p>
<h1 id="心得"><a href="#心得" class="headerlink" title="心得"></a>心得</h1><p>這次作業是CNN的範例題，這次的圖像辨識題真的讓人思考到了如何去優化他，助教提供的sample code省去了start from scratch的痛苦，讓我們能專注在實作理論的部分</p>
<p>其實很多的技術(Batch normalization、crossEntropy+softmax、data Batch等等)都已經被函數包進去一次做好了，正常的時候是不會發現到他們的存在，這或許也間接印證了他們是十分有效提高命中率的方法吧。而真的需要實作的part其實不多，比較難的是要去翻出他們的document一一認識他們的結構並理解功能，這才是最難的部分</p>
<p>助教的sample code寫得蠻精美的，甚至有看出在自訂結構其實有保留空間讓學生自行切分training set跟valid set(可能是用於做cross validation用的)，考量到讓學生改進而保留空間，真的厲害！除了實作理論與閱讀結構以外，最重要的估計就是看懂這個訓練過程的資料結構了吧~</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/07/09/ML-2021-3-1-%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/" rel="prev" title="ML_2021_3-1 卷積神經網路">
                  <i class="fa fa-chevron-left"></i> ML_2021_3-1 卷積神經網路
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/07/13/ML-2021-4-1-%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6%EF%BC%88%E4%B8%8A%EF%BC%89/" rel="next" title="ML_2021_4-1 自注意力機制（上）">
                  ML_2021_4-1 自注意力機制（上） <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">劉宇承</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
