<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"laxiflora.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="論文原文連結 翻譯版連結  本篇論文主要介紹Transformer的各種變體，以及他的優缺點 What is Transformer? Transformer採用了Self-attention技術，並屏棄了以往對於序列資料所採用的RNN 序列資料得以考慮全局性，不再像RNN那樣是序列依賴性 Transformer可以看作是CNN，只是每一個vector考慮的依賴性是整張圖片（把一個sequenc">
<meta property="og:type" content="article">
<meta property="og:title" content="Efficient Transformers:A Survey筆記">
<meta property="og:url" content="https://laxiflora.github.io/2022/07/22/Efficient-Transformers-A-Survey%E7%AD%86%E8%A8%98/index.html">
<meta property="og:site_name" content="laxiflora的小天地">
<meta property="og:description" content="論文原文連結 翻譯版連結  本篇論文主要介紹Transformer的各種變體，以及他的優缺點 What is Transformer? Transformer採用了Self-attention技術，並屏棄了以往對於序列資料所採用的RNN 序列資料得以考慮全局性，不再像RNN那樣是序列依賴性 Transformer可以看作是CNN，只是每一個vector考慮的依賴性是整張圖片（把一個sequenc">
<meta property="og:locale" content="zh_TW">
<meta property="article:published_time" content="2022-07-22T06:53:52.000Z">
<meta property="article:modified_time" content="2022-08-08T12:10:07.953Z">
<meta property="article:author" content="劉宇承">
<meta property="article:tag" content="機器學習">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://laxiflora.github.io/2022/07/22/Efficient-Transformers-A-Survey%E7%AD%86%E8%A8%98/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"https://laxiflora.github.io/2022/07/22/Efficient-Transformers-A-Survey%E7%AD%86%E8%A8%98/","path":"2022/07/22/Efficient-Transformers-A-Survey筆記/","title":"Efficient Transformers:A Survey筆記"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Efficient Transformers:A Survey筆記 | laxiflora的小天地</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">laxiflora的小天地</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">前進軟體工程師的練功之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#What-is-Transformer"><span class="nav-number">1.</span> <span class="nav-text">What is Transformer?</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transformer%E7%9A%84%E5%95%8F%E9%A1%8C"><span class="nav-number">1.1.</span> <span class="nav-text">Transformer的問題</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Dense-Transformer"><span class="nav-number">1.2.</span> <span class="nav-text">Dense Transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sparse-Attaention"><span class="nav-number">1.3.</span> <span class="nav-text">Sparse Attaention</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Fixed-patterns-FP"><span class="nav-number">1.3.1.</span> <span class="nav-text">Fixed patterns(FP)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Learnable-patterns-LP"><span class="nav-number">1.3.2.</span> <span class="nav-text">Learnable patterns(LP)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Memory"><span class="nav-number">1.3.3.</span> <span class="nav-text">Memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Low-rank-methods"><span class="nav-number">1.3.4.</span> <span class="nav-text">Low rank methods</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">劉宇承</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/22/Efficient-Transformers-A-Survey%E7%AD%86%E8%A8%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Efficient Transformers:A Survey筆記 | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Efficient Transformers:A Survey筆記
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-22 14:53:52" itemprop="dateCreated datePublished" datetime="2022-07-22T14:53:52+08:00">2022-07-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2009.06732">論文原文連結</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/263031249">翻譯版連結</a></li>
</ul>
<p>本篇論文主要介紹Transformer的各種變體，以及他的優缺點</p>
<h1 id="What-is-Transformer"><a href="#What-is-Transformer" class="headerlink" title="What is Transformer?"></a>What is Transformer?</h1><ul>
<li>Transformer採用了Self-attention技術，並屏棄了以往對於序列資料所採用的RNN</li>
<li>序列資料得以考慮全局性，不再像RNN那樣是序列依賴性</li>
<li>Transformer可以看作是CNN，只是每一個vector考慮的依賴性是整張圖片（把一個sequence鋪成平面，每一個vector視為一個pixel，vector維數&#x3D;channel）</li>
</ul>
<h2 id="Transformer的問題"><a href="#Transformer的問題" class="headerlink" title="Transformer的問題"></a>Transformer的問題</h2><ul>
<li>目前的計算複雜度過高，是$O(n^2)$，使得transformer難以在輕模型下使用</li>
<li>目前為了解決transformer過度肥大的問題，出現了許多的變種</li>
</ul>
<h2 id="Dense-Transformer"><a href="#Dense-Transformer" class="headerlink" title="Dense Transformer"></a>Dense Transformer</h2><ul>
<li>transformer的起源</li>
<li>待補</li>
</ul>
<h2 id="Sparse-Attaention"><a href="#Sparse-Attaention" class="headerlink" title="Sparse Attaention"></a>Sparse Attaention</h2><ul>
<li>這裡開始是為了降低複雜度而延伸的變種</li>
<li>限制self-attention的參考範圍，使全面參考變成部分參考</li>
<li></li>
</ul>
<h3 id="Fixed-patterns-FP"><a href="#Fixed-patterns-FP" class="headerlink" title="Fixed patterns(FP)"></a>Fixed patterns(FP)</h3><ul>
<li>參考範圍作為hyper-parameter存在，是訓練前先決定好的固定值</li>
<li>常見方法有<ul>
<li>Blockwise pattern : 把輸入序列切成block(batch)，複雜度降為$O(B^2)$，變成$(\frac{N}{B}*B^2)$<ul>
<li>導致序列不連貫，效果”可能”有限</li>
</ul>
</li>
<li>Strided pattern : 變得真的非常像CNN，採用滑動kernel的的方式，每個vector只attention自己的那塊kernel<ul>
<li>建立在假設NLP在多數情況下都是具備局部相關的前提下，免去過度參考太遠的vector所浪費的計算</li>
</ul>
</li>
<li>Compressed pattern : 超級無敵像CNN(欸)，用把vector壓成平面的角度會更好思考，其實就是pooling，把幾個token池化，變成一個vector後才做attention，個人認為複雜度會降為$O(\frac{N^2}{kernel_size})$</li>
</ul>
</li>
</ul>
<h3 id="Learnable-patterns-LP"><a href="#Learnable-patterns-LP" class="headerlink" title="Learnable patterns(LP)"></a>Learnable patterns(LP)</h3><ul>
<li>相對於ＦＰ，ＬＰ是把參考範圍也作為weight給機器去學習</li>
<li>比如routing transformer是對token向量進行k-means來將整體序列切成多個子序列</li>
</ul>
<h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>這裡看不太懂，先貼原文</p>
<p>memory乍一听好像有点让人摸不着头脑，其实想法也很简单。最开始是在19年的set transformer上使用。一般来说做multihead self-attention时，Q&#x3D;K&#x3D;V&#x3D;X（X为输入序列，长度为n），而在set transformer中，作者先单独设置了m个向量（m是超参数），然后这m个向量与X做multihead attention，得到m个临时向量（这些个临时变量我们就称作“temporary memory”），接着把X与这m个临时向量再做一次multihead attention得到输出。这个过程其实就是利用这m个向量将输入序列X的信息先通过attention进行压缩，再通过attention还原，达到抽取输入序列的特征的目的。但是在压缩编码解码的过程中肯定会有信息损失，所以后来的改进方法是引入全局记忆，即设置一些token，它们可以与所有的token进行注意力交互，比如bert的[CLS]，由于这些token的数目远小于序列长度，因此也不会给计算带来负担，而且往往携带了整个输入序列的信息，这就是我们可以在bert上用[CLS]作文本分类任务的原因。</p>
<h3 id="Low-rank-methods"><a href="#Low-rank-methods" class="headerlink" title="Low rank methods"></a>Low rank methods</h3><ul>
<li>Attention matrix在經過softmax轉化以後會是不滿秩的(存在linear dependent,rank !&#x3D; N)，所以我們可以把矩陣降維</li>
<li>k,v向量可以因此映射到kxd維，因為k為hyper-parameter，複雜度可降至 $O(nk)$</li>
<li>範例：linformer</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.04768">相關論文</a></li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/" rel="tag"># 機器學習</a>
              <a href="/tags/NLP/" rel="tag"># NLP</a>
              <a href="/tags/BERT/" rel="tag"># BERT</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/07/13/ML-2021-4-2-%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6%EF%BC%88%E4%B8%8B%EF%BC%89/" rel="prev" title="ML_2021_4-2 自注意力機制（下）">
                  <i class="fa fa-chevron-left"></i> ML_2021_4-2 自注意力機制（下）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/07/23/ML-LEE-2022-hw4/" rel="next" title="ML_LEE_2022_hw4">
                  ML_LEE_2022_hw4 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">劉宇承</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
