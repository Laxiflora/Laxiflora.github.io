<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"laxiflora.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="laxiflora的小天地">
<meta property="og:url" content="https://laxiflora.github.io/page/4/index.html">
<meta property="og:site_name" content="laxiflora的小天地">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="劉宇承">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://laxiflora.github.io/page/4/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-TW","comments":"","permalink":"","path":"page/4/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>laxiflora的小天地</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">laxiflora的小天地</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">前進軟體工程師的練功之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">劉宇承</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/13/ML-2021-4-1-%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6%EF%BC%88%E4%B8%8A%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/13/ML-2021-4-1-%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A9%9F%E5%88%B6%EF%BC%88%E4%B8%8A%EF%BC%89/" class="post-title-link" itemprop="url">ML_2021_4-1 自注意力機制（上）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-13 10:33:00" itemprop="dateCreated datePublished" datetime="2022-07-13T10:33:00+08:00">2022-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>至今為止，我們network input 都是一個vector</li>
<li>那如果輸入是可變動的一排向量（sequence）呢？</li>
</ul>
<h2 id="Vector-set-as-input"><a href="#Vector-set-as-input" class="headerlink" title="Vector set as input"></a>Vector set as input</h2><ul>
<li>長度不一的句子就是一個範例</li>
<li>關於word embedding如何得到，可以參考<a target="_blank" rel="noopener" href="https://youtu.be/X7PH3NuYW0Q">這個影片</a></li>
<li>現在的文字基本上都是被word embedding過，而句子就是一連串了文字向量</li>
<li>一段聲音訊號也是一個範例（25 millisecond），一個向量稱為『frame』</li>
<li>一個graph也是一連串的向量<ul>
<li>Drug discovery中一個分子，可以看做一個graph</li>
<li>社群媒體中，人（節點）可以是一個向量，ex.性別、年齡、工作等等</li>
</ul>
</li>
</ul>
<h2 id="What-is-the-output"><a href="#What-is-the-output" class="headerlink" title="What is the output?"></a>What is the output?</h2><h3 id="Type-1-本課專注"><a href="#Type-1-本課專注" class="headerlink" title="Type 1 (本課專注)"></a>Type 1 (本課專注)</h3><ul>
<li>每一個vector都會有一個label</li>
<li>POS tagging（詞性標注），每一個詞彙都要對應一個詞性</li>
<li>語音，每一段frame都會有一個Pheonic</li>
<li>Social network，對每一個人可能會有一種廣告投放方式</li>
</ul>
<h3 id="Type-2-hw4"><a href="#Type-2-hw4" class="headerlink" title="Type 2 (hw4)"></a>Type 2 (hw4)</h3><ul>
<li>一整個sequence輸出一個label</li>
<li>Sentiment analysis: 機器去判讀一段句字是正面的還是負面</li>
<li>給定一段音訊，分辨它是哪個人說的</li>
</ul>
<h3 id="Type-3"><a href="#Type-3" class="headerlink" title="Type 3"></a>Type 3</h3><ul>
<li>不知道輸出幾個label</li>
<li>稱為sequence to sequence(seq2seq)</li>
</ul>
<h2 id="Sequence-labeling"><a href="#Sequence-labeling" class="headerlink" title="Sequence labeling"></a>Sequence labeling</h2><ul>
<li>對於每個向量，要做一個label</li>
</ul>
<h3 id="First-approach"><a href="#First-approach" class="headerlink" title="First approach"></a>First approach</h3><ul>
<li>直接用fully connect network</li>
<li>問題出現：同樣輸入就會有同樣輸出，但是不能保證兩個vector之間是否有關連</li>
<li>需要consider the context</li>
</ul>
<h3 id="Second-approach"><a href="#Second-approach" class="headerlink" title="Second approach"></a>Second approach</h3><ul>
<li>直接給fully connected network整個window (hw2就是這樣做的)<br><img src="/../images/20220713_1.png"></li>
<li>問題：如果今天的任務是得要考慮整個sequence怎辦<ul>
<li>sequence長度有長有短，window大小要變動，而且運算量非常大又導致overfitting</li>
</ul>
</li>
</ul>
<h3 id="Third-approach"><a href="#Third-approach" class="headerlink" title="Third approach"></a>Third approach</h3><ul>
<li>採用Self-attention技術，先把向量加工再個別丟入全連階層<br><img src="/../images/20220713_2.png" alt="upload successful"></li>
<li>黑框框向量表示考慮過前後文的加工向量</li>
<li>Self-attention可以有很多層</li>
<li>經典論文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Attention is all you need</a><ul>
<li>Transformer</li>
</ul>
</li>
<li>Self-attention內部結構如下：<br><img src="/../images/20220713_3.png"></li>
<li>找出relevant vectors in a sequence，關聯度以$\alpha$表示</li>
<li>計算$\alpha$比較常見的做法是做內積，兩個向量各自乘一個矩陣($W^q、W^k等$)以後再做內積<ul>
<li>之後課程先只用這個方法</li>
</ul>
</li>
</ul>
<h2 id="How-to-apply"><a href="#How-to-apply" class="headerlink" title="How to apply"></a>How to apply</h2><p><img src="/../images/pasted-17.png"></p>
<ul>
<li>$q^1$表示輸入向量$a^1$對$W^q$矩陣相乘的結果</li>
<li>$k^i$則表示內積的另一個算子，表示$a^i * W^k$以後的結果</li>
<li>softmax不一定是唯一解，只是常見（用他沒有理由）</li>
<li>得出$\alpha’$以後，繼續根據他抽取sequence中重要的資訊<br><img src="/../images/20220713_5.png"></li>
<li>最後再把$\alpha’$乘上$W^v$，一個向量得到的分數越高，則越可能會dominate抽取出的結果</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://medium.com/ching-i/transformer-attention-is-all-you-need-c7967f38af14">參考文章</a></p>
<ul>
<li>q:query，就是輸入的vector，用於與k做內積來判斷相似性</li>
<li>k:key，指序列中的所有詞向量</li>
<li>v:value，指實際的序列內容</li>
<li>q,k內積的過程稱為Dot-product Attention</li>
<li>兩個vector之間的關聯越大，則 $\alpha$ 越大</li>
<li>上面步驟講到的都是encoder</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/11/ML-LEE-2022-hw3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/11/ML-LEE-2022-hw3/" class="post-title-link" itemprop="url">ML_LEE_2022_hw3</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-11 21:24:56" itemprop="dateCreated datePublished" datetime="2022-07-11T21:24:56+08:00">2022-07-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/ml2022spring-hw3b">作業題目</a></p>
<h1 id="可進行的目標"><a href="#可進行的目標" class="headerlink" title="可進行的目標"></a>可進行的目標</h1><h2 id="Data-augmentation-training"><a href="#Data-augmentation-training" class="headerlink" title="Data augmentation (training)"></a>Data augmentation (training)</h2><ul>
<li><p>搜尋torchvision.transform，<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">docs</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://chih-sheng-huang821.medium.com/03-pytorch-dataaug-a712a7a7f55e">有用的文章：Pytorch提供之torchvision data augmentation技巧</a></p>
</li>
<li><p>transform.randomRotate   ,   resize等等</p>
</li>
<li><p>最後必須要toTensor，model只吃pytorch的tensor不吃PIL library的</p>
</li>
</ul>
<h2 id="Adv-Data-augmentation-mixed-up-training"><a href="#Adv-Data-augmentation-mixed-up-training" class="headerlink" title="Adv. Data augmentation - mixed up (training)"></a>Adv. Data augmentation - mixed up (training)</h2><ul>
<li><p>mixup (把兩個影像混再一起，變成多重label)</p>
</li>
<li><p>cross entropy loss function需要重寫</p>
</li>
</ul>
<h2 id="Module-selection-搜尋torchvision-models"><a href="#Module-selection-搜尋torchvision-models" class="headerlink" title="Module selection (搜尋torchvision.models)"></a>Module selection (搜尋torchvision.models)</h2><ul>
<li><p>AlexNet</p>
</li>
<li><p>VGG系列</p>
</li>
<li><p>ResNet</p>
</li>
<li><p>SqueezeNet</p>
</li>
</ul>
<h2 id="Cross-validation"><a href="#Cross-validation" class="headerlink" title="Cross validation"></a>Cross validation</h2><ul>
<li><p>每次訓練更換dataset</p>
</li>
<li><p>ensemble</p>
</li>
</ul>
<p><img src="/../images/20220711_1.png" alt="upload successful"></p>
<hr>
<p>以下是我對這作業除了Base sample code以外所做的變化，針對上述目標，有做的我才會列出來</p>
<h1 id="First-Approach"><a href="#First-Approach" class="headerlink" title="First Approach"></a>First Approach</h1><p>Note: 因為這次作業放在kaggle上寫&amp;跑，而kaggle設計在結束比賽之前不能公開notebook，所以不能內嵌frame&#x3D; &#x3D;，下面只能先直接貼上code代替</p>
<!--<iframe src="https://codepen.io/gretema/embed/eYOjPJx?height=265&theme-id=default&default-tab=html,result" width="100%" height="300" frameborder="0" loading="lazy" allowfullscreen></iframe> -->
<h2 id="Data-argumentation"><a href="#Data-argumentation" class="headerlink" title="Data argumentation"></a>Data argumentation</h2><ul>
<li>改動trains transform，新增兩個處理，一個是讓照片有0.6的可能水平翻轉，另一個則是把它做normalization<ul>
<li>針對個別batch算出mean,std做normalization的方法我沒找到，目前直接套網路上常用的3 channel RGB圖之平均值當參數 (mean &#x3D; [0.5,0.5,0.5] std &#x3D; [0.1, 0.1, 0.1])<br>    - 這樣做觸犯1個問題，我的normalization是單一標準對所有data做，還是對每個batch單獨這樣做？在這個case沒差，不過這是因為數字寫死，normalization做的實在有夠醜&#x3D; &#x3D;<br>    - 觸犯另一個問題是，我的layer之間有沒有再進行一次normalization呢？有待釐清<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mean = [0.5, 0.5, 0.5]</span><br><span class="line">std = [0.1, 0.1, 0.1]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_tfm = transforms.Compose([</span><br><span class="line">    # Resize the image into a fixed shape (height = width = 128)</span><br><span class="line">    transforms.Resize((128, 128)),</span><br><span class="line">    # You may add some transforms here.</span><br><span class="line">    transforms.RandomHorizontalFlip(p=0.6),</span><br><span class="line">    # ToTensor() should be the last one of the transforms.</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean,std),</span><br><span class="line">])</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h2 id="Module-selection"><a href="#Module-selection" class="headerlink" title="Module selection"></a>Module selection</h2><ul>
<li>這裡我直接選用VGG11取代原本的自訂模型Classifier</li>
</ul>
<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><ul>
<li>跑了至少100 epoch，結果training acc達到0.97，validate acc卻只有0.1x而且不再有更好結果，明顯的overfitting &#x3D; &#x3D;</li>
<li>可能要考慮加入cross validation</li>
<li>可能是data augmentation太弱？</li>
<li>可能是VGG11模型太強(彈性過高)</li>
<li>我耍笨不小心把訓練的過程輸出洗掉了，沒有圖片QQ</li>
</ul>
<hr>
<h1 id="Second-Approach"><a href="#Second-Approach" class="headerlink" title="Second Approach"></a>Second Approach</h1><h2 id="Module-Selection"><a href="#Module-Selection" class="headerlink" title="Module Selection"></a>Module Selection</h2><ul>
<li>單純的把VGG11模型改回Classification</li>
</ul>
<h2 id="Result-1"><a href="#Result-1" class="headerlink" title="Result"></a>Result</h2><ul>
<li>看起來好像沒什麼變化，看來不是VGG模型導致overfitting</li>
<li>可能是normalization的部分出問題了，接下來嘗試把normalization改掉，用VGG train看看<ul>
<li>如果這樣成功的話，只能說應該是normalization把數字改成詭異的形狀了，算是一種人為mismatch吧<br><img src="/../images/20220711_2.png"></li>
</ul>
</li>
</ul>
<hr>
<h1 id="Third-Approach"><a href="#Third-Approach" class="headerlink" title="Third Approach"></a>Third Approach</h1><h2 id="Transform"><a href="#Transform" class="headerlink" title="Transform"></a>Transform</h2><ul>
<li>移除normalization</li>
</ul>
<h2 id="Result-2"><a href="#Result-2" class="headerlink" title="Result"></a>Result</h2><ul>
<li><p>acc爆增回正常範圍了，看來真的是normalization的鍋qwq<br><img src="/../images/20220711_3.png"></p>
</li>
<li><p>上面這是最高紀錄，valid acc 有70%，位於epoch 32，我後來一直跑到epoch 52都沒看到更好的分數，就先卡掉了(看起來進medium概率近乎於零&#x3D; &#x3D;)<br><img src="/../images/20220712_4.png"></p>
</li>
<li><p>不過雖然70%比起之前的acc是大躍進，距離medium仍有一段距離，training acc也到達瓶頸，看起來是需要提高data augmentation的時候了</p>
</li>
</ul>
<h1 id="Forth-Approach"><a href="#Forth-Approach" class="headerlink" title="Forth Approach"></a>Forth Approach</h1><ul>
<li>偷偷參考了一下<a target="_blank" rel="noopener" href="https://github.com/Joshuaoneheart/ML2022_all_A_plus/blob/main/hw3.md">學長</a>的筆記，發現新招數「AutoAugmentation」，適用在Transform內</li>
<li>這招的原理來自於<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1805.09501.pdf">這篇論文</a>，可以從data裡面學到如何排Transform Augment</li>
<li>同時也從學長的筆記學到，因為code裡面有用BatchNorm2d (batch Normalization)，所以batchSize大一點會比較有利<ul>
<li>這好像就是元兇嗎orz，多做一次norm<br>    - 不過我只有在助教寫的Classification有看到norm，因為用的是VGG11，所以不確定是否仍然有用norm(沒看源碼XD)</li>
</ul>
</li>
</ul>
<h2 id="Transform-1"><a href="#Transform-1" class="headerlink" title="Transform"></a>Transform</h2><ul>
<li>新增<code>transforms.AutoAugment()</code></li>
<li>新增<code>transforms.RandomRotation(degrees = 32)  //rotate+-32度</code></li>
</ul>
<h2 id="BatchSize"><a href="#BatchSize" class="headerlink" title="BatchSize"></a>BatchSize</h2><ul>
<li>修改為96</li>
</ul>
<h2 id="Result-3"><a href="#Result-3" class="headerlink" title="Result"></a>Result</h2><ul>
<li>這次讓他跑了一整晚，充分認識到kaggel save&amp;run的重要性&#x3D; &#x3D;</li>
<li>直接掛網頁按run all如果網頁停止回應或是閒置過久就沒了</li>
<li>這次訓練時間大約10hr，仍然沒有得到最終結果-&gt;網頁爆了<br><img src="/../images/20220712_1.png"></li>
<li>練到了291 epoch，感覺valid的acc就上不去了… 只能止步medium嗎</li>
</ul>
<hr>
<h1 id="Fifth-Approach"><a href="#Fifth-Approach" class="headerlink" title="Fifth Approach"></a>Fifth Approach</h1><ul>
<li>最後又重跑了一次training &#x3D; &#x3D;，沒有作任何更動，GPU quota還有18 hr 希望夠用…</li>
</ul>
<h2 id="Result-Finale"><a href="#Result-Finale" class="headerlink" title="Result (Finale)"></a>Result (Finale)</h2><p><img src="/../images/20220712_2.png"><br>&#x3D; &#x3D;凸</p>
<ul>
<li>最終在epoch 389的時候終止了，最好的epoch在252，其實已經很接近當初的150 patience了</li>
<li>好在best model parameters有保存下來，接下來就是load model之後直接predict了</li>
</ul>
<h2 id="最終成果"><a href="#最終成果" class="headerlink" title="最終成果"></a>最終成果</h2><p><img src="/../images/20220712_3.png"><br><a target="_blank" rel="noopener" href="https://www.kaggle.com/code/laxiflora/ml2022hw3-sample-code-training-predictin">Notebook連結</a></p>
<h1 id="心得"><a href="#心得" class="headerlink" title="心得"></a>心得</h1><p>這次作業是CNN的範例題，這次的圖像辨識題真的讓人思考到了如何去優化他，助教提供的sample code省去了start from scratch的痛苦，讓我們能專注在實作理論的部分</p>
<p>其實很多的技術(Batch normalization、crossEntropy+softmax、data Batch等等)都已經被函數包進去一次做好了，正常的時候是不會發現到他們的存在，這或許也間接印證了他們是十分有效提高命中率的方法吧。而真的需要實作的part其實不多，比較難的是要去翻出他們的document一一認識他們的結構並理解功能，這才是最難的部分</p>
<p>助教的sample code寫得蠻精美的，甚至有看出在自訂結構其實有保留空間讓學生自行切分training set跟valid set(可能是用於做cross validation用的)，考量到讓學生改進而保留空間，真的厲害！除了實作理論與閱讀結構以外，最重要的估計就是看懂這個訓練過程的資料結構了吧~</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/09/ML-2021-3-1-%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/09/ML-2021-3-1-%E5%8D%B7%E7%A9%8D%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF/" class="post-title-link" itemprop="url">ML_2021_3-1 卷積神經網路</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-09 16:13:09" itemprop="dateCreated datePublished" datetime="2022-07-09T16:13:09+08:00">2022-07-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>network架構的其中一種變形:CNN</li>
<li>此講專注在CNN專門用在影像上的講解(目前也普遍用在影像)</li>
</ul>
<h1 id="Image-classification-Version-1"><a href="#Image-classification-Version-1" class="headerlink" title="Image classification - Version 1"></a>Image classification - Version 1</h1><ul>
<li>我們需要假設圖片輸入的大小都是固定的<ul>
<li>如果大小不一，就得要rescale</li>
</ul>
</li>
<li>是classification問題，所以輸出one-hot vector (向量的長度代表你能分出多少種類別)</li>
</ul>
<h2 id="如何把影像當作輸入"><a href="#如何把影像當作輸入" class="headerlink" title="如何把影像當作輸入"></a>如何把影像當作輸入</h2><ul>
<li>一張圖片其實是一個3維的Tensor (RGB)<ul>
<li>Tensor(長跟寬)，並有3個Channel</li>
</ul>
</li>
<li>我們把3維的Tensor拉直，成為一個向量 (這也是為何影像大小需要相同)</li>
</ul>
<h2 id="Train-with-fully-connected-network？"><a href="#Train-with-fully-connected-network？" class="headerlink" title="Train with fully connected network？"></a>Train with fully connected network？</h2><ul>
<li>如果我們依然使用fully connected network來訓練，又假設neuron取1000個，則一個100x100的圖片輸入，會產生$100<em>100</em>3(彩色)<em>1000 &#x3D; 3</em>10^7$個weight，是一個巨大的數字，大幅增加了overfitting的風險 (彈性過大)<br><img src="/../images/20220709_1.png"></li>
<li>不採用全連接層，以下透過一些觀察來嘗試簡化這個網路</li>
</ul>
<h2 id="Observation-1"><a href="#Observation-1" class="headerlink" title="Observation 1"></a>Observation 1</h2><ul>
<li>對於圖片辨識，我們要做的是針對圖片裡面找到一些關鍵的部位 (ex. 鳥嘴、眼睛、翅膀)</li>
<li>每個neuron並不需要看過整張圖片(即，不用fully connected)</li>
<li>我們可以讓每個neuron只看特定的區塊就好</li>
</ul>
<h3 id="Simplification-1-typical-settig"><a href="#Simplification-1-typical-settig" class="headerlink" title="Simplification 1 - typical settig"></a>Simplification 1 - typical settig</h3><ul>
<li><p>CNN會設定一個『Receptive Field』，每個neuron讀取一個他負責的區塊<br><img src="/../images/20220709_2.png"></p>
</li>
<li><p>Receptive Field可以重疊</p>
</li>
<li><p>Different neuron是可以有不同的receptive field的</p>
</li>
<li><p>上述案例裡面，就是3x3的kernel size</p>
</li>
<li><p>通常會有一排(64、128等)個neuron去守備他</p>
</li>
<li><p>不同的receptive field之間的距離差距稱為『stride』</p>
</li>
<li><p>通常receptive field都會高度重疊</p>
</li>
<li><p>如果一個receptive field關注的範圍超出圖片範圍，就需要把外面的值補值(補0、補平均等)，稱為『padding』</p>
</li>
<li><p>Receptive fields cover the whole image</p>
</li>
</ul>
<h2 id="Observation-2"><a href="#Observation-2" class="headerlink" title="Observation 2"></a>Observation 2</h2><ul>
<li>當一個特殊部位落在不同的receptive field內怎麼處理?</li>
</ul>
<h3 id="Simplification-2-typical-setting"><a href="#Simplification-2-typical-setting" class="headerlink" title="Simplification 2 -typical setting"></a>Simplification 2 -typical setting</h3><p><img src="/../images/20220709_3.png"></p>
<ul>
<li>我們可以讓一些neuron採用共用參數(Parameter sharing)，讓他們的參數都一模一樣</li>
<li>因為輸入(receptive field)不一樣，所以各自的輸出也不會相同</li>
<li>可能rf1的第一個neuron跟rf2的第一個neuron共用參數，rf1的第二個跟rf2的第二個neuron共參… etc</li>
<li>這些共用的參數稱為『Filter』<br><img src="/../images/20220709_4.png"></li>
</ul>
<h2 id="Benefit-of-Convolutional-layer"><a href="#Benefit-of-Convolutional-layer" class="headerlink" title="Benefit of Convolutional layer"></a>Benefit of Convolutional layer</h2><ul>
<li>根據上述的觀察，我們成功讓CNN network針對相片輸入的訓練更加簡化<br><img src="/../images/20220709_5.png"></li>
<li>Convolutional layer的model bias會比較大，但CNN是專門為影像設計的network<br>PS. 這邊為何CNN bias會比較大，以及為何這樣不好，可以再google一下</li>
</ul>
<hr>
<h1 id="另一個說明CNN的版本"><a href="#另一個說明CNN的版本" class="headerlink" title="另一個說明CNN的版本"></a>另一個說明CNN的版本</h1><h2 id="Convolutional-layer"><a href="#Convolutional-layer" class="headerlink" title="Convolutional layer"></a>Convolutional layer</h2><ul>
<li><p>所謂Convolutional Layer，裡面有很多的Filter，裡面都有一個3x3xchannel維的tensor</p>
</li>
<li><p>每一個filter都是要抓取某個pattern</p>
</li>
<li><p>以下假設是channel &#x3D; 1(黑白照片)</p>
</li>
<li><p>我們把各個rf跟filter做內積，得出各值<br><img src="/../images/20220709_6.png"></p>
</li>
<li><p>接下來把所有pattern對各filter一樣的計算</p>
</li>
<li><p>這內積出來的一群數字稱為『Feature map』，再這個例子中，我們有64個filter，則我們的feature map會有64組(channels)數字，每組有4x4個數字</p>
</li>
<li><p>接下來進到第二層的convolution，我們的filter必須變成3x3x<em>64</em>，因為上一層輸出了64個channel，相對於第一層只有一個channel，第二層會出現64個channel</p>
</li>
</ul>
<h4 id="Note"><a href="#Note" class="headerlink" title="Note:"></a>Note:</h4><ul>
<li>隨著捲積層的深入，我們觀察的圖片pattern會越來越大</li>
<li>繼續上面的例子，如果我們的filter之rf一樣是看3x3大小的話，因為我們的feature map中的3x3大小實際上是對應到圖片裡面的5x5大小(跟stride有關)，所以其實層數越高，我們一次考慮的範圍會越大！<br><img src="/../images/20220709_7.png"></li>
</ul>
<h2 id="Comparison-of-2-version"><a href="#Comparison-of-2-version" class="headerlink" title="Comparison of 2 version"></a>Comparison of 2 version</h2><ul>
<li>第一個版本的共用參數，就是第二版本的filter(本slide忽略bias)</li>
<li>把一個filter掃過一張圖片，稱作『convolves over』<ul>
<li>例句(?)： each filter convolves over the input image<br><img src="/../images/pasted-15.png"></li>
</ul>
</li>
</ul>
<p><img src="/../images/20220709_8.png"></p>
<h2 id="Observation-3"><a href="#Observation-3" class="headerlink" title="Observation 3"></a>Observation 3</h2><ul>
<li>如果我們把一張大圖片縮小、拿掉odd columns，圖片還是不會有所影響(看起來差不多)，稱為subsampling -&gt; pooling</li>
<li>Pooling 本身沒有參數，沒有任何東西要learn，有些人稱他為一種激發函數</li>
<li>pooling就是把圖片像素分組，然後從裡面只選一個像素留下，簡化圖片像素大小</li>
<li>下圖為示意圖<br><img src="/../images/20220709_9.png"></li>
<li>過度pooling仍會傷害訓練效益</li>
</ul>
<hr>
<h1 id="The-whole-CNN"><a href="#The-whole-CNN" class="headerlink" title="The whole CNN"></a>The whole CNN</h1><p><img src="/../images/20220709_10.png"></p>
<ul>
<li>做完卷積層以後要做flatten</li>
<li>flatten就是把矩陣數值拉直</li>
<li>flatten完以後扔進fully connected layer訓練完，配個softmax(分類)，就是一個經典的CNN network</li>
</ul>
<h1 id="Application-GO"><a href="#Application-GO" class="headerlink" title="Application: GO"></a>Application: GO</h1><ul>
<li><p>我們用一個19x19的向量來描述一個棋盤，把它扔進network以後輸出next move應該在的位置</p>
</li>
<li><p>下圍棋可以是一個類別分類問題</p>
</li>
<li><p>這個問題也可以用fully-connected network解決</p>
</li>
<li><p>但用CNN效果更好-&gt; 棋盤可以看做一個19x19來描述</p>
</li>
<li><p>每個棋盤格的channel有48個(這格可能被叫吃等等)</p>
</li>
<li><p>這意味著圍棋與影像有許多相似特性</p>
<ul>
<li>可以只看小區塊(alpha go: 5x5)<br>    - Same pattern appear in different regions (雙叫吃等等)</li>
</ul>
</li>
<li><p>棋盤可否用pooling ? 因為每格都很重要(精細度高) -&gt; Alpha Go有沒有用呢?
  </p>
</li>
<li><p>李宏毅教你畫重點XD：學著幫論文畫重點，抓critical terms<br><img src="/../images/20220709_11.png"></p>
</li>
<li><p>alpha go 正文沒有提到神經網路結構，這是在附件找到的</p>
<ol>
<li>視為19x19x48的image</li>
<li>zero pads(padding補0至23x23)</li>
<li>有k個filter(競賽用的go，filter &#x3D; 192)</li>
<li>filter的kernel size &#x3D; 5x5</li>
<li>stride &#x3D; 1</li>
<li>用到rectifier nonlinearity(ReLU)</li>
<li>2~12層都有做zero padding至21x21，filter數同，kernel size &#x3D; 3x3，stride &#x3D; 1</li>
<li>最後apply softmax function<br><img src="/../images/20220709_12.png"></li>
</ol>
</li>
<li><p>alpha go 沒有用pooling!!</p>
</li>
</ul>
<hr>
<h1 id="Hen重要的Notes"><a href="#Hen重要的Notes" class="headerlink" title="Hen重要的Notes:"></a>Hen重要的Notes:</h1><ul>
<li>語音上、文字處理上，文獻上的方法要仔細看，CNN的receptive field設計會特別為他們特化，這裡講的單純是影像的</li>
<li>CNN並不能處理影像放大縮小(Scaling)旋轉(Rotation)的問題… (向量問題)<ul>
<li>為此我們需要data augmentation</li>
</ul>
</li>
<li>其實有Network架構(Spatial Transformer Layer)可以解決這個問題，請Ref.<a target="_blank" rel="noopener" href="https://youtu.be/SoCywZ1hZak">這個影片</a></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/07/ML-2021-2-6-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BA%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/07/ML-2021-2-6-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BA%94/" class="post-title-link" itemprop="url">ML_2021_2-6 類神經網路訓練不起來怎麼辦(五)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-07 16:34:18" itemprop="dateCreated datePublished" datetime="2022-07-07T16:34:18+08:00">2022-07-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>簡短介紹Batch Normalization的技術</li>
<li>另一種直接改變error surface的技術(相對於動態lr，一種改善訓練的方法)</li>
</ul>
<p><img src="/../images/20220707_1.png" alt="upload successful"></p>
<ul>
<li>考慮以下模型，當$x_1$輸出很小、$x_2$輸出很大的時候，就會產生error surface橢圓的問題</li>
<li>因為$x_1$小，就算$w_1$變化很大，y的變化量也不會很大(因為相乘);$x_2$則相反</li>
<li>考慮可以把$x_1、x_2$相同的數值範圍<br><img src="/../images/20220707_2.png" alt="upload successful"></li>
</ul>
<h1 id="Feature-Normalization"><a href="#Feature-Normalization" class="headerlink" title="Feature Normalization"></a>Feature Normalization</h1><h2 id="其中一種normalization做法"><a href="#其中一種normalization做法" class="headerlink" title="其中一種normalization做法"></a>其中一種normalization做法</h2><ul>
<li>對多筆feature vector的同一dimention做標準化<br><img src="/../images/pasted-11.png"></li>
<li>標準化以後，該dim的平均值&#x3D;0，$\sigma$ &#x3D; 1</li>
<li>像這樣就可以製造比較平衡的error surface，方便optimization作業</li>
</ul>
<h2 id="Case：In-deep-learning"><a href="#Case：In-deep-learning" class="headerlink" title="Case：In deep learning"></a>Case：In deep learning</h2><ul>
<li>因為深度學習有多個層，雖然在一開始我們把x做了標準化，但是在經過一層layer計算以後，數值又失去了標準化，故我們需要進行多次的標準化</li>
<li>標準化要放在激發函數前後的影響並不大<br><img src="/../images/pasted-12.png"></li>
<li>以上圖為例，我們需要對z再度進行標準化，公式如下(feature&#x3D;3的case)<br><img src="/../images/20220707_4.png" alt="upload successful"><br>則可以得到<br>$$\tilde{z}^i &#x3D; \frac{z^i-\mu}{\sigma}$$<br>後續層也依此類推</li>
<li>這個feature標準化的過程使得所有feature之間有了關聯性 -&gt; 這是一個network<br><img src="/../images/20220707_5.png" alt="upload successful"></li>
</ul>
<h2 id="Case：training-in-batch-approach"><a href="#Case：training-in-batch-approach" class="headerlink" title="Case：training in batch approach?"></a>Case：training in batch approach?</h2><ul>
<li>這樣的標準化流程會跟著batch(一組batch內部做標準化)跑，不是所有feature納進來標準化</li>
<li>這樣的作法稱作batch normalization<ul>
<li>問題來了，我們會需要足夠大的batch size才能做一個好的標準化(誤差會比較小)<br><img src="/../images/20220707_6.png"></li>
</ul>
</li>
<li>$\beta、\gamma$是模型的另外兩個參數，透過學習得到</li>
<li>為啥需要這兩個參數?<ul>
<li>因為標準化會保證$\tilde{z}$之平均值 &#x3D; 0，這樣的結果有可能會對模型產生一些負面影響，所以我們需要$\beta、\gamma$兩個參數來讓數值變成比較貼合模型需求</li>
<li>問題：這樣不就又破壞掉標準化平衡了嗎?<ul>
<li>我們初始設定$\gamma &#x3D; 1 , \beta &#x3D; 0$，讓他們初始為真的標準化</li>
<li>讓模型來決定值該怎麼分步</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Batch-normalization-testing-data"><a href="#Batch-normalization-testing-data" class="headerlink" title="Batch normalization - testing data"></a>Batch normalization - testing data</h3><ul>
<li>剛剛講的都是training的情況下</li>
<li>testing又稱inference</li>
<li>當真的是線上模型時，我們必須每一筆資料進來就進行預測，不能用batch</li>
<li>當數據只有一筆，怎麼做normalization($\mu&#x3D;? , \sigma&#x3D;?$)</li>
<li>實作上的解法(pytorch)：<ul>
<li>在training若有用這個技術，每次batch算出來的$\mu_i , \sigma_i$就會記錄下來再做以下處理  <br><img src="/../images/pasted-13.png"></li>
</ul>
</li>
</ul>
<p>在實際test時，就代入<br>$$\tilde{z} &#x3D; \frac{z-\bar{u}}{\bar{\sigma}}<br>$$</p>
<ul>
<li>Batch normalization的實際測試結果，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1502.03167">連結</a><br><img src="/../images/20220707_7.png"></li>
<li>紅色線是有做batch normalization</li>
<li>粉色線，使用sigmoid function</li>
<li>其他線，就是lr乘上$x$倍</li>
<li>黑色沒有用BN，用inception</li>
<li>收斂速度更快，但結果差不多</li>
</ul>
<h2 id="How-does-Batch-Normalization-help-optimization"><a href="#How-does-Batch-Normalization-help-optimization" class="headerlink" title="How does Batch Normalization help optimization?"></a>How does Batch Normalization help optimization?</h2><ul>
<li><p>下面這篇論文的作者發明這個詞”Internal covariate shift”</p>
</li>
<li><p>根據<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1805.11604">這篇論文</a>所認為有以下可能<br><img src="/../images/pasted-14.png"></p>
</li>
<li><p>我們做參數update，將A變成A’，B變成B’，但是B的變動是根據之前算出來的a作為input，當整體更新了以後，B’要面對的input卻不再是a，而是經過A’算出來的a’，故導致仍舊失準</p>
<ul>
<li>而Batch normalization的作法，是讓a跟a’有相似的分布(similar statistics)，故誤差會比較接近</li>
</ul>
</li>
<li><p>但是Experimental result並不支持這個緣故(打臉)</p>
<ul>
<li>打臉者認為實驗下來，a跟a’的分布都差不多，而且不管分布是不是差很多，影響都不大，於是這個假說是錯的(不是batch normalization的關鍵)</li>
<li>不過實驗跟理論依然證明，Batch normalization依然會改變error surface的地貌<br><img src="/../images/20220707_9.png"></li>
<li>此人認為batch normalization的發現可能是偶然(意料之外)的，但無論如何這是有用的方法<br>    - normalization有一堆方法，參考如下<br><img src="/../images/20220707_10.png"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/06/ML-2021-2-5-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E5%9B%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/06/ML-2021-2-5-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E5%9B%9B/" class="post-title-link" itemprop="url">ML_2021_2-5 類神經網路訓練不起來怎麼辦(四)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-06 22:20:08" itemprop="dateCreated datePublished" datetime="2022-07-06T22:20:08+08:00">2022-07-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>這是如何分類的短版本，長版本連結如下:<br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=fZAZUYEeIMg">連結1</a><br><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=hSXFuypLukA">連結2</a></li>
<li>這裡直接講分類是怎麼做的</li>
</ul>
<h1 id="Classification-as-Regression"><a href="#Classification-as-Regression" class="headerlink" title="Classification as Regression?"></a>Classification as Regression?</h1><p>Regression長這樣<br><img src="/../images/pasted-7.png"></p>
<ul>
<li>那classification怎麼看得像regression呢？</li>
<li>我們讓輸出的y(原本是一種類別)變成編號，跟$\hat{y}$比對</li>
<li>但這樣會有問題，class 1 跟 class 2 也不同類(loss &#x3D; 1)，但他們的loss會小於class 1 跟 class 3的錯誤預測(loss &#x3D; 2)</li>
<li>常見的做法是把class用one-hot vector來表示</li>
<li>當然，這樣我們就會希望output的y是一個向量而非純量 $\rightarrow$ 我們可以用多組的weight去做多次輸出，如下圖<br><img src="/../images/pasted-8.png"></li>
<li>我們通常會算出一個y以後，先做一個softmax(y)得到y’才去比較</li>
</ul>
<h2 id="Softmax-activate-function"><a href="#Softmax-activate-function" class="headerlink" title="Softmax activate function"></a>Softmax activate function</h2><p>公式如下<br>$$<br>y_i’ &#x3D; \frac{exp(y_i)}{\sum_{j}exp(y_i)}<br>$$<br>圖例<br><img src="/../images/pasted-9.png"><br>softmax有兩個特徵：<br>$$<br>1&gt;y_i&gt;0 \\\<br>\sum_iy_i’ &#x3D; 1<br>$$</p>
<ul>
<li>其實就是把$y_i$的各自機率算出來，若y&lt;0則機率~0</li>
</ul>
<h2 id="why-add-softmax-at-last-layer-in-classification"><a href="#why-add-softmax-at-last-layer-in-classification" class="headerlink" title="why add softmax at last layer in classification?"></a>why add softmax at last layer in classification?</h2><ul>
<li>可以參考原版錄影，因為解釋較長</li>
<li>騙小孩的說法是，因為機率是0到1之間，所以我們可以把y做softmax讓他normalize</li>
</ul>
<h3 id="Note"><a href="#Note" class="headerlink" title="Note :"></a>Note :</h3><ul>
<li>Sigmoid就是2 class版的softmax(Ref.深度學習的數學地圖)</li>
</ul>
<h1 id="分類模型的loss-function"><a href="#分類模型的loss-function" class="headerlink" title="分類模型的loss function"></a>分類模型的loss function</h1><ul>
<li>我們仍然可以採用MSE來計算</li>
<li>但更常用的作法是用cross entropy</li>
</ul>
<h2 id="cross-entropy-loss-function"><a href="#cross-entropy-loss-function" class="headerlink" title="cross entropy loss function"></a>cross entropy loss function</h2><p>公式如下<br>$$<br>e &#x3D; - \sum_i\hat{y}_ilny_i’<br>$$</p>
<ul>
<li>最小值就是當$y &#x3D; \hat{y}$</li>
<li>minimize cross entropy &#x3D; maximize likelihood</li>
<li>基本上softmax是被跟cross entropy綁在一起的，因為向性很高</li>
<li>所以如果用cross entropy當loss，那模型最後一層自動就會補上softmax當激發函數(pytorch)</li>
</ul>
<h2 id="用optimizer的角度來證實cross-entropy優於MSE"><a href="#用optimizer的角度來證實cross-entropy優於MSE" class="headerlink" title="用optimizer的角度來證實cross entropy優於MSE"></a>用optimizer的角度來證實cross entropy優於MSE</h2><ul>
<li><a target="_blank" rel="noopener" href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/MLDS_2015_2/Lecture/Deep%20More%20(v2).ecm.mp4/index.html">用數學證明的方式說明</a>請參考過去影片</li>
<li>以下用舉例的方式說明</li>
<li>已知一個模型如下圖<br><img src="/../images/pasted-10.png"><br>則MSE跟cross entropy的表現如下</li>
</ul>
<p><img src="/../images/20220706_15.png" alt="upload successful"></p>
<ul>
<li><p>用MSE的前提下，因為點就卡在高loss了，周圍很平坦，很難用梯度下降找到更好的點</p>
</li>
<li><p>這是一個透過改變loss function來改變整個error surface的例子</p>
</li>
<li><p>loss function的定義是有可能影響訓練難度的</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/06/ML-2021-2-4-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%B8%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/06/ML-2021-2-4-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%B8%89/" class="post-title-link" itemprop="url">ML_2021_2-4 類神經網路訓練不起來怎麼辦(三)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-06 14:04:41" itemprop="dateCreated datePublished" datetime="2022-07-06T14:04:41+08:00">2022-07-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>Critical point 不一定是在訓練模型時會碰到的最大問題</li>
</ul>
<h1 id="Adaptive-Learning-Rate"><a href="#Adaptive-Learning-Rate" class="headerlink" title="Adaptive Learning Rate"></a>Adaptive Learning Rate</h1><ul>
<li>我們都認為training loss卡住了之後，是因為parameters卡在critical point</li>
<li>其實有可能是loss function在兩個谷間碰撞，可能是兩組parameters之間剛好loss差不多</li>
<li>考慮一個情境，高爾夫球一直在球洞兩邊滾來滾去，就是滾不到終點<br><img src="/../images/pasted-3.png"></li>
<li>多數training其實還沒走到critical point就已經停止 (所以真正要注意的點不是critical point)</li>
</ul>
<h2 id="非卡在critical-point的Example"><a href="#非卡在critical-point的Example" class="headerlink" title="非卡在critical point的Example"></a>非卡在critical point的Example</h2><ul>
<li><p>給定一個convex error surface，如下圖<br><img src="/../images/20220706_2.png" alt="upload successful"></p>
</li>
<li><p>當learning rate太大，會容易在等高線密集的地方邁步過大，如下圖<br><img src="/../images/20220706_3.png" alt="upload successful"></p>
</li>
<li><p>或是當learning rate太小，容易卡在低谷幾乎動不了(要挪到X需要好幾百萬次更新)，如下圖<br><img src="/../images/image.png" alt="upload successful"></p>
</li>
</ul>
<p>$\rightarrow$ 單一learning rate通常不能貫徹模型訓練的整個過程</p>
<h2 id="如何設定learning-rate-Adagrad-Approach"><a href="#如何設定learning-rate-Adagrad-Approach" class="headerlink" title="如何設定learning rate? - Adagrad Approach"></a>如何設定learning rate? - Adagrad Approach</h2><ul>
<li><p>從上個例子可知，當某方向上等高線密集時，我們需要learning rate 小，反之則要大</p>
</li>
<li><p>為了讓$\eta$能自動變動，要調整公式</p>
</li>
<li><p>下圖為梯度下降法的原始公式<br><img src="/../images/20220706_4.png" alt="upload successful"></p>
</li>
<li><p>方便起見，這裡只用一個參數</p>
</li>
<li><p>更動以後的算式如下</p>
</li>
</ul>
<p>$$<br>\theta^{t+1}_i \leftarrow \theta^t_i - \frac{\eta}{\sigma^t_i} g^t_i<br>$$</p>
<ul>
<li>我們讓$\sigma^t_i$加入等式，這樣就可以讓learning rate變成一個parameter dependent的hyper parameter</li>
</ul>
<h3 id="如何計算sigma"><a href="#如何計算sigma" class="headerlink" title="如何計算sigma?"></a>如何計算sigma?</h3><p>$$<br>\theta^{1}_i \leftarrow \theta^0_i - \frac{\eta}{\sigma^0_i} g^0_i<br>$$<br>其中$\sigma^0_i &#x3D; \sqrt{(g^0_i)^2} &#x3D; \vert g^0_i \vert$<br>接下來<br>$$<br>\theta^{2}_i \leftarrow \theta^1_i - \frac{\eta}{\sigma^0_i} g^1_i<br>$$<br>其中$\sigma^1_i &#x3D; \sqrt{\frac{1}{2}[(g^0_i)^2+(g^1_i)^2]}$</p>
<p>…<br>一路推廣，可以得到</p>
<p>$$<br>\theta^{t+1}_i \leftarrow \theta^t_i - \frac{\eta}{\sigma^t_i} g^t_i<br>$$</p>
<p>其中</p>
<p>$$<br>\sigma^t_i &#x3D; \sqrt{\frac{1}{t+1}\sum_{j&#x3D;0}^{t}(g_i^j)^2}<br>$$</p>
<ul>
<li>目前這個技巧應用在Adagrad</li>
</ul>
<h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><ul>
<li>當gradient小(平坦)，算出來的$\sigma$就小，learning rate大</li>
<li>當gradient大(陡峭)，算出來的$\sigma$就大，learning rate小<br><img src="/../images/pasted-4.png"></li>
</ul>
<h3 id="這樣會有甚麼問題"><a href="#這樣會有甚麼問題" class="headerlink" title="這樣會有甚麼問題"></a>這樣會有甚麼問題</h3><ul>
<li>剛才的假設是同一個參數，他的gradient大小就固定一個值(?)</li>
<li>就算是同一個參數，他需要的learning rate也會隨時間而改變</li>
<li>我們期待就算是同一個參數在同一個方向，learning rate也會有所改變<br>舉例，我們討論橫軸</li>
</ul>
<p><img src="/../images/20220706_5.png" alt="upload successful"></p>
<hr>
<h2 id="如何設定learning-rate-RMSProp-Approach"><a href="#如何設定learning-rate-RMSProp-Approach" class="headerlink" title="如何設定learning rate? - RMSProp Approach"></a>如何設定learning rate? - RMSProp Approach</h2><ul>
<li>一個沒有論文的方法orz</li>
<li>方法如下圖<br><img src="/../images/pasted-5.png"></li>
<li>主要改變了紅圈圈起來的部分，捨棄了用前面所有的gradient求MSE決定$\sigma$的方法，RMSProp只採計上一個$\sigma$值以及這次的gradient之MSE和</li>
<li>多了一個hyper parameter $alpha$，調整對上一個$\sigma$的學習率高低</li>
<li>其實上一個$\sigma$就包含了前面所有的gradient之MSE，只是權重會隨著疊代越來越小</li>
</ul>
<p>learning rate變動範例圖<br><img src="/../images/20220706_7.png"></p>
<h2 id="回到一開始的範例"><a href="#回到一開始的範例" class="headerlink" title="回到一開始的範例"></a>回到一開始的範例</h2><ul>
<li>[回到這個範例](# 非卡在critical point的Example)，我們來看看各approach的效果</li>
</ul>
<h4 id="Adaptive-learning-rate"><a href="#Adaptive-learning-rate" class="headerlink" title="Adaptive learning rate"></a>Adaptive learning rate</h4><p><img src="/../images/pasted-6.png" alt="filename already exists, renamed"></p>
<ul>
<li>為啥爆炸了?<ul>
<li>根據公式，我們把前面幾次的gradient都列入計算，因為在橫線的部分步伐很大，所以當走到步伐該縮小的時候，會爆衝<br>    - 但也因為公式，爆衝一陣子以後learning rate會逐漸縮小，然後回歸正軌，等待一陣子以後learning rate上升再度爆炸</li>
</ul>
</li>
</ul>
<h5 id="解法：learning-rate-decay"><a href="#解法：learning-rate-decay" class="headerlink" title="解法：learning rate decay"></a>解法：learning rate decay</h5><ul>
<li>隨著訓練的進行，我們一定越來越接近終點</li>
<li>可以隨著時間降低learning rate，開始微調</li>
</ul>
<h5 id="解法2：Warm-up"><a href="#解法2：Warm-up" class="headerlink" title="解法2：Warm up"></a>解法2：Warm up</h5><p><img src="/../images/20220706_10.png"></p>
<ul>
<li>算是一種黑科技</li>
<li>先變大learning rate，再縮小(?)</li>
<li>在訓練bert的時候常常用到，但他在很久以前就出現在<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385">論文</a>過了</li>
<li>在transformer中也出現過，見下圖<br><img src="/../images/20220706_11.png"></li>
<li>一種可能的解釋是，因為$\sigma$是統計的數據，在訓練初期的時候容易失準，故初期讓learning rate小，等到$\sigma$精準一點以後，再讓learning rate變高</li>
<li>相關paper : <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1908.03265">RAdam</a></li>
</ul>
<h2 id="Summary-of-Optimization"><a href="#Summary-of-Optimization" class="headerlink" title="Summary of Optimization"></a>Summary of Optimization</h2><p><img src="/../images/20220706_12.png"></p>
<ul>
<li>雖然Momentum跟$\sigma$都使用過去的資料，但不會因此抵銷<ul>
<li>Momentum是把所有gradient加起來，故有考慮方向與正負號</li>
<li>$\sigma$只考慮MSE</li>
</ul>
</li>
</ul>
<h2 id="下次預告"><a href="#下次預告" class="headerlink" title="下次預告"></a>下次預告</h2><ul>
<li>當訓練過程遭遇大山，要如何闢路繞過去？</li>
<li>有沒有可能直接炸掉大山，改變error surface呢?<br>$\rightarrow$ Batch normalization<br>PS. 課程跳到2-6哦</li>
</ul>
<hr>
<h1 id="Note"><a href="#Note" class="headerlink" title="Note"></a>Note</h1><ul>
<li><p>現今最常見的Optimizer:Adam其實就是RMSProp + Momentum</p>
</li>
<li><p>Adam的細節自行參考</p>
</li>
<li><p>arxiv論文年代看法</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1512.03385%E7%82%BA%E4%BE%8B">https://arxiv.org/abs/1512.03385為例</a><br>    - 15代表2015年出版<br>    - 12代表12月</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/05/ML-2021-2-3-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BA%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/05/ML-2021-2-3-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%BA%8C/" class="post-title-link" itemprop="url">ML_2021_2-3 類神經網路訓練不起來怎麼辦(二)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-05 21:59:49" itemprop="dateCreated datePublished" datetime="2022-07-05T21:59:49+08:00">2022-07-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><ul>
<li>之前課程(Ref. 2021版1-1)說到，在實際train data時我們不是實際把所有Data算出來對L微分求loss，而是把Data先分組切成batch，而所有batch看過一遍，才叫1 epoch</li>
<li>我們可以設定shuffle，就是每個不同的epoch，data都會重新分組</li>
</ul>
<h1 id="Batch-size對模型之影響"><a href="#Batch-size對模型之影響" class="headerlink" title="Batch size對模型之影響"></a>Batch size對模型之影響</h1><ul>
<li>首先比較兩個case：<br><img src="/../images/20220705_2.png"></li>
<li>左邊沒有用batch，而右邊batch size &#x3D; 1</li>
<li>左邊表示每次必須看完所有data，參數才能更新一次；右邊則相反，每看完一個data就更新一次參數</li>
<li>一個是重攻擊長CD，一個是輕攻擊短CD (?)</li>
</ul>
<h2 id="大batch優缺"><a href="#大batch優缺" class="headerlink" title="大batch優缺"></a>大batch優缺</h2><h5 id="優點"><a href="#優點" class="headerlink" title="優點"></a>優點</h5><ul>
<li>威力大(更新幅度大)且每步都很穩</li>
</ul>
<h5 id="缺點"><a href="#缺點" class="headerlink" title="缺點"></a>缺點</h5><ul>
<li>超級慢<br>(小batch優缺則顛倒)</li>
</ul>
<h2 id="small-batch-or-big-batch"><a href="#small-batch-or-big-batch" class="headerlink" title="small batch or big batch?"></a>small batch or big batch?</h2><ul>
<li>兩邊看似各自相對，但我們還沒考慮平行運算</li>
<li>若考慮多核心，其實大batch不會比較慢</li>
<li>以下圖為例，用tesla V100 GPU，batch size到1000都很合適(梯度法)<br><img src="/../images/20220705_1.png"></li>
<li>因為高batch不一定更花時間，所以其實在平行運算下，大batch的每epoch速度甚至還比小epoch還快</li>
<li>不過，就算是平行運算下，大batch一定比較好嗎?<ul>
<li>與直覺相反的是，noisy大有時候反而可以促進訓練能力(如下圖)</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220705_3.png" alt="upload successful"></p>
<ul>
<li>相同model(同bias)下，smaller batch size有更高的performance</li>
<li>問題來源於optimizer fails(Ref. 2021版2-2關於如何判定問題是哪種)</li>
</ul>
<h2 id="為何small-batch-size可以有更好的結果？"><a href="#為何small-batch-size可以有更好的結果？" class="headerlink" title="為何small batch size可以有更好的結果？"></a>為何small batch size可以有更好的結果？</h2><ul>
<li>一說是Noisy update is better for training<br>見下圖</li>
</ul>
<p><img src="/../images/pasted-1.png"><br>small batch下，或許$L^1$卡住了，但是因為$L^2$跟$L^1$有不小的差距，所以剛好可以讓參數更新然後把參數撞開critical point</p>
<h3 id="small-batch-still-better-for-testing-data"><a href="#small-batch-still-better-for-testing-data" class="headerlink" title="small batch still better for testing data?"></a>small batch still better for testing data?</h3><ul>
<li>我們知道了small batch在training set表現更好，那testing data是否也是如此呢?</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1609.04836">根據這篇論文</a>，可以知道small batch在測試資料也有好表現</li>
</ul>
<p><img src="/../images/20220705_4.png" alt="upload successful"></p>
<ul>
<li>就算能把big batch model的準確率練到跟small batch model差不多(調hyper parameter)，在測試時也會有差距顯現 $\rightarrow$ big batch有overfitting問題<br>目前普遍認為的原因如下：<ul>
<li>就算是卡在local minima，也有分好壞</li>
<li>周圍平坦的local minima較好</li>
<li>而論文認為大batch size傾向會讓我們走向尖銳的minima point<ul>
<li>一種說法是，小batch size更動頻繁走向豐富，容易走出周圍很高的minima point(對於逃離critical point能力較高)，而停在平坦的minima point (Ref. 2021版2-2 鞍點)</li>
</ul>
<p>	</p>
</li>
<li>因為testing 跟 training的loss function，肯定會有所小偏差，如下圖<br><img src="/../images/20220705_6.png" alt="upload successful"></li>
</ul>
</li>
</ul>
<h2 id="Summary：Batch-comparasion"><a href="#Summary：Batch-comparasion" class="headerlink" title="Summary：Batch comparasion"></a>Summary：Batch comparasion</h2><p><img src="/../images/20220705_7.png" alt="upload successful"></p>
<ul>
<li>因此，batch size最終成為了一個hyper parameter</li>
</ul>
<h2 id="魚與熊掌兼得的辦法"><a href="#魚與熊掌兼得的辦法" class="headerlink" title="魚與熊掌兼得的辦法?"></a>魚與熊掌兼得的辦法?</h2><ul>
<li>看ref啃論文  &#x3D; &#x3D;</li>
</ul>
<hr>
<h1 id="另一個對抗saddle-point或minima的技術-momentum"><a href="#另一個對抗saddle-point或minima的技術-momentum" class="headerlink" title="另一個對抗saddle point或minima的技術 : momentum"></a>另一個對抗saddle point或minima的技術 : momentum</h1><ul>
<li>當small gradient的時候，我們走到一個鞍點或局部最小點之後就會停下來</li>
<li>但我們可以用物理式來思考，球由高處滾下來到最低點碰到上坡，不一定會停下來，因為有動能</li>
</ul>
<h2 id="Review-原本的梯度下降"><a href="#Review-原本的梯度下降" class="headerlink" title="Review : 原本的梯度下降"></a>Review : 原本的梯度下降</h2><p><img src="/../images/pasted-2.png"></p>
<h2 id="梯度下降-momentum"><a href="#梯度下降-momentum" class="headerlink" title="梯度下降+momentum"></a>梯度下降+momentum</h2><ul>
<li>簡單來說，就是加入慣性，額外參考上一次的移動軌跡</li>
</ul>
<p><img src="/../images/20220706_8.png" alt="upload successful"></p>
<ul>
<li>多了一個hyper parameter $\lambda$<br><img src="/../images/20220706_9.png" alt="upload successful"></li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/04/ML-2022-2-1-%E5%86%8D%E6%8E%A2%E5%AF%B6%E5%8F%AF%E5%A4%A2%E3%80%81%E6%95%B8%E7%A2%BC%E5%AF%B6%E8%B2%9D%E5%88%86%E9%A1%9E%E5%99%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/04/ML-2022-2-1-%E5%86%8D%E6%8E%A2%E5%AF%B6%E5%8F%AF%E5%A4%A2%E3%80%81%E6%95%B8%E7%A2%BC%E5%AF%B6%E8%B2%9D%E5%88%86%E9%A1%9E%E5%99%A8/" class="post-title-link" itemprop="url">ML_2022_2-1 再探寶可夢、數碼寶貝分類器</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-04 22:24:04" itemprop="dateCreated datePublished" datetime="2022-07-04T22:24:04+08:00">2022-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/04/ML-2021-2-2-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%B8%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/04/ML-2021-2-2-%E9%A1%9E%E7%A5%9E%E7%B6%93%E7%B6%B2%E8%B7%AF%E8%A8%93%E7%B7%B4%E4%B8%8D%E8%B5%B7%E4%BE%86%E6%80%8E%E9%BA%BC%E8%BE%A6-%E4%B8%80/" class="post-title-link" itemprop="url">ML_2021_2-2 類神經網路訓練不起來怎麼辦(一)</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-04 22:22:35" itemprop="dateCreated datePublished" datetime="2022-07-04T22:22:35+08:00">2022-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><p>這裡只討論optimazion失靈的時候，如何把梯度下降做得更好</p>
<h2 id="為何opti會失敗（grad）？"><a href="#為何opti會失敗（grad）？" class="headerlink" title="為何opti會失敗（grad）？"></a>為何opti會失敗（grad）？</h2><ul>
<li>gradient decent&#x3D;0，使參數無法再更新</li>
<li>點卡在local minima or saddle point(稱為卡在critical point)</li>
</ul>
<h3 id="分辨critical-point是saddle-point-or-local-minima"><a href="#分辨critical-point是saddle-point-or-local-minima" class="headerlink" title="分辨critical point是saddle point or local minima"></a>分辨critical point是saddle point or local minima</h3><ul>
<li>雖然我們無法知道loss function長怎樣，但可以用泰勒展開式逼近</li>
<li>給定一組參數$\theta’$</li>
<li>則使用tayler series approximation<br>原式為<br>$$<br>f(x) &#x3D; f(a) + \frac{f’(a)}{1!}(x-a) + \frac{f’’(a)}{2!}(x-a)^2 + ….<br>$$<br>我們取到2次微分，代入$x &#x3D; \theta及a &#x3D; \theta’$得到<br>$$<br>L(\theta) \sim L(\theta’)^Tg + \frac{1}{2}(\theta - \theta’)^TH(\theta - \theta’)<br>,其中 g &#x3D; \nabla L(\theta’)(請參考上週)<br>$$</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220704_1.png"></p>
<ul>
<li><p>其實g就是$L(\theta’)$對$\theta_i$的一階微分，Hessian是$L(\theta’)$對$\theta_{ij}$做二次微分</p>
</li>
<li><p>因為critical point的時候g &#x3D; 0，所以我們要考慮H(也就是2次微分的部分)來分辨是哪種問題，2次微分可以看出地貌<br>把Hessian部分拉出來討論<br><img src="/../images/20220704_3.png"><br>要如何確認滿足哪個原因呢?</p>
<ul>
<li>線性代數：正定、負定、均非 (看H的eigen value)</li>
</ul>
<h3 id="範例說明"><a href="#範例說明" class="headerlink" title="範例說明"></a>範例說明</h3></li>
<li><p>給定一個模型$y &#x3D; w_1w_2x$，資料僅有一筆，$f(1)$時其label &#x3D; 1，且w1w2之間不具有任何激發函數，loss function採用MSE</p>
</li>
<li><p>則x&#x3D;1時透過爆搜我們可以得出下面的error surface(偷偷看正解圖)<br><img src="/../images/20220704_2.png"></p>
</li>
<li><p>其中鞍點的四周都是高牆，無法離開</p>
</li>
<li><p>局部最小點則是在範圍內找不到更低的點</p>
</li>
<li><p>但假設我們不知道這個error surface，我們可以應用上面的方法來測定他是哪個問題，根據MSE公式我們得出<br>$$<br>L &#x3D; (\hat{y}-w_1w_2x)^2 &#x3D; (1-w_1w_2)^2<br>$$<br>對他們做微分可以得到(注意chain rule)<br>$$<br>g &#x3D; \frac{\partial L}{\partial w_1} &#x3D; 2(1-w_1w_2)(-w_2)<br>$$<br>$$<br>g &#x3D; \frac{\partial L}{\partial w_2} &#x3D; 2(1-w_1w_2)(-w_1)<br>$$<br>代入g&#x3D;0，可以發現當$w_1 &#x3D; w_2 &#x3D; 0$，有critical point<br>接下來要確認他們是哪個問題，就繼續再做微分:<br><img src="/../images/20220704_5.png"><br>代入剛剛的$w_1 &#x3D; w_2 &#x3D; 0$得到<br>$$<br>H &#x3D;  <br>\left[<br>\begin{matrix}<br>     0 &amp;&amp; -2 \\\ -2 &amp;&amp; 0<br>\end{matrix}<br>\right] \tag{3}<br>$$<br>抓H的eigen values來知道他是哪個point</p>
</li>
</ul>
<h2 id="case-saddle-point"><a href="#case-saddle-point" class="headerlink" title="case: saddle point"></a>case: saddle point</h2><ul>
<li>我們可以藉由H來得到參數該移動的方向<br>令$\lambda$是H的一個eigen value, u為$\lambda$的其中一個eigen vector<br>則<br>$$<br>v^THv &#x3D; u^THu &#x3D; u^T(\lambda u) &#x3D; \lambda \vert \vert u \vert \vert^2<br>$$<br>若今天$\lambda &lt; 0$則必定$u^THu&lt;0$，回顧剛剛的式子<br>$$<br>L(\theta) \sim L(\theta’)^Tg + \frac{1}{2}(\theta - \theta’)^TH(\theta - \theta’)<br>$$<br>可以知道$L(\theta)必定&gt;L(\theta’)$<br><img src="/../images/20220704_6.png"><br>我們只要將$\theta’沿著u的方向更新u得到\theta$，就可以再次降低loss</li>
</ul>
<h3 id="範例說明-1"><a href="#範例說明-1" class="headerlink" title="範例說明"></a>範例說明</h3><ul>
<li>延續剛剛的例子，我們知道$H的\lambda_1 &#x3D; 2, \lambda_2 &#x3D;-2$，屬於saddle point(非正定與負定)</li>
<li>取$\lambda_2 &#x3D; -2 , u &#x3D; (1,1)$，則把$\theta &#x3D; (0,0)+(1,1)$，就可以逃出saddle point</li>
<li>實務上不易使用，因為要做出2次微分且還需要用到找出該矩陣的eigen value，計算量過大 (還有別招可以用)</li>
</ul>
<h2 id="Saddle-point-vs-Local-Minima"><a href="#Saddle-point-vs-Local-Minima" class="headerlink" title="Saddle point vs. Local Minima"></a>Saddle point vs. Local Minima</h2><ul>
<li>在三維的密閉石棺中，在更高維度未必是密閉的</li>
<li>在低維度的local minima中，是否只是高維中的saddle point? </li>
<li>當參數超級多，是否極度有可能local minima其實只是saddle point? (假說)</li>
<li>在實作中，絕大多數的模型，critical point所在點中，幾乎找不到所有eigen value均&gt;0的範例，表示我們幾乎不可能找到完全的local minima</li>
<li>定義一個數值”Minimum ratio &#x3D; $\frac{正\lambda數}{\lambda數}$”，表示你的critical point有多像local minima</li>
<li>所以我們可以知道，通常一個模型train到loss卡住，極高可能是卡在一個saddle point</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/04/ML-2021-2-1-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E4%BB%BB%E5%8B%99%E6%94%BB%E7%95%A5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/04/ML-2021-2-1-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92%E4%BB%BB%E5%8B%99%E6%94%BB%E7%95%A5/" class="post-title-link" itemprop="url">ML_2021_2-1 機器學習任務攻略</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-04 22:20:49" itemprop="dateCreated datePublished" datetime="2022-07-04T22:20:49+08:00">2022-07-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="機器學習任務攻略"><a href="#機器學習任務攻略" class="headerlink" title="機器學習任務攻略"></a>機器學習任務攻略</h2><p><img src="/../images/202200703_7.png"><br>  - 當有一個模型的表現不佳，有時候不一定是overfitting的問題<br>  - 問題來源可能有數種<br>    - Model Bias：模型本身的彈性不足，值域過小導致找不到最佳解<br>    - Optimization Issue：模型的彈性是夠的，也就是$f^*(x)$存在，只是因為optimizer不給力，始終無法把$\theta$帶到loss更小的地方</p>
<h2 id="如何分辨是model-bias-issue-or-Optimization-issue"><a href="#如何分辨是model-bias-issue-or-Optimization-issue" class="headerlink" title="如何分辨是model bias issue or Optimization issue?"></a>如何分辨是model bias issue or Optimization issue?</h2><p>  - 以下圖為例<br><img src="/../images/20220703_1.png"></p>
<ul>
<li>通常我們會認為這是模型overfitting了，才會導致層數增加反倒命中率下降</li>
<li>overfitting固然有可能，但它不是唯一的可能性，我們應該要從訓練資料的loss下手<br><img src="/../images/20220703_2.png"></li>
<li>可以發現就算是訓練資料，56層的loss也是大於20層的，故排除overfitting的可能</li>
<li>至於模型彈性這個可能也可以排除，因為56層的複雜度&gt;20層，故56層的loss只可能比20層還小，若是顛倒的話表示應該不是模型彈性問題，而是optimizer的鍋</li>
</ul>
<hr>
<ul>
<li>若是發現類似優化器的問題，可以試試看先跑一些比較淺層的model或是簡易的model(如linear regression)，先觀察得出來的結果</li>
<li>再跑深度的model，比較他們的結果，若深度的結果沒比較好，可以考慮換optimizer<br>原因樹狀圖(?<br><img src="/../images/20220703_3.png"></li>
</ul>
<h2 id="Overfitting的成因"><a href="#Overfitting的成因" class="headerlink" title="Overfitting的成因"></a>Overfitting的成因</h2><p><img src="/../images/20220703_4.png"></p>
<ol>
<li>若訓練資料不足，模型彈性過高也可能導致overfitting(增加training data最有效)<ul>
<li>data augmentation也是一種方法(ex.圖片翻轉作為新資料)</li>
</ul>
</li>
<li>降低模型的彈性也可以降低這個可能</li>
<li>採用一些技巧<ul>
<li>Early stopping</li>
<li>Regularization</li>
<li>Dropout</li>
<li>Less features</li>
</ul>
</li>
</ol>
<h2 id="衡量模型"><a href="#衡量模型" class="headerlink" title="衡量模型"></a>衡量模型</h2><ul>
<li>或許某個model在所有model裡面test成績最突出，但它未必會真的是最好的模型(運氣問題)<br><img src="/../images/20220703_5.png"></li>
<li>極端範例，一個模型剛好隨機出了最好的結果</li>
<li>所以testing set有分public跟private，避免一直上傳模型賭出最好成績</li>
</ul>
<h3 id="N-fold-Cross-Validation"><a href="#N-fold-Cross-Validation" class="headerlink" title="N-fold Cross Validation"></a>N-fold Cross Validation</h3><ul>
<li>把train set切成3份，2份是training data，1份是val data</li>
<li>交叉身分去訓練n次</li>
</ul>
<p><img src="/../images/20220703_6.png" alt="upload successful"></p>
<h4 id="data-mismatch"><a href="#data-mismatch" class="headerlink" title="data mismatch"></a>data mismatch</h4><ul>
<li>training data 跟 testing data有不同分布</li>
<li>ex. 機器學習2020年觀看人數預測2021年觀看人數，很高可能會mismatch</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一頁"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">劉宇承</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
