<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css" integrity="sha256-xejo6yLi6vGtAjcMIsY8BHdKsLg7QynVlFMzdQgUuy8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"laxiflora.github.io","root":"/","images":"/images","scheme":"Muse","darkmode":true,"version":"8.12.3","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="laxiflora的小天地">
<meta property="og:url" content="https://laxiflora.github.io/page/2/index.html">
<meta property="og:site_name" content="laxiflora的小天地">
<meta property="og:locale" content="zh_TW">
<meta property="article:author" content="劉宇承">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://laxiflora.github.io/page/2/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-TW","comments":"","permalink":"","path":"page/2/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>laxiflora的小天地</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">laxiflora的小天地</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">前進軟體工程師的練功之路</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>歸檔</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">劉宇承</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">41</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="回到頂端">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/04/ML-LEE-2022-hw6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/04/ML-LEE-2022-hw6/" class="post-title-link" itemprop="url">ML_LEE_2022_hw6</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-04 11:58:16" itemprop="dateCreated datePublished" datetime="2022-08-04T11:58:16+08:00">2022-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-17 19:31:50" itemprop="dateModified" datetime="2022-08-17T19:31:50+08:00">2022-08-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Task-introduction"><a href="#Task-introduction" class="headerlink" title="Task introduction"></a>Task introduction</h1><ul>
<li>GAN：project some random variables into specific space</li>
<li>必須實作：DCGAN、WGAN、WGAN-GP</li>
<li>產生1000張動漫人臉<ul>
<li>&lt;number&gt;.jpg</li>
</ul>
</li>
</ul>
<h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><ul>
<li>從Crypko爬下來的</li>
<li>71,314張pictures<br>faces<br>|<br>|_0.jpg<br>|_1.jpg<br>|<br>…</li>
</ul>
<h2 id="Evaluation-metrics"><a href="#Evaluation-metrics" class="headerlink" title="Evaluation metrics"></a>Evaluation metrics</h2><ol>
<li>FID score</li>
<li>AFD rate,表示多少張圖片能被辯認為動漫頭像</li>
</ol>
<h2 id="Baseline"><a href="#Baseline" class="headerlink" title="Baseline"></a>Baseline</h2><p><img src="/../images/pasted-47.png"><br>Simple：SAMPLE CODE(DCGAN) , train 1 hr<br>Medium：DCGAN with more epochs , train 1<del>1.5 hr<br>Strong：WGAN &#x2F; WGAN-GP , train 2</del>3 hr<br>Boss：StyleGAN , train &lt; 5 hr</p>
<h2 id="Report-Question"><a href="#Report-Question" class="headerlink" title="Report Question"></a>Report Question</h2><p><img src="/../images/20220817_7.png"></p>
<ol>
<li>列出WGAN跟GAN的兩大差異</li>
<li>畫出WGAN跟WGAN-GP的gradient norm結果</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.2661">GAN</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1701.07875">WGAN</a></li>
</ul>
<h3 id="WGAN-amp-WGAN-GP"><a href="#WGAN-amp-WGAN-GP" class="headerlink" title="WGAN &amp; WGAN-GP"></a>WGAN &amp; WGAN-GP</h3><p><img src="/../images/20220817_8.png"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/wgan/wgan.py">WGAN link</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/wgan_gp/wgan_gp.py">WGAN-GP link</a></li>
</ul>
<h3 id="Style-GAN"><a href="#Style-GAN" class="headerlink" title="Style-GAN"></a>Style-GAN</h3><p><a target="_blank" rel="noopener" href="https://github.com/lucidrains/stylegan2-pytorch">link</a></p>
<hr>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/04/ML-LEE-2022-hw5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/04/ML-LEE-2022-hw5/" class="post-title-link" itemprop="url">ML_LEE_2022_hw5</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-04 11:58:13" itemprop="dateCreated datePublished" datetime="2022-08-04T11:58:13+08:00">2022-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><p>本次作業使用judgeboi</p>
</li>
<li><p>translate english to chinese</p>
</li>
</ul>
<h1 id="作業講解"><a href="#作業講解" class="headerlink" title="作業講解"></a>作業講解</h1><h2 id="datasets"><a href="#datasets" class="headerlink" title="datasets"></a>datasets</h2><ul>
<li>(en,zh-tw) paired data</li>
</ul>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><ul>
<li>BLEU score</li>
<li>本次會需要對training data做一些preprocessing(norm,刪除極端資料)</li>
</ul>
<h2 id="技巧"><a href="#技巧" class="headerlink" title="技巧"></a>技巧</h2><ul>
<li>label smoothing</li>
<li>tokenize</li>
<li>lr scheduling (warm-up , 遞減lr)</li>
<li>back translation (中英，英中都train)<ul>
<li>不同語言的data需要保持在同一個維度<br>    - backward model的表現很重要<br>    - model capacity will increase，since data amount increased</li>
</ul>
</li>
</ul>
<h2 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h2><p><img src="/../images/20220804_1.png"></p>
<p>Simple: Train RNN seq2seq (Sample code)<br>Medium: add lr scheduler, train longer<br>Strong: 使用transformer, tuning hyperparameter<br>Boss: Apply back-translation</p>
<p>Note: 助教的ppt有建議hyperparameter</p>
<h2 id="Report"><a href="#Report" class="headerlink" title="Report"></a>Report</h2><p><img src="/../images/20220804_2.png"></p>
<ul>
<li>問題一：要visualize positional embedding，用一個2維matrix表示	(cosine similarity)<ul>
<li>可以從decoder得到，使用<code>pos_emb = model.decoder.embed_positions.weights.cpu().detech()</code><br>    	- torch.size([1026,256]) (256維)<br>    - 推薦使用cosine similarity</li>
</ul>
</li>
<li>問題二：實作Clipping Gradient norm 並顯示出gradient norm<ul>
<li>避免梯度爆炸</li>
<li>Gradient norm: 把每個參數的gradient收集起來變成vector，對他們計算p-norm</li>
<li>作法：<br>        1. 設定一個最大值max_norm<br>       2. 收集paras，並計算他們的p-norm，命結果為Lnorm<br>       3. 如果Lnorm &gt; max_norm，則計算scale_factor &#x3D; max_norm &#x2F; Lnorm，並對每個gradient乘上scale_factor<ul>
<li>設定max_norm &#x3D; 1.0</li>
<li>Apply plot of “gradient norm v.s step”，並圈出Lnorm &gt; max_norm的地方</li>
</ul>
</li>
<li>助教的code已經有算出gnorm了，我們要把它儲存起來，才能在training結束的時候具現化它</li>
</ul>
</li>
</ul>
<hr>
<h1 id="寫作業歷程"><a href="#寫作業歷程" class="headerlink" title="寫作業歷程"></a>寫作業歷程</h1><p>這份作業無法繳交了，因為judgeboi已經關起來了qq，只能直接在本機用test data去驗證BLEU分數</p>
<h2 id="觀察Sample-Code"><a href="#觀察Sample-Code" class="headerlink" title="觀察Sample Code"></a>觀察Sample Code</h2><p>首先，來研究一下助教的code，整個notebook分為幾大片段：</p>
<ol>
<li><p>下載資料集以及import packages</p>
<ul>
<li>資料集來自fairseq</li>
</ul>
</li>
<li><p>對資料集內容做前處理(clean_corpus)</p>
<ul>
<li>移除一些垃圾字元<ul>
<li>移除特殊符號</li>
<li>如果是中文，把全形轉換成半形</li>
</ul>
</li>
<li>移除過長或過短的字詞<ul>
<li>min &#x3D; 1</li>
<li>max &#x3D; 1000</li>
</ul>
</li>
<li>輸出<code>train_dev.clean.zh/en</code></li>
</ul>
</li>
<li><p>切割valid&#x2F;training set</p>
<ul>
<li>1:99</li>
<li>輸出 <code>train.clean.zh/en , valid.clean.zh/en </code> 4檔案</li>
</ul>
</li>
<li><p>處理OOV問題</p>
<ul>
<li>使用<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/159200073">sentencepiece</a></li>
</ul>
</li>
</ol>
<p>至此資料處理完成</p>
<ol start="5">
<li><p>模型定義</p>
<ul>
<li>fairseq?</li>
<li>預設RNN的encoder,decoder</li>
<li>大模型class由seq2seq包裝</li>
</ul>
<p> 實際instance長這樣：</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HINT: <span class="doctag">TODO:</span> switch to TransformerEncoder &amp; TransformerDecoder</span></span><br><span class="line">encoder = RNNEncoder(args, src_dict, encoder_embed_tokens)</span><br><span class="line">decoder = RNNDecoder(args, tgt_dict, decoder_embed_tokens)</span><br><span class="line"><span class="comment"># encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)</span></span><br><span class="line"><span class="comment"># decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># sequence to sequence model</span></span><br><span class="line">model = Seq2Seq(args, encoder, decoder)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>所以要做的就是自己做一如下面的TransformerEncoder&#x2F;Decoder，取代原本的RNN<br>助教強調對於seq2seq任務來說，init非常重要，下方的初始化會需要做出相對應的調整</p>
<ol start="6">
<li><p>Optimizer &amp; learning rate schaduling</p>
<ul>
<li>lr這塊需要套公式，公式有給</li>
</ul>
<p> 至此模型初始化完成</p>
</li>
<li><p>Traing step</p>
<ul>
<li>這裡沒什麼要注意的了</li>
<li>觀察一下要如何完成report</li>
</ul>
</li>
</ol>
<h2 id="First-Approach"><a href="#First-Approach" class="headerlink" title="First Approach"></a>First Approach</h2><p>直接run sample code，觀察運作方式<br>BLEU score &#x3D; 16.08</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2022-08-04 07:04:07 | INFO | hw5.seq2seq | BLEU = 16.08 43.4/21.3/11.4/6.3 (BP = 1.000 ratio = 1.009 hyp_len = 112803 ref_len = 111811)</span><br><span class="line">2022-08-04 07:04:07 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/checkpoints/rnn/checkpoint15.pt</span><br><span class="line">2022-08-04 07:04:07 | INFO | hw5.seq2seq | end of epoch 15</span><br></pre></td></tr></table></figure>

<h2 id="Second-Approach"><a href="#Second-Approach" class="headerlink" title="Second Approach"></a>Second Approach</h2><ul>
<li>把encoder, decoder註解拿掉，由RNN改成Transformer</li>
</ul>
<h3 id="hyperparameter修正"><a href="#hyperparameter修正" class="headerlink" title="hyperparameter修正"></a>hyperparameter修正</h3><ul>
<li>參考<a href="">attention is all you need</a>的table 3</li>
</ul>
<p><img src="/images/20220804_5.png?20x20"><br>其中：</p>
<ul>
<li>$P_{drop}$ &#x3D; Residual Drop</li>
<li>$d_{ff&#x2F;v&#x2F;k&#x2F;model}$ &#x3D; dimension of fast-forward&#x2F;key&#x2F;value&#x2F;model</li>
<li>N &#x3D; layer數</li>
<li>$\epsilon_{ls}$ &#x3D; label smoothing rate</li>
</ul>
<p>我照著Base版修改hp</p>
<ul>
<li>encoder&#x2F;decoder_embed_dim &#x3D; 512</li>
<li>encoder&#x2F;decoder_ffn_embed_dim &#x3D; 2048</li>
<li>encoder&#x2F;decoder_layers &#x3D; 6</li>
<li>args.encoder&#x2F;decoder_attention_head &#x3D; 8 (太高也不好)</li>
</ul>
<h3 id="修改learning-rate-公式"><a href="#修改learning-rate-公式" class="headerlink" title="修改learning rate 公式"></a>修改learning rate 公式</h3><p><code>lr = pow(d_model,-0.5)*min( pow(step_num,-0.5), step_num* pow(warmup_step,-1.5) )</code></p>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2022-08-04 16:04:59 | INFO | hw5.seq2seq | BLEU = 25.50 59.7/34.3/20.6/13.0 (BP = 0.937 ratio = 0.939 hyp_len = 105012 ref_len = 111811)</span><br><span class="line">2022-08-04 16:05:00 | INFO | hw5.seq2seq | saved epoch checkpoint: /content/checkpoints/rnn/checkpoint15.pt</span><br><span class="line">2022-08-04 16:05:00 | INFO | hw5.seq2seq | end of epoch 15</span><br></pre></td></tr></table></figure>
<p>有達到strong base line了，不過還沒做報告</p>
<h2 id="Third-Approach"><a href="#Third-Approach" class="headerlink" title="Third Approach"></a>Third Approach</h2><p>之前沒有為完成report寫一些額外的code，這次把他補上了</p>
<h3 id="Prob1-visualize-positional-embedding"><a href="#Prob1-visualize-positional-embedding" class="headerlink" title="Prob1:visualize positional embedding"></a>Prob1:visualize positional embedding</h3><p>參考了<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42369818/article/details/124102920">這篇網誌</a>中的Report 1，自己做雖然有成功detach，但並不知道後續該怎麼做…對於CosineSimilarity與tensor dimention的掌握度不足..完全沒想到要用unsqueeze</p>
<h3 id="Prob2-實作Clipping-Gradient-norm-並顯示出gradient-norm"><a href="#Prob2-實作Clipping-Gradient-norm-並顯示出gradient-norm" class="headerlink" title="Prob2:實作Clipping Gradient norm 並顯示出gradient norm"></a>Prob2:實作Clipping Gradient norm 並顯示出gradient norm</h3><p>其實clipping gradient norm助教已經寫好了，我做的只是把每個step的gnorm存到一個list gnormList裡面，然後再把它丟進圖表裡面印出來</p>
<h3 id="Mount-google-drive"><a href="#Mount-google-drive" class="headerlink" title="Mount google drive"></a>Mount google drive</h3><p>有鑑於上次的大暴死，這次決定把epoch的cache保存在自己的雲端硬碟而非放在colab裡面<br>不然連線階段一個過期，整個檔案會被刪除，就算有save model都沒救…</p>
<h3 id="Result-1"><a href="#Result-1" class="headerlink" title="Result"></a>Result</h3><p>BLEU score &#x3D; 25.63</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">2022-08-05 13:10:14 | INFO | hw5.seq2seq | example source: so we&#x27;re hoping that&#x27;s what they&#x27;ll do .</span><br><span class="line">2022-08-05 13:10:14 | INFO | hw5.seq2seq | example hypothesis: 我們希望他們能做到這點 。</span><br><span class="line">2022-08-05 13:10:14 | INFO | hw5.seq2seq | example reference: 所以 , 我們希望它們能夠幫忙 。</span><br><span class="line">2022-08-05 13:10:14 | INFO | hw5.seq2seq | validation loss:	3.2599</span><br><span class="line">2022-08-05 13:10:14 | INFO | hw5.seq2seq | BLEU = 25.63 57.9/32.9/19.6/12.3 (BP = 0.986 ratio = 0.986 hyp_len = 110246 ref_len = 111811)</span><br></pre></td></tr></table></figure>

<hr>
<h1 id="Report-1"><a href="#Report-1" class="headerlink" title="Report"></a>Report</h1><p><img src="/../images/20220804_2.png"></p>
<h2 id="Prolem-1"><a href="#Prolem-1" class="headerlink" title="Prolem 1"></a>Prolem 1</h2><p><img src="/../images/20220805_1.png"></p>
<h2 id="Problem-2"><a href="#Problem-2" class="headerlink" title="Problem 2"></a>Problem 2</h2><p><img src="/../images/20220805_2.png"></p>
<hr>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><h2 id="梯度爆炸"><a href="#梯度爆炸" class="headerlink" title="梯度爆炸"></a>梯度爆炸</h2><p>梯度爆炸：在error surface平坦的地方，設的lr過大，導致整個參數大跑<br><img src="/../images/pasted-45.png"></p>
<h2 id="OOV-out-of-vacabulary"><a href="#OOV-out-of-vacabulary" class="headerlink" title="OOV (out of vacabulary)"></a>OOV (out of vacabulary)</h2><ul>
<li>類似人類會的英語字彙不足，不足以表達意涵</li>
<li>字彙過長，不好處理</li>
<li>本作業中使用subwords來解決這個問題，<a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/">Reference</a></li>
</ul>
<h2 id="Google雲端"><a href="#Google雲端" class="headerlink" title="Google雲端"></a>Google雲端</h2><p>本次作業的模型參數檔、gnorm軌跡與預測結果<a target="_blank" rel="noopener" href="https://drive.google.com/drive/folders/16hEQlLCZNB1ormHsNN15VAxmRf0LlJzU?usp=sharing">連結</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/04/ML-2021-X-4-GPT%E7%9A%84%E9%87%8E%E6%9C%9B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/04/ML-2021-X-4-GPT%E7%9A%84%E9%87%8E%E6%9C%9B/" class="post-title-link" itemprop="url">ML_2021_X-4 GPT的野望</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-04 01:19:27" itemprop="dateCreated datePublished" datetime="2022-08-04T01:19:27+08:00">2022-08-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 23:51:10" itemprop="dateModified" datetime="2022-08-08T23:51:10+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="GPT的任務"><a href="#GPT的任務" class="headerlink" title="GPT的任務"></a>GPT的任務</h1><p><a target="_blank" rel="noopener" href="https://talktotransformer.com/">GPT模型demo</a></p>
<p>給定一個seq，要能預測出下一個出現的token是甚麼<br>    ex. ground truth是台灣大學，則給定\\&lt;BOS&gt;、台，就要能預測灣</p>
<p>有點像transformer的decoder，只知道之前的內容。</p>
<ul>
<li><p>因為GPT具備predict next token的能力，所以也可以用來做GAN</p>
</li>
<li><p>GPT的形象是獨角獸</p>
</li>
</ul>
<h1 id="How-to-use-GPT"><a href="#How-to-use-GPT" class="headerlink" title="How to use GPT"></a>How to use GPT</h1><ul>
<li><p>GPT也可以跟BERT用一樣的做法，拿出來用以後直接接一個簡單的classifier</p>
</li>
<li><p>原文論文不是這樣用(可能是fine-tune都有問題)</p>
</li>
<li><p>原文的訓練方式有點類似學測的模擬題目<br><img src="/../images/20220808_1.png"><br> 給定樣本題與正確答案，希望他能做出類似的答案，也就是要能看懂題目要幹嘛，並給出答案</p>
</li>
<li><p>從翻譯當例子，就是告訴它「Translate english to Chinese」(task description)後，再給幾個範例</p>
<ul>
<li>cheese -&gt; 起司 (examples)<br>    - sea -&gt; 海洋</li>
</ul>
<p>  <br>  並叫它繼續填空</p>
<ul>
<li>plush -&gt;  ___  (prompt)</li>
</ul>
</li>
<li><p>這樣的做法類似「few-shot learning」，但沒有用到gradient descent</p>
<ul>
<li>few-shot，表示給定的樣本數很少</li>
<li>原文作者給它命名為「in-context learning」</li>
</ul>
</li>
<li><p>這種學法很有野心，但目前命中率不高(40~50%，175B parameters)</p>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://youtu.be/DOG1L9lvsDY">相關細節</a></p>
<h2 id="Beyond-Text"><a href="#Beyond-Text" class="headerlink" title="Beyond Text"></a>Beyond Text</h2><p>除了剛剛的翻譯例子以外，GPT還有很多用途</p>
<p>在語音、CV等等領域也有所應用，留待深入研究</p>
<ul>
<li>BERT也可以做語音版的，語音也可以填空與預測<ul>
<li>老師有帶領實驗室合作，開發相關的資料庫任務組：superb (語音版的GLUE)</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/08/03/ML-2021-X-3-BERT%E7%9A%84%E5%A5%87%E8%81%9E%E8%BB%BC%E4%BA%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/08/03/ML-2021-X-3-BERT%E7%9A%84%E5%A5%87%E8%81%9E%E8%BB%BC%E4%BA%8B/" class="post-title-link" itemprop="url">ML_2021_X-3 BERT的奇聞軼事</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-08-03 01:33:10" itemprop="dateCreated datePublished" datetime="2022-08-03T01:33:10+08:00">2022-08-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 22:00:39" itemprop="dateModified" datetime="2022-08-08T22:00:39+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><p>明明只學填空，為何BERT有用?</p>
</li>
<li><p>you shall know a word by the company it keeps</p>
</li>
<li><p>詞向量並非是BERT為祖先</p>
<ul>
<li>BERT(contextualized word embedding) 、 CBOW(word embedding)</li>
</ul>
</li>
<li><p>BERT會把各個詞彙變成一個詞向量，詞義越相近的詞彙，則他們的向量相似度會更像<br><img src="/../images/20220803_4.png"></p>
</li>
</ul>
<hr>
<h1 id="BERT是否真的看得懂文章？"><a href="#BERT是否真的看得懂文章？" class="headerlink" title="BERT是否真的看得懂文章？"></a>BERT是否真的看得懂文章？</h1><ul>
<li><p>基於語言學假設，知道詞彙的意思要看他的前後文</p>
</li>
<li><p>但BERT真的只拿詞彙的前後文當判別依據嗎？</p>
<ul>
<li>拿BERT做DNA分類</li>
</ul>
</li>
<li><p>把DNA序列(A,T,C,G)變成好幾個英文詞彙(隨機對)然後直接丟入BERT 做fine-tune training</p>
<ul>
<li>BERT pretrained by English</li>
<li>ex. ATTACG -&gt; He She She He It Us</li>
</ul>
</li>
<li><p>出乎意料的用有pretrain的BERT命中率比直接用隨機參數的transformer encoder模型還高 (<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2103.07162">Reference</a>)</p>
<ul>
<li>這個實驗可以發現就算這整串文章毫無邏輯，BERT也可以表現的比完全隨機還好，表示機器就算看不懂文章，也學到了某些東西<br>    - 關於BERT學習過程仍待研究</li>
</ul>
</li>
</ul>
<p>    <br>關於BERT的研究(變形)</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://youtu.be/1_gRK9EIQpc">BERT(上)</a></li>
<li><a target="_blank" rel="noopener" href="https://youtu.be/Bywo7m6ySlk">BERT(下)</a></li>
</ul>
<hr>
<h1 id="Multi-lingual-BERT"><a href="#Multi-lingual-BERT" class="headerlink" title="Multi-lingual BERT"></a>Multi-lingual BERT</h1><p> <b><em>Train BERT with different languages</em></b></p>
<ul>
<li><p>用多國語言訓練(pretrain)BERT，就可以解中文的資料集</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1909.09587">相關論文實驗</a></li>
<li>多語言BERT模型的表現是最好的</li>
</ul>
</li>
<li><p>或許對於不同語言之間差異不大? (仍有待研究)</p>
<ul>
<li>ex. 兔跟rabbit相近、游跟swim相近</li>
</ul>
</li>
</ul>
<p> 老師的lab一開始也是嘗試train自己的multi-lingual BERT以查清BERT學習的方法</p>
<ul>
<li>實驗結果顯示multi-lingual BERT需要的dataset很大<br><img src="/../images/20220803_1.png"><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.10938">Reference</a></li>
</ul>
<hr>
<ul>
<li>但是既然語言特性並非BERT的學習重點，為何不會輸入中文，吐出日文?<ul>
<li>表示BERT還是會注意語言之間的差異</li>
<li>那如果抵銷掉語言之間的差異呢？</li>
</ul>
</li>
</ul>
<p>    <br>   <br><img src="/../images/20220803_2.png"></p>
<ul>
<li>老師的lab實際把英文丟入BERT模型內，再加上一個向量，這個向量是英文與中文詞向量平均之間的差距，可以得出輸入英文，輸出中文的填空結果</li>
</ul>
<p><img src="/../images/20220803_3.png"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/30/ML-2021-X-1-X-2-BERT%E7%B0%A1%E4%BB%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/30/ML-2021-X-1-X-2-BERT%E7%B0%A1%E4%BB%8B/" class="post-title-link" itemprop="url">ML_2021_X-1&X-2 BERT簡介</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-30 16:23:44" itemprop="dateCreated datePublished" datetime="2022-07-30T16:23:44+08:00">2022-07-30</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-09 16:58:50" itemprop="dateModified" datetime="2022-08-09T16:58:50+08:00">2022-08-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li><p>芝麻街家族與模型有很多關聯<br><img src="/../images/20220730_1.png"></p>
</li>
<li><p>BERT有340M個parameters，非常巨大</p>
</li>
<li><p>下面課程主要講BERT與GPT系列</p>
<blockquote>
<p>BERT 就是transformer encoder</p>
</blockquote>
</li>
</ul>
<hr>
<h1 id="BERT-learning-technique"><a href="#BERT-learning-technique" class="headerlink" title="BERT learning technique"></a>BERT learning technique</h1><h2 id="Semi-supervised"><a href="#Semi-supervised" class="headerlink" title="Semi-supervised?"></a>Semi-supervised?</h2><pre><code>- BERT用在下游任務需要labeled data做一些fine-tune，是supervised learning
- BERT pretrain過程卻不需要labeled data，是unsupervised learning
</code></pre>
<p>$\rightarrow$ 所以合起來稱為semi-supervised</p>
<h2 id="Self-supervised"><a href="#Self-supervised" class="headerlink" title="Self-supervised?"></a>Self-supervised?</h2><ul>
<li>雖然是supervised learning，但是卻不需要人工標記，這種方法將訓練資料本身作為label</li>
<li>我們會切割一部分的資料x’作為輸入，一部分的資料x’’則做為label<ul>
<li>在沒有資料的情況下，自己想辦法supervised (故在人工方面可以看做是一種unsupervised)</li>
</ul>
</li>
<li>BERT的pretrain任務，就是self-supervised learning</li>
</ul>
<h1 id="Pretrain-Self-supervised-learning"><a href="#Pretrain-Self-supervised-learning" class="headerlink" title="Pretrain(Self-supervised learning)"></a>Pretrain(Self-supervised learning)</h1><ul>
<li></li>
<li>不同於supervised，self-supervised的資料沒有標註，我們會切割一部分的資料x’作為輸入，一部分的資料x’’則做為label<ul>
<li>在沒有資料的情況下，自己想辦法supervised (是一種unsupervised)</li>
</ul>
</li>
</ul>
<h3 id="Pretrain任務1：masking-input"><a href="#Pretrain任務1：masking-input" class="headerlink" title="Pretrain任務1：masking input"></a>Pretrain任務1：masking input</h3><pre><code>- 會隨機把input sequence中隨機一個vector蓋掉，稱為masking input，然後讓BERT去訓練猜中原本蓋掉的詞(token)是甚麼
- mask / random
- 很像分類問題，類別量 = token總數
- BERT出來會有一個linear的matrix，做完softmax以後輸出  
</code></pre>
<p><img src="/../images/pasted-44.png"></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">reference</a></li>
</ul>
<h3 id="Pretrain任務2：Next-sentence-prediction"><a href="#Pretrain任務2：Next-sentence-prediction" class="headerlink" title="Pretrain任務2：Next sentence prediction"></a>Pretrain任務2：Next sentence prediction</h3><pre><code>- 任取兩個sequence，在開頭跟句子之間加入分隔符號
</code></pre>
<p>    - BERT要訓練去辨認這兩個例子是否相接<br>    - 這招不是很有效，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.11692">Robustly optimized BERT approach</a><br>    	- 一種可能是這個任務過於簡單</p>
<ul>
<li>另外一招：sentence order prediction(SOP)<ul>
<li>2句子本來就接在一起但亂序，要分辨誰是前面誰是後面</li>
<li>在<a target="_blank" rel="noopener" href="https://arxiv.org/avs/1909.11942">ALBERT</a>中使用</li>
</ul>
</li>
</ul>
<h2 id="How-to-use-BERT"><a href="#How-to-use-BERT" class="headerlink" title="How to use BERT"></a>How to use BERT</h2><ul>
<li>BERT雖然只做上述兩個訓練，但【卻可以使用在不同的任務上面 (downstream tasks)】<ul>
<li>針對不同任務，BERT仍需要做一點微調(一些些的labeled data)，稱為<b><em>Fine-Tune</em></b></li>
</ul>
</li>
<li>我們會讓BERT去做各種任務(任務集)取各種任務的成績以後平均<ul>
<li>一個訓練的集合：<a target="_blank" rel="noopener" href="https://gluebenchmark.com/">general Language Understanding Evaluation(GLUE)</a></li>
</ul>
</li>
</ul>
<h2 id="BERT-表現in-GLUE"><a href="#BERT-表現in-GLUE" class="headerlink" title="BERT 表現in GLUE"></a>BERT 表現in GLUE</h2><p><img src="/../images/20220802_1.png"></p>
<ul>
<li>1.0的基準線是人類的成績(指標不一定是正確率)</li>
</ul>
<h2 id="BERT實務"><a href="#BERT實務" class="headerlink" title="BERT實務"></a>BERT實務</h2><h3 id="Case-1"><a href="#Case-1" class="headerlink" title="Case 1"></a>Case 1</h3><ul>
<li>輸入一個sequence，輸出一個class (ex. sentiment analysis)<br><img src="/../images/20220802_2.png"></li>
<li>使用pretrained data後，BERT的參數已經被初始化了(一個會做填空題的BERT)，而線性層則是仍然要隨機初始化</li>
</ul>
<h3 id="Case-2"><a href="#Case-2" class="headerlink" title="Case 2"></a>Case 2</h3><ul>
<li><p>輸入一個sequence，輸出一樣長度的sequence (詞性標註 POS tagging)<br><img src="/../images/20220802_3.png"></p>
</li>
<li><p>處理過程同case 1</p>
</li>
</ul>
<h3 id="Case-3"><a href="#Case-3" class="headerlink" title="Case 3"></a>Case 3</h3><ul>
<li>輸入兩個句子，輸出一個類別 (NLI)<ul>
<li>NLI : 從前提要能推出假設</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220802_4.png"></p>
<h3 id="Case-4-作業7"><a href="#Case-4-作業7" class="headerlink" title="Case 4 (作業7)"></a>Case 4 (作業7)</h3><ul>
<li>問答系統：給機器讀文章，問他問題要能回應</li>
<li>但是機器只能從文章中給出答案(抓取文章的特定序列)<ul>
<li>輸出兩個正整數</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220802_5.png"></p>
<ul>
<li><p>輸入的形狀跟case 3很像，只是後面改成文章，前面改成問題<br><img src="/../images/20220802_6.png"></p>
</li>
<li><p>黃色向量輸出分別對橘、藍vector做內積，然後過softmax</p>
</li>
<li><p>答案會是($d_i,d_j)$，其中i來自橘色，j來自藍色</p>
</li>
</ul>
<h2 id="Training-BERT-is-challenging"><a href="#Training-BERT-is-challenging" class="headerlink" title="Training BERT is challenging"></a>Training BERT is challenging</h2><ul>
<li><p>google訓練最早的BERT的時候用了3 billions words</p>
</li>
<li><p>訓練非常花時間，但是微調很快(colab GPU約1 hr)</p>
</li>
<li><p>既然BERT都已經被訓練過了，為何還會有人想要重新訓練他?</p>
<ul>
<li>實際上訓練BERT的過程中，BERT到底學到了甚麼仍有待研究<br>    - 為了<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2010.02480">學習BERT的胚胎學</a>，所以會需要重新訓練</li>
</ul>
</li>
</ul>
<h2 id="如果今天要解的任務是seq2seq呢"><a href="#如果今天要解的任務是seq2seq呢" class="headerlink" title="如果今天要解的任務是seq2seq呢"></a>如果今天要解的任務是seq2seq呢</h2><ul>
<li><p>BERT只有pretrain encoder，有沒有辦法pretrain decoder？ 可以。</p>
</li>
<li><p>Encoder看到corrupted的data，decoder則是要想辦法把他還原</p>
<ul>
<li>弄壞資料的方法：旋轉、空白、mask…<br><img src="/../images/20220802_7.png"></li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/29/ML-2021-6-4-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E5%9B%9B-%E2%80%93-Cycle-GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/29/ML-2021-6-4-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E5%9B%9B-%E2%80%93-Cycle-GAN/" class="post-title-link" itemprop="url">ML_2021_6-4 生成式對抗網路(四) – Cycle GAN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-29 16:57:34" itemprop="dateCreated datePublished" datetime="2022-07-29T16:57:34+08:00">2022-07-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Learning-from-unpaired-data"><a href="#Learning-from-unpaired-data" class="headerlink" title="Learning from unpaired data"></a>Learning from unpaired data</h1><ul>
<li>把GAN用在unsupervised learning</li>
<li>如何用沒標註的資料做semi-supervised learning<ul>
<li>2021 HW3,HW5都有用到<br>    	- 不過他們仍然需要一些paired data</li>
</ul>
</li>
</ul>
<h2 id="影像風格轉換"><a href="#影像風格轉換" class="headerlink" title="影像風格轉換"></a>影像風格轉換</h2><ul>
<li><p>以影像風格轉換，要把三次元真人的圖片轉成二次元的輸出，不可能先幫3次元訓練資料畫一個二次元的圖片來pair，所以任何一筆成對資料都沒有</p>
</li>
<li><p>我們可否把輸入的真人圖片變成一個distribution，輸出的圖片也是一個distribution呢?<br><img src="/../images/pasted-39.png"></p>
</li>
</ul>
<h3 id="First-approach"><a href="#First-approach" class="headerlink" title="First approach"></a>First approach</h3><ul>
<li><p>套用原本GAN的想法，只要能從x domain sample即可</p>
<ul>
<li>從domain x sample，輸出以後跟y domain做discriminator，最後輸出向量<br><img src="/../images/pasted-40.png"></li>
</ul>
</li>
<li><p>問題：</p>
<ul>
<li>generator可以只訓練通過discriminator的照片，然後完全忽略輸入<ul>
<li>所以我們需要condition，但又因為沒有paired data，我們不能用condition GAN</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>-&gt; 既然這樣，就用兩次GAN，看輸出能不能還原原本的圖片 -&gt; 使用cycle GAN</p>
<h1 id="Cycle-GAN"><a href="#Cycle-GAN" class="headerlink" title="Cycle GAN"></a>Cycle GAN</h1><p>同樣以影像風格轉換為例(輸入3次元人臉，輸出二次元人臉)</p>
<ul>
<li><p>在原本的GAN網路中再新增一個GAN，把第一個generator的輸出丟進第二個generator的輸入，第二個GAN用於產生跟原始的輸入x盡量相似的圖片
     </p>
</li>
<li><p>即讓$G_{x \rightarrow y}越接近G_{y\rightarrow x}$越好<br><img src="/../images/20220729_13.png"></p>
</li>
<li><p>問題2: 機器有沒有可能亂學，「串通作弊」呢</p>
<ul>
<li>EX: 機器gen1學到真人戴眼鏡，就會把眼鏡拿掉變成痣；gen2則學到看到二次元痣，就把痣拿掉換回眼鏡</li>
<li>EX2: gen1跟gen2互相對稱旋轉圖片</li>
</ul>
</li>
<li><p>不過在實作上這個問題發生率不高，因為network is lazy，看到眼鏡就輸出眼鏡了</p>
</li>
</ul>
<p><img src="/../images/20220729_14.png"></p>
<ul>
<li><p>相反來說，我們也會需要一個discriminator來看$G_{y\rightarrow x}$(就是生成的3次元頭像是否跟原始圖像很像)</p>
</li>
<li><p>如上圖，這兩個合起來就會是cycle GEN</p>
</li>
</ul>
<h1 id="其他做影像風格轉換的GAN"><a href="#其他做影像風格轉換的GAN" class="headerlink" title="其他做影像風格轉換的GAN"></a>其他做影像風格轉換的GAN</h1><ul>
<li><p>Disco GAN</p>
</li>
<li><p>Dual GAN</p>
</li>
<li><p>Cycle GAN</p>
<ul>
<li>這三個想法幾乎一模一樣，只是團隊不同</li>
</ul>
</li>
<li><p>StarGAN則是可以在多種風格間轉換(Cycle只能兩種風格)</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1907.10830">進階版GAN</a>，以及應用他的<a target="_blank" rel="noopener" href="https://selfie2anime.com/">網站</a></p>
</li>
</ul>
<h1 id="文字風格轉換"><a href="#文字風格轉換" class="headerlink" title="文字風格轉換"></a>文字風格轉換</h1><ul>
<li><p>輸入一個句子，輸出另一個句子 (此例是把負面句子變成正面句子)</p>
<ul>
<li>依樣畫葫蘆，收集一堆負面&#x2F;正面的句子(同樣沒有成對資料)</li>
</ul>
</li>
<li><p>套用Cycle GAN作法</p>
</li>
</ul>
<p><img src="/../images/pasted-41.png"></p>
<ul>
<li><p>問題: 文字的相似度如何計算?<br>  自行研究</p>
</li>
<li><p>輸出如果是文字接給discriminator會有問題，需要用RL做</p>
</li>
</ul>
<h2 id="文字風格轉換應用-除了負面轉正面的句子"><a href="#文字風格轉換應用-除了負面轉正面的句子" class="headerlink" title="文字風格轉換應用(除了負面轉正面的句子)"></a>文字風格轉換應用(除了負面轉正面的句子)</h2><ol>
<li>Unsupervised Abstractive Summarization (摘要練習)<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.02851">https://arxiv.org/abs/1810.02851</a></li>
</ul>
</li>
<li>Unsupervised Translation (翻譯) <ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.04087">https://arxiv.org/abs/1710.04087</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.11041">https://arxiv.org/abs/1710.11041</a></li>
</ul>
</li>
<li>Unsupervised ASR (語音辨識)<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.00316">https://arxiv.org/abs/1804.00316</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1812.09323">https://arxiv.org/abs/1812.09323</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.04100">https://arxiv.org/abs/1904.04100</a></li>
</ul>
</li>
</ol>
<p>    
    </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/29/ML-2021-6-3-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E4%B8%89-%E2%80%93-%E7%94%9F%E6%88%90%E5%99%A8%E6%95%88%E8%83%BD%E8%A9%95%E4%BC%B0%E8%88%87%E6%A2%9D%E4%BB%B6%E5%BC%8F%E7%94%9F%E6%88%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/29/ML-2021-6-3-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E4%B8%89-%E2%80%93-%E7%94%9F%E6%88%90%E5%99%A8%E6%95%88%E8%83%BD%E8%A9%95%E4%BC%B0%E8%88%87%E6%A2%9D%E4%BB%B6%E5%BC%8F%E7%94%9F%E6%88%90/" class="post-title-link" itemprop="url">ML_2021_6-3 生成式對抗網路(三) – 生成器效能評估與條件式生成</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-29 15:24:39" itemprop="dateCreated datePublished" datetime="2022-07-29T15:24:39+08:00">2022-07-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>GAN的訓練仍然困難，gen跟dis有一個卡住了，就整個卡住了<ul>
<li>Generator跟Discriminator需要互相match each other</li>
</ul>
</li>
</ul>
<h1 id="More-training-GEN-tips"><a href="#More-training-GEN-tips" class="headerlink" title="More training GEN tips"></a>More training GEN tips</h1><p><img src="/../images/20220729_2.png"></p>
<h1 id="GAN-for-Sequence-generation"><a href="#GAN-for-Sequence-generation" class="headerlink" title="GAN for Sequence generation"></a>GAN for Sequence generation</h1><ul>
<li><p>前面講的都是影像的GAN</p>
</li>
<li><p>Decoder變成了generator</p>
</li>
<li><p>Decoder的輸出一樣丟入discriminator訓練，產生分數<br><img src="/../images/pasted-37.png"></p>
</li>
<li><p>問題在於，decoder不能用梯度下降去train</p>
<ul>
<li>微不出decoder weight變化對discriminator的影響（distribution不變）<br><img src="/../images/20220729_3.png"></li>
</ul>
</li>
<li><p>碰到很難train的地方，可以用用看RL</p>
<ul>
<li>RL很難train，且GAN也很難train，不好用</li>
</ul>
</li>
<li><p>完整的GAN課程：<a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLJV_el3uVTsMq6JEFPW35BCiOQTsoqwNw">連結</a></p>
</li>
<li><p>More generative models: VAE、FLOW-based Model</p>
</li>
</ul>
<h1 id="可否用supervised-learning做"><a href="#可否用supervised-learning做" class="headerlink" title="可否用supervised learning做"></a>可否用supervised learning做</h1><ul>
<li>直接把正確的圖片變成vector，作為ground truth（訓練目標）<ul>
<li>直接放入隨機向量來生成圖片</li>
</ul>
</li>
<li>可以這樣做，但是向量不能亂取，相關文章：<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1707.05776">Generative Latent Optimization (GLO)</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2007.02798">Gradient Origin Networks</a></li>
</ul>
</li>
</ul>
<h1 id="Quality-of-GAN"><a href="#Quality-of-GAN" class="headerlink" title="Quality of GAN"></a>Quality of GAN</h1><ul>
<li><p>如何衡量GAN的好壞</p>
</li>
<li><p>以往都是直接真人去看效果，但可能不客觀且價格昂貴</p>
</li>
<li><p>在某些任務的確可以衡量</p>
<ul>
<li>（作業6）提供一個動畫，看GAN能抓出幾張是人臉</li>
</ul>
</li>
<li><p>分類系統，把GAN輸出的影像作為分類系統的輸入，讓這個系統分類</p>
<ul>
<li>Ex. GAN產生班馬，給分類系統分類該圖像是否班馬類</li>
<li>當分類越集中，則GAN的輸出「可能」越好</li>
<li>問題：Mode Collapse</li>
</ul>
</li>
</ul>
<h2 id="Mode-Collapse"><a href="#Mode-Collapse" class="headerlink" title="Mode Collapse"></a>Mode Collapse</h2><ul>
<li>可能GAN輸出的圖片來來去去就那幾張，過度單一，但那些圖片都剛好分類成功</li>
<li>GAN知道discriminter的盲點了，就集中攻擊這個點<br><img src="/../images/pasted-38.png"></li>
<li>上圖的人臉過度單一</li>
<li>目前暫時無解，但看得出來</li>
</ul>
<h2 id="Mode-Dropping"><a href="#Mode-Dropping" class="headerlink" title="Mode Dropping"></a>Mode Dropping</h2><ul>
<li>GAN輸出的圖片看起來有一些變化性，看不出問題</li>
<li>但可能輸出的圖片只是真實圖片的一小個子集</li>
<li>不容易偵測出來</li>
</ul>
<h2 id="Diversity"><a href="#Diversity" class="headerlink" title="Diversity"></a>Diversity</h2><ul>
<li>衡量GAN輸出的多樣性分布</li>
</ul>
<p><img src="/images/20220729_5.png" alt="upload successful"></p>
<ul>
<li><p>與quality差別在於，quality衡量只看一張圖片，分類越集中越好</p>
</li>
<li><p>diversity則是看一堆圖片，輸出的平均越均衡，代表多樣性越好</p>
</li>
<li><p>Inception score(IS)：若good quality, diversity，則large IS</p>
</li>
<li><p>但作業不會用inception score</p>
<ul>
<li>輸出都是人臉，對於IS來說diversity會很小</li>
</ul>
</li>
<li><p>作業採用Frechet inception distance(FID)</p>
<ul>
<li>把輸出丟入CNN，再把進入softmax前的那個vector拿出來作為輸入</li>
<li>假設真實圖片跟產生的圖片都是gaussian distribution</li>
<li>對他們算Frechet inception distance<ul>
<li>越小品質越高</li>
</ul>
</li>
</ul>
</li>
<li><p>問題：需要很多samples，且不知道輸出分佈是否為gaussian</p>
<ul>
<li>所以不能只看這個，作業會FID跟IS都參考<br><img src="/images/20220729_6.png"></li>
</ul>
</li>
<li><p>有時候，FID很好（低）而且人臉也做得很真實，也未必是一個很好的model</p>
<ul>
<li>memory GAN: 如果這個GAN可能是直接照抄訓練資料的，剛好符合diversity跟classification</li>
<li>可否比對訓練資料跟輸出的相似度？<ul>
<li>也可能GAN剛好輸出都是輸入資料的左右反轉，相似度又比不出來<br>-&gt; GAN的evaluation仍為可深入研究的題目</li>
</ul>
</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.03446">目前的GAN evaluation的作法列舉</a></p>
</li>
</ul>
<h1 id="Conditional-Generation"><a href="#Conditional-Generation" class="headerlink" title="Conditional Generation"></a>Conditional Generation</h1><ul>
<li><p>到目前為止GAN都只講隨機的輸入</p>
</li>
<li><p>若給定一個x(條件)，產生y</p>
<ul>
<li>Text to image任務<br><img src="/../images/20220729_8.png"></li>
</ul>
</li>
<li><p>根據Sample的z不同，會產生滿足x條件的不同輸出</p>
</li>
</ul>
<h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><ul>
<li>必須也知道文字敘述的條件，不然GAN只會產生清晰圖片，忽略條件</li>
<li>Discriminator除了看圖片是否好，還要看是否吻合條件</li>
</ul>
<p><img src="/images/20220729_9.png"></p>
<ul>
<li><p>text-image的training data通常會需要成對的資料(condition,image)</p>
</li>
<li><p>但是這樣通常訓練的結果不會很好</p>
<ul>
<li>還是要mix一些label &#x3D; 0(故意塞錯的) 的資料（清晰圖片+錯誤描述）<br><img src="/../images/20220729_10.png"></li>
</ul>
</li>
</ul>
<h2 id="conditional-GAN其他應用"><a href="#conditional-GAN其他應用" class="headerlink" title="conditional GAN其他應用"></a>conditional GAN其他應用</h2><h3 id="sound-to-image"><a href="#sound-to-image" class="headerlink" title="sound to image"></a>sound to image</h3><ul>
<li><p>給聲音，然後畫出圖片</p>
<ul>
<li>給sound一些label其實不難收集，可以爬影片然後get sound以及相關畫面</li>
<li>(sound, “a dog barking sound”)</li>
<li>(sound, “river sound”)<br><img src="/../images/20220729_12.png"></li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://wjohn1483.github.io/audio_to_scene/index.html">參考網站</a></p>
</li>
</ul>
<h3 id="talking-head-generation"><a href="#talking-head-generation" class="headerlink" title="talking head generation"></a>talking head generation</h3><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.08233">相關文獻</a></p>
<h3 id="image-to-image"><a href="#image-to-image" class="headerlink" title="image to image"></a>image to image</h3><p><img src="/../images/20220729_11.png"></p>
<ul>
<li><p>Conditional GAN也可以做image translation（輸入圖片，輸出吻合條件的圖片）</p>
<ul>
<li>pix2pix</li>
</ul>
</li>
<li><p>老樣子，image 2 image用supervisied learning，可能會學習到類似的情況下，圖片輸入很多種，導致輸出模糊（同GAN一開始小精靈的例子）</p>
<ul>
<li>所以還是要用GAN<ul>
<li>但GAN可能還是會有想像力過度豐富的問題</li>
<li>兩者需要同時使用</li>
</ul>
</li>
</ul>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/avs/1611.07004">相關文獻</a></p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/28/ML-2021-6-2-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E4%BA%8C-%E7%90%86%E8%AB%96%E4%BB%8B%E7%B4%B9%E8%88%87WGAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/28/ML-2021-6-2-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E4%BA%8C-%E7%90%86%E8%AB%96%E4%BB%8B%E7%B4%B9%E8%88%87WGAN/" class="post-title-link" itemprop="url">ML_2021_6-2 生成式對抗網路(二) - 理論介紹與WGAN</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-28 00:53:06" itemprop="dateCreated datePublished" datetime="2022-07-28T00:53:06+08:00">2022-07-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="訓練的目標"><a href="#訓練的目標" class="headerlink" title="訓練的目標"></a>訓練的目標</h1><ul>
<li>訓練到底要min&#x2F;max甚麼東西呢?<br><img src="/../images/20220728_1.png"></li>
</ul>
<p>一維的範例</p>
<p><img src="/../images/20220728_2.png"></p>
<ul>
<li><p>要找的最佳化G參數就是<br>$$<br>G^* &#x3D; arg\ min_GDiv(P_G,P_{data})<br>$$</p>
</li>
<li><p>其中Div()表示兩個distribution之間的距離(相似度)公式</p>
</li>
<li><p>問題在不知道怎麼計算divergence</p>
</li>
<li><p>GAN可以在只有Sample的情況下，估計出div()是多少</p>
<ul>
<li>需要從$P_G、P_{data}$取樣，$P_{data}$取自圖庫，而$P_G$則取自generator產生的圖片<br>    - 這部分就要交給Discriminator，他要max一個objective function，公式有很多種</li>
</ul>
</li>
</ul>
<h2 id="JS-divergence"><a href="#JS-divergence" class="headerlink" title="JS divergence"></a>JS divergence</h2><p>公式如下(我們要取Max)<br>    $$<br>    V(G,D) &#x3D; E_{y\ from\ P_{data}}[logD(y)] + E_{y\ from\ P_G}[log(1-D(y)]<br>    $$</p>
<ul>
<li>我們會需要來自data的D(y)越大越好，來自G的D(y)越小越好</li>
</ul>
<p>Note: 若加上一點自由度，簡化上述公式，可以得到<br>$$<br>J^D &#x3D; -D(x) + D(G(z)), for\ all\ D(x),\ D(G(z))\  \in \ [0,1]<br>$$<br>且生成器的損失函數：<br>$$<br>J^G &#x3D; -J^D<br>$$<br>因為他們之間彼此對抗，所以他們兩者之間的損失只差一個負號，稱為min-max GAN</p>
<p><img src="/../images/20220729_1.png"></p>
<ul>
<li>其實 $D^*$ 等同於(-1) x cross entropy<ul>
<li>早年這麼設計的理由是因為，希望objective function可以跟二元分類扯上關係</li>
</ul>
</li>
</ul>
<p><img src="/../images/20220728_3.png"></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.2661">參考</a></p>
</li>
<li><p>small divergence，data跟G的圖很像，則hard to discrininate，則small max V(D,G)</p>
</li>
<li><p>因為$max_D\ V(D,G)$與JS divergence有關聯，所以我們可以把Div()換掉，變成<br>$$<br>G^* &#x3D; arg\ min_G [max_DV(G,D)] \\\<br>D^* &#x3D; arg\ max_DV(D,G)<br>$$<br>&#x2F;&#x2F;D的max objetive value跟JS divergence有關</p>
</li>
</ul>
<h2 id="其他的divergence"><a href="#其他的divergence" class="headerlink" title="其他的divergence"></a>其他的divergence</h2><ul>
<li>當然，我們也可以用不同的divergence<ul>
<li>對於不同的divergence，用甚麼樣的objective function，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1606.00709">這篇論文有詳細解釋</a><br><img src="/../images/20220728_4.png"></li>
</ul>
</li>
</ul>
<h1 id="訓練GAN的小技巧"><a href="#訓練GAN的小技巧" class="headerlink" title="訓練GAN的小技巧"></a>訓練GAN的小技巧</h1><h2 id="JS-divergence-的問題"><a href="#JS-divergence-的問題" class="headerlink" title="JS divergence 的問題"></a>JS divergence 的問題</h2><ul>
<li><p>$P_G、P_{data}$重疊的地方往往很少</p>
<ul>
<li>pf1. 圖片是高維空間裡面，低維的manifold<br>    	- 就像在一個平面空間中的兩條線一樣，重合的地方很少<br>    	- 在高維空間內隨便sample的點都不會是圖片<br>    	- 所以他們相交的部分幾乎可以忽略</li>
<li>pf2.若$P_G、P_{data}$sample的點不夠多，很容易劃出一個界線把他們切開<br>-&gt; $P_G、P_{data}$重疊範圍非常少</li>
</ul>
</li>
<li><p>若兩個分布沒有重疊的地方，算出來的Div就會永遠都是log 2，看不出差距<br><img src="/../images/20220728_5.png"></p>
</li>
</ul>
<h2 id="WGAN"><a href="#WGAN" class="headerlink" title="WGAN"></a>WGAN</h2><ul>
<li>換一個衡量divergense來衡量2 distribution之相似度</li>
</ul>
<h3 id="Wasserstein-distance"><a href="#Wasserstein-distance" class="headerlink" title="Wasserstein distance"></a>Wasserstein distance</h3><ul>
<li><p>假設一個distribution P為一坨土，而另一個distribution Q為目的地</p>
</li>
<li><p>把土堆P挪到Q所需要的移動距離平均就是Wasserstein distance<br><img src="/../images/pasted-34.png"></p>
</li>
<li><p>因為可能的挪法很多，所以d會有不同</p>
<ul>
<li>定義: 窮舉所有的moving plan，找出最小的移動距離當作wasserstein distance<ul>
<li>計算麻煩</li>
</ul>
</li>
</ul>
</li>
<li><p>假設我們能計算Wasserstein distance，帶來的優點:</p>
<ul>
<li>就可以解決JS divergence看不出上圖的好壞比較的問題  <br><img src="/../images/20220728_7.png"></li>
</ul>
</li>
</ul>
<h3 id="Evaluate-Wasserstein-distance"><a href="#Evaluate-Wasserstein-distance" class="headerlink" title="Evaluate Wasserstein distance"></a>Evaluate Wasserstein distance</h3><ul>
<li>解下面的Optimization問題(下圖)，解出來就會是Wasserstein distance<br><img src="/../images/20220728_9.png"><br>[、]是期望值，D(x)就是剛剛的D(y)</li>
<li>D必須是1-Lipschitz function (Discriminator不可變化劇烈)<ul>
<li>如果沒有這個constraint，則D的training不會收斂<br>    - 讓D保持smooth強迫D(x)變成無窮與負無窮</li>
<li>基本上就是保證real跟generated的data距離不會太遠</li>
</ul>
</li>
</ul>
<p><img src="/../images/pasted-35.png"></p>
<h3 id="how-to-確保這個式子可用"><a href="#how-to-確保這個式子可用" class="headerlink" title="how to 確保這個式子可用"></a>how to 確保這個式子可用</h3><ul>
<li><p>原始GAN方法</p>
<ul>
<li>強迫network的parameters w bound在[c,-c]<br>    - 在梯度下降的para更新後，若w&gt;c , w&#x3D;c ; if w&lt;-c , w &#x3D; -c<br>    - 可能可以讓function平滑一點，但沒有解決問題</li>
</ul>
</li>
<li><p>有一篇 paper : improved WGAN 做的處理方法:</p>
<ul>
<li>在real data取sample，在fake data取一個sample，在中間再取一個sample，這個sample的梯度需要接近1 (?)</li>
</ul>
</li>
</ul>
<p>      <br><img src="/../images/pasted-36.png"></p>
<ul>
<li>相關方法很多，可以多查查<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1802.05957">Spectral Norm</a><ul>
<li>Keep gradient norm在哪都 &lt; 1</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Q-amp-A"><a href="#Q-amp-A" class="headerlink" title="Q &amp; A"></a>Q &amp; A</h4><p>Q1: 在discriminator訓練時，可否加入GAN以往的輸出</p>
<p>A1: 可。實務上跑的時候不會真的讓discriminator被maximize，太花時間，所以通常幾個iteration後就會轉換到generator</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/27/ML-2021-6-1-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E4%B8%80-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%B4%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/27/ML-2021-6-1-%E7%94%9F%E6%88%90%E5%BC%8F%E5%B0%8D%E6%8A%97%E7%B6%B2%E8%B7%AF-%E4%B8%80-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E4%BB%8B%E7%B4%B9/" class="post-title-link" itemprop="url">ML_2021_6-1 生成式對抗網路(一) - 基本概念介紹</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-27 22:52:40" itemprop="dateCreated datePublished" datetime="2022-07-27T22:52:40+08:00">2022-07-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/../images/20220727_4.png"></p>
<ul>
<li>到目前為止的network都是一個function</li>
<li>這次則是把network當作generator使用<ul>
<li>現在的network會加入一個new variable z，現在network就有兩筆輸入了</li>
</ul>
</li>
<li>z由某個simple distribution生成(distribution必須夠簡單 ex. uniform)</li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1406.2661">初代GAN</a></li>
</ul>
<h1 id="Why-需要輸出是一個分布"><a href="#Why-需要輸出是一個分布" class="headerlink" title="Why 需要輸出是一個分布"></a>Why 需要輸出是一個分布</h1><ul>
<li>以video prediction「小精靈」為例說明<ul>
<li>給定previous frames，輸出預測下一個frame會出現的畫面</li>
<li>但是在類似畫面下，有時候小精靈往左轉，有時候他往右轉，導致分裂(機器選擇兩面討好，這樣對兩個case的loss最小)<br>    -&gt; 讓機器的輸出不再單一，而是一個機率性的分佈  <br><img src="/../images/pasted-32.png"></li>
</ul>
</li>
</ul>
<p>    </p>
<p>在機器的輸出需要創造性的時候(同一輸入可能有多種輸出)，就會需要distribution<br>    - ex. 繪圖、寫文章、對話</p>
<h1 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network(GAN)"></a>Generative Adversarial Network(GAN)</h1><ul>
<li><a target="_blank" rel="noopener" href="https://github.com/hindupuravinash/the-gan-zoo">有很多種變形</a></li>
</ul>
<h2 id="Anime-face-ganeration"><a href="#Anime-face-ganeration" class="headerlink" title="Anime face ganeration"></a>Anime face ganeration</h2><ul>
<li>先把x輸入拿掉，並假設z輸入是normal distribution</li>
<li>其實二次元人物的臉(圖片)就只是一個高維向量</li>
<li>輸入的distribution複雜性其實影響不大，因generator會想辦法把它變複雜</li>
</ul>
<h2 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h2><ul>
<li>在GAN中會有這樣一個神經網路，用於判別輸出的東西是否真實</li>
<li>輸入是產生的圖片，而輸出則是一種純量[0.1]</li>
<li>可用CNN、transformer…等都可以</li>
</ul>
<h2 id="Basic-Idea-of-GAN"><a href="#Basic-Idea-of-GAN" class="headerlink" title="Basic Idea of GAN"></a>Basic Idea of GAN</h2><p>示意圖:<br><img src="/../images/20220728_6.png"></p>
<ul>
<li><p>就像物競天擇的演化一樣，discriminator會去除掉得分低的GAN成品，而GAN成品就會「天擇」成discriminator比較能接受的情況</p>
</li>
<li><p>但是discriminator也會進化，讓GAN必須再繼續進行進化</p>
</li>
<li><p>discriminator與generator通常互相視為敵人<br>GAN版示意圖(毛圖注意)<br><img src="/../images/20220727_8.png"></p>
</li>
</ul>
<h2 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h2><ol>
<li><p>Init gen and discriminator</p>
</li>
<li><p>固定住Generator (G)，輸入一陀random sampled vector，吐出成品，更新discriminator (D)</p>
<ul>
<li>拿一些「ground truth」 (ex. 真正的二次元人物)，互相比較相似度，並且更新D</li>
<li>對D來說這是一個分類問題，或是regression問題 (正確圖片標1，錯的標0)，總之就是看個人想怎麼做</li>
</ul>
</li>
<li><p>固定D，更新G，G要練習把D的acc升到最高(去欺騙D)</p>
<ul>
<li>把兩個neural network接起來，就會變成「輸入是一個向量，而輸出會是一個分數」，所以現在情況等同於maximize score (gradient ascent)<br>    - 當然固定D，所以「評分系統」不可變動</li>
</ul>
</li>
<li><p>LOOP，反覆訓練G、D<br><img src="/../images/pasted-33.png"></p>
</li>
</ol>
<hr>
<h2 id="現代GAN"><a href="#現代GAN" class="headerlink" title="現代GAN"></a>現代GAN</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.gwern.net/Faces">StyleGAN</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1710.10196">Progressive GAN</a></p>
</li>
<li><p>GAN可以產生沒看過的人臉，做一些內插<br><img src="/../images/20220728_10.png"></p>
</li>
<li><p>下一堂講解theory behind GAN</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://laxiflora.github.io/2022/07/24/ML-2021-5-3-Transformer%EF%BC%88%E4%B8%8B%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="劉宇承">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | laxiflora的小天地">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2022/07/24/ML-2021-5-3-Transformer%EF%BC%88%E4%B8%8B%EF%BC%89/" class="post-title-link" itemprop="url">ML_2021_5-3 Transformer（下）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2022-07-24 22:54:31" itemprop="dateCreated datePublished" datetime="2022-07-24T22:54:31+08:00">2022-07-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新於</span>
      <time title="修改時間：2022-08-08 20:10:07" itemprop="dateModified" datetime="2022-08-08T20:10:07+08:00">2022-08-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ul>
<li>接續5-2，講論文的transformer中的decoder區塊</li>
<li>Decoder有兩種<ul>
<li>autoregressive(AT)</li>
<li>non-autoregressive(NAT)</li>
</ul>
</li>
<li>這堂課主講AT</li>
</ul>
<h1 id="Transformer：Decoder的運作-語音辨識為範例"><a href="#Transformer：Decoder的運作-語音辨識為範例" class="headerlink" title="Transformer：Decoder的運作 (語音辨識為範例)"></a>Transformer：Decoder的運作 (語音辨識為範例)</h1><ul>
<li><p>輸入一段聲音，輸出一段文字</p>
</li>
<li><p>encoder收到聲音訊號(seq)以後，輸出一排vector(seq)</p>
</li>
<li><p>Decoder用於產生語音辨識的結果<br><img src="/../images/20220726_1.png"></p>
</li>
<li><p>輸出會是一個向量(one-hot vector)，他的長度就是整個語料庫的大小</p>
<ul>
<li>中文通常就是一個字為單位，英文有可能以詞為單位，也可能以字根字首為單位(subwords)</li>
</ul>
</li>
<li><p>第一步驟的時候，decoder會輸入一個token(BEGIN)，一種特殊符號</p>
</li>
<li><p>接下來第二及之後的步驟，會把前面步驟輸出的字母丟入decoder作為輸入<br><img src="/../images/20220726_2.png"></p>
<ul>
<li>這樣的問題就是，如果前面辨識產生的結果是錯的，那後面的輸出也會受到錯誤的結果影響 (error propagation)</li>
</ul>
</li>
</ul>
<h1 id="Transformer：Decoder結構"><a href="#Transformer：Decoder結構" class="headerlink" title="Transformer：Decoder結構"></a>Transformer：Decoder結構</h1><ul>
<li>暫且忽略來自encoder的輸入</li>
</ul>
<p><img src="/../images/20220726_3.png" alt="upload successful"></p>
<ul>
<li>撇除圈起來的地方不看，可以發現decoder跟encoder的差別沒有很大</li>
</ul>
<h2 id="masked-self-attention"><a href="#masked-self-attention" class="headerlink" title="masked self-attention"></a>masked self-attention</h2><ul>
<li>注意到decoder第一格有一個”masked multi-head attention”</li>
<li>相對於原始的self-attention，decoder只能參考前面的vector，不能參考之後的<br><img src="/../images/20220726_4.png"></li>
<li>因為token是一個一個產生，不能考慮右邊</li>
</ul>
<h2 id="Determine-output-length"><a href="#Determine-output-length" class="headerlink" title="Determine output length"></a>Determine output length</h2><ul>
<li>目前的decoder運作機制，不知道甚麼時候該停下來 (無限自動選字的概念)</li>
<li>需要有一個「斷」的token，塞在輸出的vector class內<br><img src="/../images/20220726_5.png"></li>
</ul>
<h2 id="Non-autoregressive-NAT"><a href="#Non-autoregressive-NAT" class="headerlink" title="Non-autoregressive(NAT)"></a>Non-autoregressive(NAT)</h2><p><img src="/../images/20220726_6.png" alt="upload successful"></p>
<ul>
<li>AT會把上一個字輸出出來，才產生下一個字元</li>
<li>NAT則是一次給好幾個START token，一次性產生整個sequence</li>
</ul>
<h3 id="Determine-NAT-output-length"><a href="#Determine-NAT-output-length" class="headerlink" title="Determine NAT output length"></a>Determine NAT output length</h3><ul>
<li>如何知道NAT decoder的長度哩?<ul>
<li>另外做一個pridictor去預測NAT該輸出的長度</li>
<li>假設一個句子的長度上限，看哪段輸出了END，就把字串砍到那個位置</li>
</ul>
</li>
</ul>
<h3 id="NAT優點"><a href="#NAT優點" class="headerlink" title="NAT優點"></a>NAT優點</h3><ul>
<li>相對於AT更平行化</li>
<li>可控的輸出長度(可以不用被動等到有END)<ul>
<li>可以發現AT是有點RNN、LSTM的思維</li>
<li>NAT是熱門的研究主題</li>
</ul>
</li>
<li>目前NAT的performance還是比較差<ul>
<li>原因:<a target="_blank" rel="noopener" href="https://youtu.be/jvyKmU4OM3c">multi-modality</a></li>
</ul>
</li>
</ul>
<h1 id="Transformer：Encoder-Decoder"><a href="#Transformer：Encoder-Decoder" class="headerlink" title="Transformer：Encoder-Decoder"></a>Transformer：Encoder-Decoder</h1><ul>
<li>現在焦點放到剛剛圖中圈起來的地方，這裡是encoder與decoder交會的地方(cross attention)</li>
</ul>
<p>圖示如下:<br><img src="/../images/20220726_7.png"></p>
<ul>
<li><p>做法很像一層self-attention在做的事情，只是q來自於decoder，而k,v來自於encoder</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/7472621">cross attention的相關論文</a></p>
<ul>
<li>這個方法不是來自transformer<br>    - 是先有cross才有self</li>
</ul>
</li>
<li><p>在原始論文內，decoder每一層cross attention都會拿encoder最後一層的輸出當輸入</p>
<ul>
<li>當然也有其他種連接方式，<a target="_blank" rel="noopener" href="https://arxov.org/abs/2005.08081">參考</a></li>
</ul>
</li>
</ul>
<hr>
<p> 以上是模型訓練好以後，模型怎麼去跑，接下來來談seq2seq類模型在training中碰到的小問題</p>
<h1 id="Seq2Seq：Training"><a href="#Seq2Seq：Training" class="headerlink" title="Seq2Seq：Training"></a>Seq2Seq：Training</h1><h2 id="Teacher-forcing"><a href="#Teacher-forcing" class="headerlink" title="Teacher forcing"></a>Teacher forcing</h2><p>下圖為Transformer的最終訓練展示圖<br><img src="/../images/pasted-31.png"></p>
<ul>
<li>每一次預測一個單位字，就是做一次的分類問題</li>
<li>每一個字視為一個分類問題，所以要minimize 這些所有預測+BEGIN、END各自的cross entropy</li>
<li>在訓練的時候會給decoder看ground truth<ul>
<li>這樣做法叫做Teacher forcing</li>
</ul>
</li>
</ul>
<h2 id="Copy-mechanism"><a href="#Copy-mechanism" class="headerlink" title="Copy mechanism"></a>Copy mechanism</h2><ul>
<li>很多任務不一定要decoder產生東西，而是從輸入中複製東西出來<ul>
<li>Ex. User: 你好，我是庫洛洛<br>    	Machine: 庫洛洛你好，很高興認識你<br>    - 機器不需要知道庫洛洛是誰，只要判別出人名複製就好</li>
</ul>
</li>
<li>機器聽不懂的話，也可以直接copy user input來再次詢問user是甚麼意思</li>
<li>應用: 閱讀文章的摘要</li>
<li>Pointer Network、Copy network</li>
</ul>
<h2 id="Guided-Attention"><a href="#Guided-Attention" class="headerlink" title="Guided Attention"></a>Guided Attention</h2><ul>
<li>TTS as example(語音合成)</li>
<li>看到過短的句子可能沒念完整，但讓她念好幾次卻發音成功<ul>
<li>嘗試強迫機器把所有看到的東西都看一遍 -&gt; guided attention</li>
</ul>
</li>
<li>在輸出嚴格的任務中頗好用(語音合成、辨識)<br><img src="/../images/pasted-27.png"></li>
<li>如果機器的觀看順序顛三倒四，表示這種attention可能會出問題</li>
<li>Guided attention就是強迫機器的attention有規範(ex.由左向右)</li>
<li>相關參考：Monotonic attention、Location-aware attention</li>
</ul>
<h2 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h2><p><img src="/../images/pasted-30.png"></p>
<ul>
<li><p>假設這個decoder只可能產生兩個token，要輸出一段sequence，前面都是直接輸出該輪概率最高的token，稱為「Greedy decoding」</p>
</li>
<li><p>但有沒有可能前面選擇非最佳的token，反倒導致後續的decode命中率更集中呢</p>
</li>
<li><p>Beam search找一個非最佳也不用爆搜的作法</p>
</li>
<li><p>關於這個演算法，有兩方論戰：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1904.09751">The curious case of neural test degeneration</a></p>
<ul>
<li>Randomness is needed for decoder when generating seq in some tasks (ex.TTS)</li>
</ul>
</li>
<li><p>老師認為在針對答案較為單一的任務，Beam search會表現比較好；而如果需要機器的想像力(空間大)的任務，則建議需要一些隨機性(故意加一些noise)</p>
</li>
<li><p>TTS任務中，需要在測試集加入雜訊</p>
<ul>
<li>true beauty lies in the crackks of imperfection</li>
</ul>
</li>
</ul>
<h2 id="Optimizing-evalyation-metrics"><a href="#Optimizing-evalyation-metrics" class="headerlink" title="Optimizing evalyation metrics?"></a>Optimizing evalyation metrics?</h2><ul>
<li>作業用BLEU Score作為判斷依據<ul>
<li>Decoder產生輸出以後，跟正確的句子做比較</li>
</ul>
</li>
<li>但訓練的時候資料分開計算，只能用cross entropy。這兩者之間未必正相關</li>
<li>不一定要挑decoder cross entropy效果最好的那個模型<ul>
<li>可否在training用BLEU score?<br>    	- 不容易，BLEU本身很複雜，不易微分<br>        - 當遇到opti無法解決的問題，就用RL(強化學習)硬train一發<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1511.06732">REF</a> (HARD)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Exposure-bias"><a href="#Exposure-bias" class="headerlink" title="Exposure bias"></a>Exposure bias</h2><p><img src="/../images/20220727_2.png"></p>
<ul>
<li><p>因為decoder在train的時候，前面的vector是看著ground truth在做，所以不會有「一步錯，步步錯的問題」</p>
</li>
<li><p>但當然在測試時不可能這麼做</p>
</li>
<li><p>可以故意在training裡面加入錯的ground truth來讓模型習慣前面有錯誤輸出的應對方式 -&gt; <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1506.03099">Scheduled Sampling</a></p>
</li>
<li><p>在transformer中會有所變化，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1906.07651">參考</a></p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一頁"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">劉宇承</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a> 強力驅動
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
